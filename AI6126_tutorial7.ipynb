{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI6126_tutorial7.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMuCoiRHVeA8xrdOSOztQtU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jinyingtld/python/blob/main/AI6126_tutorial7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image Editing \n",
        "In this tutorial, we will get to know:\n",
        "* basic knowledge regarding image-to-image generation and image style transfer.\n",
        "* two classic image-to-image translation methods - pix2pix (with paired training data) and CycleGAN (with unpaired training data).\n",
        "* train pix2pix and CycleGAN\n",
        "* perform inference with a pretrained models.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lDzSNVJkLsfJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PART I Image-to-Image Translation\n",
        "\n",
        "### Introduction\n",
        "Let's first recap some background knowledge about image-to-image translation.\n",
        "Image-to-image translation usually synthesizes images from another set of images. Image-to-image translation tasks can also be divided into two types: **paired** and **unpaired**. The former usually contains paired image data in the training set therefore is easier for image synthesis; the latter does not need paired training data hence is more challenging.\n",
        "\n",
        "In this tutorial, we will focus on two methods, pix2pix for paired image-to-image translation and CycleGAN for unpaired image-to-image translation, to learn how to generate high-fidelity images. \n",
        "\n",
        "Code reference [Jun-Yan Zhu](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix)"
      ],
      "metadata": {
        "id": "G7AkDn-JMoWg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Requirement \n",
        "* Pytorch \n",
        "* torchvision\n",
        "* opencv\n",
        "* matplotlib\n",
        "* pillow\n",
        "\n",
        "Google Collab has install these packages"
      ],
      "metadata": {
        "id": "5cjxVMyQOeSi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAf5MqzhLa83",
        "outputId": "28fc9b72-2377-408d-fb5e-6611c956291b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Mon_Oct_12_20:09:46_PDT_2020\n",
            "Cuda compilation tools, release 11.1, V11.1.105\n",
            "Build cuda_11.1.TC455_06.29190527_0\n",
            "gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
            "Copyright (C) 2017 Free Software Foundation, Inc.\n",
            "This is free software; see the source for copying conditions.  There is NO\n",
            "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Check nvcc version \n",
        "!nvcc -V\n",
        "# Check GCC version\n",
        "!gcc --version"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image \n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "\n",
        "import numpy as np\n",
        "from datetime import datetime \n",
        "import time\n",
        "import logging\n",
        "import random\n",
        "import cv2\n",
        "import math \n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim \n",
        "import torch.autograd as autograd\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import Linear, Conv2d, BatchNorm2d, LayerNorm, LeakyReLU, ConvTranspose2d, ReLU, Tanh, InstanceNorm2d\n",
        "from torch.nn import ReflectionPad2d, ReplicationPad2d\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.datasets as dset \n",
        "import torchvision \n",
        "import itertools\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "ZydbjI6cPE5H"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Pytorch installation \n",
        "print(torch.__version__, torch.cuda.is_available())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJ4oMNpvOz-5",
        "outputId": "b01932ad-2060-45bf-933f-558f93883b61"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.10.0+cu111 True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the current folder\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LI--SE0uQ2xm",
        "outputId": "c6880005-8e61-4cf1-b1de-8b387ec39953"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## useful functions"
      ],
      "metadata": {
        "id": "W-x4de2-Q9Zk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# view images \n",
        "def visualize(img_arr, dpi=80):\n",
        "    plt.figure(figsize=(10,10), dpi=dpi)\n",
        "    plt.imshow(((img_arr.numpy().transpose(1,2,0) + 1.0)*127.5).astype(np.uint8))\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# load one image in tensor format \n",
        "# transform images into 1*C*H*W; data range [-1,1]\n",
        "def load_image(filename):\n",
        "    "
      ],
      "metadata": {
        "id": "wSRS85M0Q7WV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}