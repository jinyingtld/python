{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MMDetection-Faster-R-CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNQphPkIj7UtkGghGp5SPTr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jinyingtld/python/blob/main/MMDetection_Faster_R_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [MMDetection Faster R-CNN 源码详解（一)](https://zhuanlan.zhihu.com/p/166248079)\n",
        "\n",
        "本系列文章会详细剖析 MMDetection 是如何实现 Faster R-CNN 的，在本篇文章（一）中会详细的讲解 Faster R-CNN 中 backbone 相关的代码。\n",
        "\n",
        "下图是 MMDetection 实现的 Faster R-CNN 的结果。R-50 代表的是 ResNet 50，X-101 代表的是 ResNeXt 101。所以在本篇文章中会详细的讲解这两个 backbone 的网络结构和在 MMDetection 中的源码实现。\n",
        "\n",
        "![Image](https://pic3.zhimg.com/80/v2-a5c9e0fe5d3f2ff43e82a570eb813326_720w.jpg)\n",
        "\n",
        "\n",
        "## 一、ResNet\n",
        "\n",
        "![](https://pic4.zhimg.com/80/v2-1155f81ae526e777e575900f3e84b65b_720w.jpg)\n",
        "\n",
        "上图是 ResNet 的网络结构，我们来详细的分析一下。\n",
        "\n",
        "网络的输入是 224×224 的图片，首先会经过 stem 模块。stem 模块对于不同深度的 ResNet 使用的都是相同的结构，都会经过一个conv 7×7（channels：64，stride：2，padding：3） 的卷积。输出特征图的大小为 112×112。然后再次下采样，经过 Max Pooling 3×3（stride：2，padding：1） 得到 56 ×56 的特征图。当经过了 stem 模块，会完成 4 倍的下采样。(x: 224X224X3 -->conv:( 7x7 stride=2,padding=3 output=112x112)-->BN--->ReLu-->Maxpool(3x3, stride=2 padding=1 downsampling out=112/2=56)\n",
        "\n",
        "接下来会进入 4 组堆叠的残差模块，除了经过第一组残差模块特征图大小以及通道数不发生变化以外，后面三组残差模块，每经过一组，特征图的大小都会缩小一半，通道数扩张为原来 2 倍。经过四组残差模块进行特征提取后，特征图的大小变为 7×7，然后对这 7×7 的特征图做全局均值池化(avg Pooling)。最后接上全连接层，将通道数变为类别个数进行输出。\n",
        "\n",
        "在 ResNet 中最主要的结构就是残差模块，我们下面就详细解释一下残差模块的结构。\n",
        "\n",
        "残差模块含有shortcut连接, 会将经过卷积操作的结果和未经过卷积操作的结果相加. (注意: 注意：这里是相加不是拼接）对于相加后的结果再用激活函数计算. 不同的深度的 ResNet，使用了不同的残差模块。深度小于50的ResNet, 使用BasicBlock, 深度大于等于50的ResNet使用Bottleneck. 下面我们就来分别看一下这两种结构。\n",
        "\n",
        "##（一）BasicBlock（深度小于 50 的 ResNet 使用）\n",
        "BasicBlock 用于深度小于 50 的 ResNet（ResNet 18、34）。它的结构如下图：\n",
        "![](https://pic4.zhimg.com/80/v2-8ef93910b9b1d74f45cef442424b31fb_720w.jpg)\n",
        "图三：BasicBlock 结构\n",
        "\n",
        "对于每个BasicBlock, 有两个分支. 一个分支用来正常的卷积,另一个分支用于跳跃连接. 输入一张特征图后会经过两个3x3的卷积提取特征,然后将卷积操作后的特征图与输入的特征图相加，再用 ReLU 激活函数进行计算。在 BasicBlock 中，卷积的通道数不发生改变，可以直接将输入的特征图和卷积后的特征图相加。\n",
        "\n",
        "上面的操作既不会改变特征图的大小，又不会改变特征图的通道数，那么我们如何进行下采样呢？换句话说，也就是上面的情况是针对同一个 stage 之内的 BasicBlock，对于不同 stage 之间的 BasicBlock 我们怎么处理呢（如：conv2_2 和 conv3_1）？\n",
        "\n",
        "我们对每个stage中的第一个block进行更改.将第一个3x3的卷积的步长变为原来的2倍, 通过数也扩大为原来的2倍,padding不变还为1. 这样的化经过卷积后的特征图的大小变为原来的1/2,通道数会扩张为原来的2倍. 对于shortcut分支,使用步长为2的 1×1 卷积用于下采样和扩张通道数，这样特征图的大小变成原来的 1/2，通道数也会扩张为原来的 2 倍。和卷积分支的输出特征图形状相同。然后我们将两个分支的结果相加，再通过 ReLU 激活函数即可。如下图：\n",
        "\n",
        "![](https://pic2.zhimg.com/v2-e849a9d912716e1c213fb5db3bb76a45_r.jpg)图四：stage 和 stage 之间的 BasicBlock\n",
        "\n",
        "当然因为 stem 和第一个 stage 之间的通道数都是 64，且第一个 stage 不需要进行下采样。所以，我们使用图三的 block 即可。]\n",
        "\n",
        "我们来看一下源码：\n"
      ],
      "metadata": {
        "id": "OJDTllqasZ8h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bxJdU2-_sSmD"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.utils.checkpoint as cp\n",
        "from mmcv.cnn import (build_conv_layer, build_norm_layer, build_plugin_layer, constant_init, kaiming_init)\n",
        "from mmcv.runner import load_checkpoint\n",
        "from torch.nn.modules.batchnorm import _BatchNorm\n",
        "\n",
        "from mmdet.utils import get_root_logger\n",
        "from ..builder import BACKBONES\n",
        "from ..utils import ResLayer\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    \"\"\"ResNet 18, 34 使用的block\"\"\"\n",
        "    # 输出通道为输入通道的倍数.(输出通道数 == 输入通道数)\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self,\n",
        "                 inplanes,\n",
        "                 planes,\n",
        "                 stride=1,\n",
        "                 dilation=1,\n",
        "                 downsample=None\n",
        "                 style='pytorch',\n",
        "                 with_cp=False,\n",
        "                 conf_cfg=None,\n",
        "                 norm_cfg=dict(type='BN'),\n",
        "                 dcn=None,\n",
        "                 plugins=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        assert dcn is None, 'Not implemented yet.'\n",
        "        assert plugins is None, 'Not implemented yet.'\n",
        "        # conv3x3 ---> bn1 --> relu --> conv3x3 ---> bn2 --> relu\n",
        "\n",
        "        #bn1, bn2\n",
        "        self.norm1_name, norm1 = build_norm_layer(norm_cfg, planes, postfix=1)\n",
        "        self.norm2_name, norm2 = build_norm_layer(norm_cfg, planes, postfix=2)\n",
        "\n",
        "        # 当conv1: 3x3 conv \n",
        "        # 当conv 为3x3 且padding = dilation时, 原特征图大小只和 stride 有关\n",
        "        self.conv1 = build_conv_layer(\n",
        "            conv_cfg,\n",
        "            inplanes,\n",
        "            planes,\n",
        "            3,\n",
        "            stride=stride,\n",
        "            padding=dilation,\n",
        "            dilation=dilation,\n",
        "            bias=False)\n",
        "        self.add_module(self.norm1_name,norm1)\n",
        "\n",
        "        # conv2: 3x3 conv, stride = 1, padding = 1.\n",
        "        self.conv2 = build_conv_layer(\n",
        "            conv_cfg, planes, planes, 3, padding=1, bias=False)\n",
        "        self.add_module(self.norm2_name, norm2)\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "        self.dilation = dilation\n",
        "        self.with_cp = with_cp\n",
        "\n",
        "    @property\n",
        "    def norm1(self):\n",
        "        \"\"\"nn.Module: normalization layer after the first convolution layer\"\"\"\n",
        "        return getattr(self, self.norm1_name)\n",
        "    \n",
        "    @property\n",
        "    def norm2(self):\n",
        "        \"\"\"nn.Module: normalization layer after the second convolution layer\"\"\"\n",
        "        return getattr(self, self.norm2_name)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Forward function.\"\"\"\n",
        "        def _inner_forward(x):\n",
        "            identity = x\n",
        "\n",
        "            out = self.conv1(x)\n",
        "            out = self.norm1(out)\n",
        "            out = self.relu(out)\n",
        "\n",
        "            out = self.conv2(out)\n",
        "            out = self.norm2(out)\n",
        "\n",
        "            # 需要保证identity 和 x的宽度相同.\n",
        "            if self.downsample is not None:\n",
        "                identity = self.downsample(x)\n",
        "            \n",
        "            # h(x) = f(x) + x\n",
        "            out += identity\n",
        "\n",
        "            return out\n",
        "\n",
        "        # 加载预训练模型并且需要求导的时候, 使用checkpoint用时间换取空间.\n",
        "        # 这是因为加载权重后可以训练的epoch数少, 可以考虑时间换取空间.\n",
        "        if self.with_cp and x.requires_grad:\n",
        "            # 使用 checkpoint 不保存中间计算的激活值, 在反向传播中重新计算一次中间激活值。\n",
        "            # 即重新运行一次检查点部分的前向传播，这是一种以时间换空间（显存）的方法。\n",
        "            out = cp.checkpoint(_inner_forward, x)\n",
        "        # 不加载权重，从零开始训练。不使用 ckpt，因为训练慢。\n",
        "        else:\n",
        "            out = _inner_forward(x)\n",
        "\n",
        "         # 注意：f(x) + x 之后再进行 relu\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## （二）Bottleneck（深度大于等于 50 的 ResNet 使用）\n",
        "\n",
        "Bottleneck 用于深度大于等于50de ResNet (ResNet 50, 101, 152). 它的结构如下图：\n",
        "\n",
        "![](https://pic2.zhimg.com/80/v2-b37d119bf676d64d30e0f36a72824999_720w.jpg)图五：Bottleneck 结构\n",
        "\n",
        "对于 Bottleneck 来说，它会先使用 1×1 的卷积对输入的通道数进行压缩，然后再使用 3×3 的卷积进行卷积，最后使用 1×1 的卷积恢复通道数。然后将输入与卷积的结果相加并通过激活函数进行计算。\n",
        "\n",
        "对于上面的操作，特征图的大小和输入输出的通道数不发生改变。如果需要下采样。需要将每个 stage 的第一个 Bottleneck 中的 3×3 卷积的步长和通道数设置为原来的 2 倍。对于 shortcut 分支，我们使用 1×1 步长为 2，通道数为原来 2 倍的卷积核进行下采样。如下图：\n",
        "\n",
        "![](https://pic1.zhimg.com/80/v2-61b2c58524945a7af86b33b95c6f35ac_720w.jpg)\n",
        "图六：stage 和 stage 之间的 BasicBlock\n",
        "\n",
        "stem 和第一个 stage 之前。只需要扩大通道数不需要下采样，所以，我们只用将上图（图六）的 Bottleneck 中的 3×3 的卷积的步长设置为 1 即可。\n",
        "\n",
        "我们来看一下源码：\n"
      ],
      "metadata": {
        "id": "l5f5VjtiInpK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Bottleneck(nn.Module):\n",
        "    \"\"\"ResNet 50, 101, 152 使用的 block\n",
        "\n",
        "    Args:\n",
        "        style:(str) 'pytorch 或 'caffe'.\n",
        "                    如果使用 'pytorch', block 中 stride 为 2 的卷积层是 3x3 conv, stride=2\n",
        "                    如果使用 'caffe',   block 中 stride 为 2 的卷积层是 1x1 conv, stride=2\n",
        "    \"\"\"\n",
        "    # 输出通道数为输入通道数的倍数. (输出通道数 == 4 × 输入通道数)\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self,\n",
        "                 inplanes,\n",
        "                 planes,\n",
        "                 stride=1,\n",
        "                 dilation=1,\n",
        "                 downsample=None,\n",
        "                 style='pytorch',\n",
        "                 with_cp=False,\n",
        "                 conv_cfg=None,\n",
        "                 norm_cfg=dict(type='BN'),\n",
        "                 dcn=None,\n",
        "                 plugins=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        assert style in ['pytorch', 'caffe']\n",
        "        assert dcn is None or isinstance(dcn, dict)\n",
        "        assert plugins is None or isinstance(plugins, list)\n",
        "        if plugins is not None:\n",
        "            allowed_position = ['after_conv1', 'after_conv2', 'after_conv3']\n",
        "            assert all(p['position'] in allowed_position for p in plugins)\n",
        "\n",
        "        self.inplanes = inplanes\n",
        "        self.planes = planes\n",
        "        self.stride = stride\n",
        "        self.dilation = dilation\n",
        "        self.style = style\n",
        "        self.with_cp = with_cp\n",
        "        self.conv_cfg = conv_cfg\n",
        "        self.norm_cfg = norm_cfg\n",
        "        self.dcn = dcn\n",
        "        self.with_dcn = dcn is not None\n",
        "        self.plugins = plugins\n",
        "        self.with_plugins = plugins is not None\n",
        "\n",
        "        if self.with_plugins:\n",
        "            # collect plugins for conv1/conv2/conv3\n",
        "            self.after_conv1_plugins = [\n",
        "                plugin['cfg'] for plugin in plugins\n",
        "                if plugin['position'] == 'after_conv1'\n",
        "            ]\n",
        "            self.after_conv2_plugins = [\n",
        "                plugin['cfg'] for plugin in plugins\n",
        "                if plugin['position'] == 'after_conv2'\n",
        "            ]\n",
        "            self.after_conv3_plugins = [\n",
        "                plugin['cfg'] for plugin in plugins\n",
        "                if plugin['position'] == 'after_conv3'\n",
        "            ]\n",
        "\n",
        "        if self.style == 'pytorch':\n",
        "            self.conv1_stride = 1\n",
        "            self.conv2_stride = stride\n",
        "        else:\n",
        "            self.conv1_stride = stride\n",
        "            self.conv2_stride = 1\n",
        "\n",
        "        # conv1x1 --> bn1 --> relu\n",
        "        # conv3x3 --> bn2 --> relu\n",
        "        # conv1x1 --> bn3\n",
        "        self.norm1_name, norm1 = build_norm_layer(norm_cfg, planes, postfix=1)\n",
        "        self.norm2_name, norm2 = build_norm_layer(norm_cfg, planes, postfix=2)\n",
        "        self.norm3_name, norm3 = build_norm_layer(\n",
        "            norm_cfg, planes * self.expansion, postfix=3\n",
        "        )\n",
        "\n",
        "        self.conv1 = build_conv_layer(\n",
        "            conv_cfg,\n",
        "            inplanes,\n",
        "            planes,\n",
        "            kernel_size=1,\n",
        "            stride=self.conv1_stride,\n",
        "            bias=False)\n",
        "        self.add_module(self.norm1_name, norm1)\n",
        "        fallback_on_stride = False\n",
        "        if self.with_dcn:\n",
        "            fallback_on_stride = dcn.pop('fallback_on_stride', False)\n",
        "        if not self.with_dcn or fallback_on_stride:\n",
        "            self.conv2 = build_conv_layer(\n",
        "                conv_cfg,\n",
        "                planes,\n",
        "                planes,\n",
        "                kernel_size=3,\n",
        "                stride=self.conv2_stride,\n",
        "                padding=dilation,\n",
        "                dilation=dilation,\n",
        "                bias=False)\n",
        "        else:\n",
        "            assert self.conv_cfg is None, 'conv_cfg must be None for DCN'\n",
        "            self.conv2 = build_conv_layer(\n",
        "                dcn,\n",
        "                planes,\n",
        "                planes,\n",
        "                kernel_size=3,\n",
        "                stride=self.conv2_stride,\n",
        "                padding=dilation,\n",
        "                dilation=dilation,\n",
        "                bias=False)\n",
        "\n",
        "        self.add_module(self.norm2_name, norm2)\n",
        "        self.conv3 = build_conv_layer(\n",
        "            conv_cfg,\n",
        "            planes,\n",
        "            planes * self.expansion,\n",
        "            kernel_size=1,\n",
        "            bias=False)\n",
        "        self.add_module(self.norm3_name, norm3)\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample \n",
        "\n",
        "        if self.with_plugins:\n",
        "            self.after_conv1_plugin_names = self.make_block_plugins(\n",
        "                planes, self.after_conv1_plugins)\n",
        "            self.after_conv2_plugin_names = self.make_block_plugins(\n",
        "                planes, self.after_conv2_plugins)\n",
        "            self.after_conv3_plugin_names = self.make_block_plugins(\n",
        "                planes * self.expansion, self.after_conv3_plugins)\n",
        "\n",
        "    def make_block_plugins(self, in_channels, plugins):\n",
        "        \"\"\"make plugins for block.\n",
        "\n",
        "        Args:\n",
        "            in_channels (int): Input channels of plugin.\n",
        "            plugins (list[dict]): List of plugins cfg to build.\n",
        "\n",
        "        Returns:\n",
        "            list[str]: List of the names of plugin.\n",
        "        \"\"\"\n",
        "        assert isinstance(plugins, list)\n",
        "        plugin_names = []\n",
        "        for plugin in plugins:\n",
        "            plugin = plugin.copy()\n",
        "            name, layer = build_plugin_layer(\n",
        "                plugin,\n",
        "                in_channels=in_channels,\n",
        "                postfix=plugin.pop('postfix', ''))\n",
        "            assert not hasattr(self, name), f'duplicate plugin {name}'\n",
        "            self.add_module(name, layer)\n",
        "            plugin_names.append(name)\n",
        "        return plugin_names\n",
        "\n",
        "    def forward_plugin(self, x, plugin_names):\n",
        "        out = x\n",
        "        for name in plugin_names:\n",
        "            out = getattr(self, name)(x)\n",
        "        return out\n",
        "\n",
        "    @property\n",
        "    def norm1(self):\n",
        "        \"\"\"nn.Module: normalization layer after the first convolution layer\"\"\"\n",
        "        return getattr(self, self.norm1_name)\n",
        "\n",
        "    @property\n",
        "    def norm2(self):\n",
        "        \"\"\"nn.Module: normalization layer after the second convolution layer\"\"\"\n",
        "        return getattr(self, self.norm2_name)\n",
        "\n",
        "    @property\n",
        "    def norm3(self):\n",
        "        \"\"\"nn.Module: normalization layer after the third convolution layer\"\"\"\n",
        "        return getattr(self, self.norm3_name)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        \"\"\"Forward function.\"\"\"\n",
        "\n",
        "        def _inner_forward(x):\n",
        "            identity = x\n",
        "\n",
        "            out = self.conv1(x)\n",
        "            out = self.norm1(out)\n",
        "            out = self.relu(out)\n",
        "\n",
        "            if self.with_plugins:\n",
        "                out = self.forward_plugin(out, self.after_conv1_plugin_names)\n",
        "\n",
        "            out = self.conv2(out)\n",
        "            out = self.norm2(out)\n",
        "            out = self.relu(out)\n",
        "\n",
        "            if self.with_plugins:\n",
        "                out = self.forward_plugin(out, self.after_conv2_plugin_names)\n",
        "\n",
        "            out = self.conv3(out)\n",
        "            out = self.norm3(out)\n",
        "\n",
        "            if self.with_plugins:\n",
        "                out = self.forward_plugin(out, self.after_conv3_plugin_names)\n",
        "\n",
        "            if self.downsample is not None:\n",
        "                identity = self.downsample(x)\n",
        "\n",
        "            out += identity\n",
        "\n",
        "            return out\n",
        "\n",
        "        if self.with_cp and x.requires_grad:\n",
        "            out = cp.checkpoint(_inner_forward, x)\n",
        "        else:\n",
        "            out = _inner_forward(x)\n",
        "\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "1pDgpc_6Mg41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 下面我们来看一下 ResNet 类的源码："
      ],
      "metadata": {
        "id": "k6YCR-UPTGv9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet(nn.Moduel):\n",
        "    \"\"\"ResNet backbone.\n",
        "\n",
        "    Args:\n",
        "        depth:                     (int)   ResNet 的深度, 可以是 {18, 34, 50, 101, 152}.\n",
        "        in_channels:               (int)   输入图像的通道数(默认: 3).\n",
        "        stem_channels:             (int)   stem 的通道数(默认: 64).\n",
        "        base_channels:             (int)   ResNet 的 res layer 的基础通道数(默认: 64).\n",
        "        num_stages:                (int)   使用 ResNet 的 stage 数量(默认: 4).\n",
        "        strides:         (Sequence[int])   每个 stage 的第一个 block 的 stride, 如果为 2 进行 2 倍下采样.\n",
        "        dilations:       (Sequence[int])   每个 stage 中所有 block 的第一个卷积层的 dilation.\n",
        "        out_indices:     (Sequence[int])   需要输出的 stage 的索引.\n",
        "        style:                     (str)   'pytorch' 或 'caffe'.\n",
        "                                           如果使用 'pytorch', block 中 stride 为 2 的卷积层是 3x3 conv2, stride=2\n",
        "                                           如果使用 'caffe',   block 中 stride 为 2 的卷积层是 1x1 conv1, stride=2\n",
        "        deep_stem:                (bool)   如果为 True, 将 stem 的 7x7 conv 替换为 3 个 3x3 conv.\n",
        "        avg_down:                 (bool)   在下采样的时候使用 Avg pool 2x2 stride=2 代替带步长的卷积.\n",
        "        frozen_stages:             (int)   冻结的 stage 数(停止更新梯度, 并开启eval模式), -1 代表不冻结.\n",
        "        conv_cfg:                 (dict)   构建 conv 的 config.\n",
        "        norm_cfg:                 (dict)   构建 norm 的 config.\n",
        "        norm_eval:                (bool)   是否设置 norm 层为 eval 模式. 即冻结参数状态(mean, var).\n",
        "        dcn:                      (dict)   构建 DCN 的 config.\n",
        "        stage_with_dcn: (Sequence[bool])   需要使用 DCN 的 stage.\n",
        "        plugins:            (list[dict])   为 stage 提供插件.\n",
        "        with_cp:                  (bool)   是否加载 checkpoint. 使用 checkpoint 会节省一部分内存, 同时会减少训练时间.\n",
        "        zero_init_residual:       (bool)   是否使用 0 对所有 block 中的最后一个 norm 层初始化, 使其为恒等映射.\n",
        "\n",
        "    Example:\n",
        "        >>> from mmdet.models import ResNet\n",
        "        >>> import torch\n",
        "        >>> self = ResNet(depth=18)\n",
        "        >>> self.eval()\n",
        "        >>> inputs = torch.rand(1, 3, 32, 32)\n",
        "        >>> level_outputs = self.forward(inputs)\n",
        "        >>> for level_out in level_outputs:\n",
        "        ...     print(tuple(level_out.shape))\n",
        "        (1, 64, 8, 8)\n",
        "        (1, 128, 4, 4)\n",
        "        (1, 256, 2, 2)\n",
        "        (1, 512, 1, 1)\n",
        "    \"\"\"\n",
        "    arch_settings = {\n",
        "        18: (BasicBlock, (2, 2, 2, 2)),\n",
        "        34: (BasicBlock, (3, 4, 6, 3)),\n",
        "        50: (Bottleneck, (3, 4, 6, 3)),\n",
        "        101: (Bottleneck, (3, 4, 23, 3)),\n",
        "        152: (Bottleneck, (3, 8, 36, 3))\n",
        "    }\n",
        "\n",
        "    def __init__(self,\n",
        "                 depth,\n",
        "                 in_channels=3,\n",
        "                 stem_channels=64,\n",
        "                 base_channels=64,\n",
        "                 num_stages=4,\n",
        "                 strides=(1, 2, 2, 2),\n",
        "                 dilations=(1, 1, 1, 1),\n",
        "                 out_indices=(0, 1, 2, 3),\n",
        "                 style='pytorch',\n",
        "                 deep_stem=False,\n",
        "                 avg_down=False,\n",
        "                 frozen_stages=-1,\n",
        "                 conv_cfg=None,\n",
        "                 norm_cfg=dict(type='BN', requires_grad=True),\n",
        "                 norm_eval=True,\n",
        "                 dcn=None,\n",
        "                 stage_with_dcn=(False, False, False, False),\n",
        "                 plugins=None,\n",
        "                 with_cp=False,\n",
        "                 zero_init_residual=True):\n",
        "        super(ResNet, self).__init__()\n",
        "        # ========================== 初始化属性 =============================\n",
        "        if depth not in self.arch_settings:\n",
        "            raise KeyError(f'invalid depth {depth} for resnet')\n",
        "        self.depth = depth\n",
        "        self.stem_channels = stem_channels\n",
        "        self.base_channels = base_channels\n",
        "        self.num_stages = num_stages\n",
        "        assert num_stages >= 1 and num_stages <= 4\n",
        "        self.strides = strides\n",
        "        self.dilations = dilations\n",
        "        assert len(strides) == len(dilations) == num_stages\n",
        "        self.out_indices = out_indices\n",
        "        assert max(out_indices) < num_stages\n",
        "        self.style = style\n",
        "        self.deep_stem = deep_stem\n",
        "        self.avg_down = avg_down\n",
        "        self.frozen_stages = frozen_stages\n",
        "        self.conv_cfg = conv_cfg\n",
        "        self.norm_cfg = norm_cfg\n",
        "        self.with_cp = with_cp\n",
        "        self.norm_eval = norm_eval\n",
        "        self.dcn = dcn\n",
        "        self.stage_with_dcn = stage_with_dcn\n",
        "        if dcn is not None:\n",
        "            assert len(stage_with_dcn) == num_stages\n",
        "        self.plugins = plugins\n",
        "        self.zero_init_residual = zero_init_residual\n",
        "        # ===================================================================\n",
        "        self.block, stage_blocks = self.arch_settings[depth]\n",
        "        self.stage_blocks = stage_blocks[:num_stages]\n",
        "\n",
        "        # stem 层\n",
        "        self.inplanes = stem_channels\n",
        "        self._make_stem_layer(in_channels, stem_channels)\n",
        "\n",
        "        # res 层\n",
        "        self.res_layers = []\n",
        "        for i, num_blocks in enumerate(self.stage_blocks):\n",
        "            stride = strides[i]\n",
        "            dilation = dilations[i]\n",
        "            dcn = self.dcn if self.stage_with_dcn[i] else None\n",
        "            if plugins is not None:\n",
        "                stage_plugins = self.make_stage_plugins(plugins, i)\n",
        "            else:\n",
        "                stage_plugins = None\n",
        "            planes = base_channels * 2**i\n",
        "            res_layer = self.make_res_layer(\n",
        "                block=self.block,\n",
        "                inplanes=self.inplanes,\n",
        "                planes=planes,\n",
        "                num_blocks=num_blocks,\n",
        "                stride=stride,\n",
        "                dilation=dilation,\n",
        "                style=self.style,\n",
        "                avg_down=self.avg_down,\n",
        "                with_cp=with_cp,\n",
        "                conv_cfg=conv_cfg,\n",
        "                norm_cfg=norm_cfg,\n",
        "                dcn=dcn,\n",
        "                plugins=stage_plugins)\n",
        "            self.inplanes = planes * self.block.expansion\n",
        "            layer_name = f'layer{i + 1}'\n",
        "            self.add_module(layer_name, res_layer)\n",
        "            self.res_layers.append(layer_name)\n",
        "\n",
        "        self._freeze_stages()\n",
        "\n",
        "        self.feat_dim = self.block.expansion * base_channels * 2**(\n",
        "            len(self.stage_blocks) - 1)\n",
        "\n",
        "    def make_stage_plugins(self, plugins, stage_idx):\n",
        "        \"\"\"Make plugins for ResNet ``stage_idx`` th stage.\n",
        "\n",
        "        Currently we support to insert ``context_block``,\n",
        "        ``empirical_attention_block``, ``nonlocal_block`` into the backbone\n",
        "        like ResNet/ResNeXt. They could be inserted after conv1/conv2/conv3 of\n",
        "        Bottleneck.\n",
        "\n",
        "        An example of plugins format could be:\n",
        "\n",
        "        Examples:\n",
        "            >>> plugins=[\n",
        "            ...     dict(cfg=dict(type='xxx', arg1='xxx'),\n",
        "            ...          stages=(False, True, True, True),\n",
        "            ...          position='after_conv2'),\n",
        "            ...     dict(cfg=dict(type='yyy'),\n",
        "            ...          stages=(True, True, True, True),\n",
        "            ...          position='after_conv3'),\n",
        "            ...     dict(cfg=dict(type='zzz', postfix='1'),\n",
        "            ...          stages=(True, True, True, True),\n",
        "            ...          position='after_conv3'),\n",
        "            ...     dict(cfg=dict(type='zzz', postfix='2'),\n",
        "            ...          stages=(True, True, True, True),\n",
        "            ...          position='after_conv3')\n",
        "            ... ]\n",
        "            >>> self = ResNet(depth=18)\n",
        "            >>> stage_plugins = self.make_stage_plugins(plugins, 0)\n",
        "            >>> assert len(stage_plugins) == 3\n",
        "\n",
        "        Suppose ``stage_idx=0``, the structure of blocks in the stage would be:\n",
        "\n",
        "        .. code-block:: none\n",
        "\n",
        "            conv1-> conv2->conv3->yyy->zzz1->zzz2\n",
        "\n",
        "        Suppose 'stage_idx=1', the structure of blocks in the stage would be:\n",
        "\n",
        "        .. code-block:: none\n",
        "\n",
        "            conv1-> conv2->xxx->conv3->yyy->zzz1->zzz2\n",
        "\n",
        "        If stages is missing, the plugin would be applied to all stages.\n",
        "\n",
        "        Args:\n",
        "            plugins (list[dict]): List of plugins cfg to build. The postfix is\n",
        "                required if multiple same type plugins are inserted.\n",
        "            stage_idx (int): Index of stage to build\n",
        "\n",
        "        Returns:\n",
        "            list[dict]: Plugins for current stage\n",
        "        \"\"\"\n",
        "        stage_plugins = []\n",
        "        for plugin in plugins:\n",
        "            plugin = plugin.copy()\n",
        "            stages = plugin.pop('stages', None)\n",
        "            assert stages is None or len(stages) == self.num_stages\n",
        "            # whether to insert plugin into current stage\n",
        "            if stages is None or stages[stage_idx]:\n",
        "                stage_plugins.append(plugin)\n",
        "\n",
        "        return stage_plugins\n",
        "\n",
        "    def make_res_layer(self, **kwargs):\n",
        "        \"\"\"Pack all blocks in a stage into a ``ResLayer``.\"\"\"\n",
        "        return ResLayer(**kwargs)\n",
        "\n",
        "    @property\n",
        "    def norm1(self):\n",
        "        \"\"\"nn.Module: the normalization layer named \"norm1\" \"\"\"\n",
        "        return getattr(self, self.norm1_name)\n",
        "\n",
        "     def _make_stem_layer(self, in_channels, stem_channels):\n",
        "        # 使用 deep stem, 即 3 个 3x3 conv.\n",
        "        if self.deep_stem:\n",
        "            self.stem = nn.Sequential(\n",
        "                build_conv_layer(\n",
        "                    self.conv_cfg,\n",
        "                    in_channels,\n",
        "                    stem_channels // 2,\n",
        "                    kernel_size=3,\n",
        "                    stride=2,\n",
        "                    padding=1,\n",
        "                    bias=False),\n",
        "                build_norm_layer(self.norm_cfg, stem_channels // 2)[1],\n",
        "                nn.ReLU(inplace=True),\n",
        "                build_conv_layer(\n",
        "                    self.conv_cfg,\n",
        "                    stem_channels // 2,\n",
        "                    stem_channels // 2,\n",
        "                    kernel_size=3,\n",
        "                    stride=1,\n",
        "                    padding=1,\n",
        "                    bias=False),\n",
        "                build_norm_layer(self.norm_cfg, stem_channels // 2)[1],\n",
        "                nn.ReLU(inplace=True),\n",
        "                build_conv_layer(\n",
        "                    self.conv_cfg,\n",
        "                    stem_channels // 2,\n",
        "                    stem_channels,\n",
        "                    kernel_size=3,\n",
        "                    stride=1,\n",
        "                    padding=1,\n",
        "                    bias=False),\n",
        "                build_norm_layer(self.norm_cfg, stem_channels)[1],\n",
        "                nn.ReLU(inplace=True))\n",
        "        # 使用原版的 stem 即 7x7 conv\n",
        "        else:\n",
        "            self.conv1 = build_conv_layer(\n",
        "                self.conv_cfg,\n",
        "                in_channels,\n",
        "                stem_channels,\n",
        "                kernel_size=7,\n",
        "                stride=2,\n",
        "                padding=3,\n",
        "                bias=False)\n",
        "            self.norm1_name, norm1 = build_norm_layer(\n",
        "                self.norm_cfg, stem_channels, postfix=1)\n",
        "            self.add_module(self.norm1_name, norm1)\n",
        "            self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "    def _freeze_stages(self):\n",
        "        # 冻结 stem 层 --> stage 为 0\n",
        "        if self.frozen_stages >= 0:\n",
        "            if self.deep_stem:\n",
        "                self.stem.eval()\n",
        "                for param in self.stem.parameters():\n",
        "                    param.requires_grad = False\n",
        "            else:\n",
        "                self.norm1.eval()\n",
        "                for m in [self.conv1, self.norm1]:\n",
        "                    for param in m.parameters():\n",
        "                        param.requires_grad = False\n",
        "\n",
        "        # 冻结 res 层  --> stage 大于 0\n",
        "        for i in range(1, self.frozen_stages + 1):\n",
        "            m = getattr(self, f'layer{i}')\n",
        "            m.eval()\n",
        "            for param in m.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "    def init_weights(self, pretrained=None):\n",
        "        \"\"\"Initialize the weights in backbone.\n",
        "\n",
        "        Args:\n",
        "            pretrained (str, optional): Path to pre-trained weights.\n",
        "                Defaults to None.\n",
        "        \"\"\"\n",
        "        if isinstance(pretrained, str):\n",
        "            logger = get_root_logger()\n",
        "            load_checkpoint(self, pretrained, strict=False, logger=logger)\n",
        "        elif pretrained is None:\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, nn.Conv2d):\n",
        "                    kaiming_init(m)\n",
        "                elif isinstance(m, (_BatchNorm, nn.GroupNorm)):\n",
        "                    constant_init(m, 1)\n",
        "\n",
        "            if self.dcn is not None:\n",
        "                for m in self.modules():\n",
        "                    if isinstance(m, Bottleneck) and hasattr(\n",
        "                            m.conv2, 'conv_offset'):\n",
        "                        constant_init(m.conv2.conv_offset, 0)\n",
        "\n",
        "            if self.zero_init_residual:\n",
        "                for m in self.modules():\n",
        "                    if isinstance(m, Bottleneck):\n",
        "                        constant_init(m.norm3, 0)\n",
        "                    elif isinstance(m, BasicBlock):\n",
        "                        constant_init(m.norm2, 0)\n",
        "        else:\n",
        "            raise TypeError('pretrained must be a str or None')\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Forward function.\"\"\"\n",
        "        if self.deep_stem:\n",
        "            x = self.stem(x)\n",
        "        else:\n",
        "            x = self.conv1(x)\n",
        "            x = self.norm1(x)\n",
        "            x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        outs = []\n",
        "        for i, layer_name in enumerate(self.res_layers):\n",
        "            res_layer = getattr(self, layer_name)\n",
        "            x = res_layer(x)\n",
        "            if i in self.out_indices:\n",
        "                outs.append(x)\n",
        "        return tuple(outs)\n",
        "\n",
        "    def train(self, mode=True):\n",
        "        \"\"\"Convert the model into training mode while keep normalization layer\n",
        "        freezed.\"\"\"\n",
        "        super(ResNet, self).train(mode)\n",
        "        self._freeze_stages()\n",
        "        if mode and self.norm_eval:\n",
        "            for m in self.modules():\n",
        "                # trick: eval have effect on BatchNorm only\n",
        "                if isinstance(m, _BatchNorm):\n",
        "                    m.eval()"
      ],
      "metadata": {
        "id": "x43IGMFqTTBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[更多ResNeXt](https://zhuanlan.zhihu.com/p/166248079)"
      ],
      "metadata": {
        "id": "RhI4TgxZU-sR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [MMDetection Faster R-CNN 源码详解（二）](https://zhuanlan.zhihu.com/p/183098688)\n",
        "\n",
        "本篇文章中，会重点剖析 MMDetection 实现的 Faster R-CNN 中的 neck 相关的源码。\n",
        "\n",
        "## 一、FPN 的思想(Feature Pyramid Network)\n",
        "\n",
        "在 MMDetection 中，Faster R-CNN 的 baseline 结合了 FPN，通过 FPN 会大大的提升检测的效果。为什么 FPN 有这么强的作用呢？我们从如下两点分析\n",
        "\n",
        "1. 提取了多尺度的特征: 相对于单尺度的特征，多尺度的特征对大中小物体都能覆盖。对于 CNN 网络，浅层特征的特征途较大, 感受野较小, 方便检测小物体. 深层特征的特征图较小, 感受野较大, 方便检测大物体. 所以使用多尺度的特征对于不同大小的物体都有很好的覆盖效果。\n",
        "\n",
        "2. 融合了各个尺度的特征：对于浅层的特征图，对位置敏感但是语义信息较弱。深层的特征图，对位置不敏感但是语义信息较强。那么我们就可以将当前的尺度与更深层的尺度的特征图相融合。这样既有深层的语义信息又对位置敏感。\n",
        "\n",
        "\n",
        "## 二、Faster R-CNN 结合 FPN\n",
        "接下来我们就来看一下如何将 Faster R-CNN 与 FPN 向结合，下图是将 Faster R-CNN 与 FPN 融合的网络结构。\n",
        "\n",
        "![](https://pic1.zhimg.com/80/v2-4aee99e6842420bf682433ff4c0ff720_720w.jpg) Faster R-CNN 结合 FPN 的网络结构\n",
        "\n",
        "\n",
        "拿到 backbone 的后四个尺度的输出，也就是 C2 ～ C5。以 resnet 50 为例，通道数分别为：256、512、1024、2048。先使用 1×1 的卷积，将 resnet 输出的特征图压缩通道数到 256，得到 P2 ～ P5。然后将浅层的特征图与深层的特征图相加（需要先上采样，保证特征图大小相同再相加）。再使用 3 × 3 的卷积核进行卷积，此步骤会将相加的特征进一步融合，得到 FPN 输出的特征，也就是 P2 ～ P5。在 P5 上使用 1 × 1 步长为 2 的 max pool 进行下采样，得到 P6。所以当数据经过 FPN 后，我们会拿到五个尺度的特征，也就是 P2 ～ P6。每个特征的通道数都是 256。因为每个尺度输出的特征图的通道数固定，所以我们就可以使用相同的头部进行预测了。\n",
        "\n",
        "![](https://pic1.zhimg.com/80/v2-c0172be282021a1029f7b72b51079ffe_1440w.jpg)\n",
        "\n",
        "\n",
        "![](https://pic2.zhimg.com/v2-e49ebcf931b5cf424ed311338f9ff35d_b.jpg)\n",
        "\n",
        "\n",
        "## 三、RetinaNet 中的 FPN\n",
        "\n",
        "![](https://pic1.zhimg.com/80/v2-b5a2faa28bd62f532d4fb405159f15dc_720w.jpg)\n",
        "\n",
        "在 RetinaNet 中，利用的 backbone 的特征是 C3 ～ C5。将 C3 ～ C5 的特征图经过 1×1 的卷积压缩通道数，再将深层特征图与浅层特征图相加。然后使用 3 × 3 的卷积进一步融合特征。这样操作后，我们提取了从 P3 ～ P5 的特征。对于 C5，我们用 3 × 3 步长为 2，padding 为 1 的卷积进行两次下采样就得到 FPN 的 P6 和 P7。\n",
        "\n"
      ],
      "metadata": {
        "id": "G3gGKZ5BVLeZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 四、FPN 源码分析\n",
        "（一）Faster R-CNN 的 FPN 配置\n",
        "紧接着，将x输入到neck中,也就是fpn结构中，我这里fpn的设置参数为"
      ],
      "metadata": {
        "id": "0B0o04mTVqIw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "neck=dict(\n",
        "        type='FPN',\n",
        "        in_channels=[256, 512, 1024, 2048],\n",
        "        out_channels=256,\n",
        "        num_outs=5),"
      ],
      "metadata": {
        "id": "uy6mhzVaa25e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "（二）RetinaNet 的 FPN 配置"
      ],
      "metadata": {
        "id": "-pKD1d2ra8lY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "neck=dict(\n",
        "        type='FPN',\n",
        "        in_channels=[256, 512, 1024, 2048],\n",
        "        out_channels=256,\n",
        "        start_level=1,\n",
        "        add_extra_convs='on_input',\n",
        "        num_outs=5),"
      ],
      "metadata": {
        "id": "qE56vomna9i5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "结合上面的配置文件我们来看一下源码：\n"
      ],
      "metadata": {
        "id": "BExuOoPJbBH_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from mmcv.cnn import ConvModule, xavier_init\n",
        "\n",
        "from mmdet.core import auto_fp16\n",
        "from ..builder import NECKS\n",
        "\n",
        "@NECKS.register_module()\n",
        "class FPN(nn.Module):\n",
        "    \"\"\"Feature Pyramid Network.  (https://arxiv.org/abs/1612.03144)\n",
        "\n",
        "    Args:\n",
        "        in_channels:                    (List[int])     每个尺度的输入通道数, 也是 backbone 的输出通道数.\n",
        "        out_channels:                  (int)     fpn 的输出通道数, 所有尺度的输出通道数相同, 都是一个值.\n",
        "        num_outs:                      (int)     输出 stage 的个数.(可以附加额外的层, num_outs 不一定等于 in_channels)\n",
        "        start_level:                   (int)     使用 backbone 的起始 stage 索引, 默认为 0.\n",
        "        end_level:                     (int)     使用 backbone 的终止 stage 索引。\n",
        "                                                默认为 -1, 代表到最后一层(包括)全使用.\n",
        "        add_extra_convs:        (bool | str)     可以是 bool 或 str:\n",
        "                                                (bool)  bool 代表是否添加额外的层.(默认值: False)\n",
        "                                                        True:   在最顶层 feature map 上添加额外的卷积层,\n",
        "                                                                具体的模式需要 extra_convs_on_inputs 指定.\n",
        "                                                        False:  不添加额外的卷积层\n",
        "                                                (str)   str  需要指定 extra convs 的输入的 feature map 的来源\n",
        "                                                        'on_input':     最高层的 feature map 作为 extra 的输入\n",
        "                                                        'on_lateral':   最高层的 lateral 结果 作为 extra 的输入\n",
        "                                                        'on_output':    最高层的经过 conv 的 lateral 结果作为 extra 的输入\n",
        "        extra_convs_on_inputs:  (bool, deprecated)  True  等同于 `add_extra_convs='on_input'\n",
        "                                                    False 等同于 `add_extra_convs='on_output'\n",
        "                                                    默认值为True\n",
        "        relu_before_extra_convs:      (bool)     是否在 extra conv 前使用 relu. (默认值: False)\n",
        "        no_norm_on_lateral:           (bool)     是否对 lateral 使用 bn. (默认值: False)\n",
        "        conv_cfg:                     (dict)     构建 conv 层的 config 字典. (默认值: None)\n",
        "        norm_cfg:                     (dict)     构建  bn  层的 config 字典. (默认值: None)\n",
        "        act_cfg:                      (dict)     构建 activation  层的 config 字典. (默认值: None)\n",
        "        upsample_cfg:                 (dict)     构建 interpolate 层的 config 字典. (默认值: `dict(mode='nearest')`)                                                    \n",
        "        \n",
        "        Example:\n",
        "        >>> import torch\n",
        "        >>> in_channels = [2, 3, 5, 7]\n",
        "        >>> scales = [340, 170, 84, 43]\n",
        "        >>> inputs = [torch.rand(1, c, s, s)\n",
        "        ...           for c, s in zip(in_channels, scales)]\n",
        "        >>> self = FPN(in_channels, 11, len(in_channels)).eval()\n",
        "        >>> outputs = self.forward(inputs)\n",
        "        >>> for i in range(len(outputs)):\n",
        "        ...     print(f'outputs[{i}].shape = {outputs[i].shape}')\n",
        "        outputs[0].shape = torch.Size([1, 11, 340, 340])\n",
        "        outputs[1].shape = torch.Size([1, 11, 170, 170])\n",
        "        outputs[2].shape = torch.Size([1, 11, 84, 84])\n",
        "        outputs[3].shape = torch.Size([1, 11, 43, 43])\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 in_channels,\n",
        "                 out_channels,\n",
        "                 num_outs,\n",
        "                 start_level=0,\n",
        "                 end_level=-1,\n",
        "                 add_extra_convs=False,\n",
        "                 extra_convs_on_inputs=True,\n",
        "                 relu_before_extra_convs=False,\n",
        "                 no_norm_on_lateral=False,\n",
        "                 conv_cfg=None,\n",
        "                 norm_cfg=None,\n",
        "                 act_cfg=None,\n",
        "                 upsample_cfg=dict(mode='nearest')):\n",
        "        super(FPN, self).__init__()\n",
        "        assert isinstance(in_channels, list)\n",
        "        self.in_channels = in_channels          # [256, 512, 1024, 2048]\n",
        "        self.out_channels = out_channels        # 256\n",
        "        self.num_ins = len(in_channels)         # 4\n",
        "        self.num_outs = num_outs                # 5\n",
        "        self.relu_before_extra_convs = relu_before_extra_convs  # False\n",
        "        self.no_norm_on_lateral = no_norm_on_lateral            # False\n",
        "        self.fp16_enabled = False\n",
        "        self.upsample_cfg = upsample_cfg.copy()\n",
        "\n",
        "        # end_level 是对 backbone 输出的尺度中使用的最后一个尺度的索引\n",
        "        # 如果是 -1 表示使用 backbone 最后一个 feature map, 作为最终的索引.\n",
        "        if end_level == -1:\n",
        "            self.backbone_end_level = self.num_ins      #4\n",
        "            # 因为还有 extra conv 所以存在 num_outs > num_ins - start_level 的情况\n",
        "            assert num_outs >= self.num_ins - start_level\n",
        "        else:\n",
        "            # 如果 end_level < inputs, 说明不使用 backbone 全部的尺度, 并且不会提供额外的层.\n",
        "            self.backbone_end_level = end_level\n",
        "            assert end_level <= len(in_channels)\n",
        "            assert num_outs == end_level - start_level\n",
        "\n",
        "        self.start_level = start_level                      # 0\n",
        "        self.end_level = end_level                          # -1\n",
        "        self.add_extra_convs = add_extra_convs              # False\n",
        "        assert isinstance(add_extra_convs, (str, bool))\n",
        "        # add_extra_convs 可以是 bool 或 str\n",
        "        # 1. add_extra_convs 是 str\n",
        "        if isinstance(add_extra_convs, str):\n",
        "            # 确保 add_extra_convs 是 'on_input', 'on_lateral' 或 'on_output'\n",
        "            assert add_extra_convs in ('on_input', 'on_lateral', 'on_output')\n",
        "        # 2. add_extra_convs 是 bool, 需要看 extra_convs_on_inputs\n",
        "        elif add_extra_convs:\n",
        "            if extra_convs_on_inputs:\n",
        "                # For compatibility with previous release\n",
        "                # TODO: deprecate `extra_convs_on_inputs`\n",
        "                self.add_extra_convs = 'on_input'\n",
        "            else:\n",
        "                self.add_extra_convs = 'on_output'\n",
        "\n",
        "        self.lateral_convs = nn.ModuleList()\n",
        "        self.fpn_convs = nn.ModuleList()\n",
        "\n",
        "        # 构建Lateral conv 和 fpn conv \n",
        "        for i in range(self.start_level, self.backbone_end_level):\n",
        "            # 水平卷积(lateral conv): 1×1, C=256,\n",
        "            l_conv = ConvModule(\n",
        "                in_channels[i],\n",
        "                out_channels,\n",
        "                1,\n",
        "                conv_cfg=conv_cfg,\n",
        "                norm_cfg=norm_cfg if not self.no_norm_on_lateral else None,\n",
        "                act_cfg=act_cfg,\n",
        "                inplace=False)\n",
        "            # fpn 输出卷积: 3×3, C=256, P=1\n",
        "            fpn_conv = ConvModule(\n",
        "                out_channels,\n",
        "                out_channels,\n",
        "                3,\n",
        "                padding=1,\n",
        "                conv_cfg=conv_cfg,\n",
        "                norm_cfg=norm_cfg,\n",
        "                act_cfg=act_cfg,\n",
        "                inplace=False)\n",
        "            \n",
        "            self.lateral_convs.append(l_conv)\n",
        "            self.fpn_convs.append(fpn_conv)\n",
        "\n",
        "        # add extra conv layers (e.g., RetinaNet)\n",
        "        extra_levels = num_outs - self.backbone_end_level + self.start_level\n",
        "        # 只有 add_extra_convs 为 True 或 str 时才添加 extra_convs\n",
        "        if self.add_extra_convs and extra_levels >= 1:\n",
        "            for i in range(extra_levels):\n",
        "                if i == 0 and self.add_extra_convs == 'on_input':\n",
        "                    in_channels = self.in_channels[self.backbone_end_level - 1]\n",
        "                else:\n",
        "                    in_channels = out_channels\n",
        "                # extra conv 是3x3步长为2, padding为1的卷积\n",
        "                extra_fpn_conv = ConvModule(\n",
        "                    in_channels,\n",
        "                    out_channels,\n",
        "                    3,\n",
        "                    stride=2,\n",
        "                    padding=1,\n",
        "                    conv_cfg=conv_cfg,\n",
        "                    norm_cfg=norm_cfg,\n",
        "                    act_cfg=act_cfg,\n",
        "                    inplace=False)\n",
        "                self.fpn_convs.append(extra_fpn_conv)\n",
        "    # default init_weights for conv(msra) and norm in ConvModule\n",
        "    def init_weights(self):\n",
        "        \"\"\"Initialize the weights of FPN module.\"\"\"\n",
        "        # 使用xavier初始化卷积层\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                xavier_init(m, distribution='uniform')\n",
        "    \n",
        "    @auto_fp16()\n",
        "    def forward(self, inputs):\n",
        "        \"\"\"Forward function.\"\"\"\n",
        "        assert len(inputs) == len(self.in_channels)\n",
        "\n",
        "        # ====================== 进行水平计算(1x1卷积) ====================\n",
        "        laterals = [\n",
        "            lateral_conv(inputs[i + self.start_level])\n",
        "            for i, lateral_conv in enumerate(self.lateral_convs)\n",
        "        ]\n",
        "        # ==============================================================\n",
        "\n",
        "        # ========================== 计算 top-down =============================\n",
        "        used_backbone_levels = len(laterals)\n",
        "        # 自上至下将 laterals 里面的结果更新为经过 top-down 的结果.\n",
        "        for i in range(used_backbone_levels - 1, 0, -1):\n",
        "           # In some cases, fixing `scale factor` (e.g. 2) is preferred, but\n",
        "            #  it cannot co-exist with `size` in `F.interpolate`.\n",
        "            # 有 scale 的情况\n",
        "            if 'scale_factor' in self.upsample_cfg:\n",
        "                 # 因为range函数不包括右边的端点, 所以可以使用 i - 1\n",
        "                 laterals[i-1] += F.interpolate(laterals[i], **self.upsample_cfg)\n",
        "            # 没有 scale 的情况, 需要计算下层的 feature map 大小.\n",
        "            else:\n",
        "                 # 计算下层 feature map 大小\n",
        "                prev_shape = laterals[i - 1].shape[2:]\n",
        "                laterals[i - 1] += F.interpolate(\n",
        "                    laterals[i], size=prev_shape, **self.upsample_cfg)\n",
        "        # =====================================================================\n",
        "\n",
        "        # ========================== 计算输出的结果 =============================\n",
        "        # part 1: 计算所有 lateral 的输出的结果\n",
        "        outs = [\n",
        "            self.fpn_convs[i](laterals[i]) for i in range(used_backbone_levels)\n",
        "        ]\n",
        "        \n",
        "        # part 2: 添加 extra levels\n",
        "        if self.num_outs > len(outs):\n",
        "            # 使用 max pool 获得更高层的输出信息, 如: Faster R-CNN, Mask R-CNN (4 lateral + 1 max pool)\n",
        "            if not self.add_extra_convs:\n",
        "                for i in range(self.num_outs - used_backbone_levels):\n",
        "                    outs.append(F.max_pool2d(outs[-1], 1, stride=2))\n",
        "            # 添加额外的卷积层获得高层输出信息, 如: RetinaNet (3 lateral + 2 conv3x3 stride2)\n",
        "            else:\n",
        "                # 'on_input':   最高层的 feature map 作为 extra 的输入\n",
        "                if self.add_extra_convs == 'on_input':\n",
        "                    extra_source = inputs[self.backbone_end_level - 1]\n",
        "                # 'on_lateral': 最高层的 lateral 结果 作为 extra 的输入\n",
        "                elif self.add_extra_convs == 'on_lateral':\n",
        "                    extra_source = laterals[-1]\n",
        "                # 'on_output':  最高层的经过 conv 的 lateral 结果作为 extra 的输入\n",
        "                elif self.add_extra_convs == 'on_output':\n",
        "                    extra_source = outs[-1]\n",
        "                else:\n",
        "                    raise NotImplementedError\n",
        "                # 计算 input extra\n",
        "                outs.append(self.fpn_convs[used_backbone_levels](extra_source))\n",
        "                # 计算 extra\n",
        "                for i in range(used_backbone_levels + 1, self.num_outs):\n",
        "                    if self.relu_before_extra_convs:\n",
        "                        outs.append(self.fpn_convs[i](F.relu(outs[-1])))\n",
        "                    else:\n",
        "                        outs.append(self.fpn_convs[i](outs[-1]))\n",
        "        return tuple(outs)\n"
      ],
      "metadata": {
        "id": "710b6nBZbEiW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [MMDetection Faster R-CNN 源码详解（三)](https://zhuanlan.zhihu.com/p/184618997)\n",
        "\n",
        "在上一小节中，我们介绍了 neck 部分的源码。在接下来的两篇文章中，会详细的剖析 Faster R-CNN 中 rpn 部分的源码。在本篇文章主要讲解 RPN 中的重点概念和原理。\n",
        "\n",
        "\n",
        "## RPN（原理篇）\n",
        "\n",
        "Faster R-CNN 最突出的贡献就在于提出了 Region Proposal Network（RPN），使用了卷积神经网络生成候选区域，替代了传统的 Selective Search 方法，使网络在速度和精度上都有了显著的提升。我们会从如下五个方面详解 RPN 中的重点概念和原理：\n",
        "\n",
        "1. Anchor\n",
        "2. BBox 编码\n",
        "3. RPN 网络流程\n",
        "4. RPN 网络训练\n",
        "5. 生成候选区域\n",
        "\n",
        "## 一、Anchor\n",
        "对于RPN来说, 一个最重要的概念就是Anchor, 那么什么是Anchor? 将feature map上的一个个点,映射到哦原始图片上的一个像素点.以这个像素点为中心生成固定大小和长宽比的窗口, 那么这个窗口,就叫做anchor.\n",
        "\n",
        "我们看下面的图片，对原始图片（下图左侧）下采样后我们得到了feature map(下图右侧). 把 feature map 上的每个格点，映射到原图，我们就会得到锚点。也就是右侧每个相同颜色的格子映射到左侧的橘色的点。其中左侧橘色的点代表了原图的一个像素点，也就是我们得到的锚点。因为有padding, 所以锚点不会再左侧网格的中心, 而是再左侧每个网格左上角的第一个像素点.\n",
        "\n",
        "得到锚点后, 以每个锚点为中心, 对每个锚点生成固定大小和长宽比例的錨框(Anchor), 也就是左图中红紫蓝颜色的框. 那么当所有的各自都生成了錨框后, 錨框就会作为我们的先验, 遍布整张图片. (如下图左侧，为了方便可视化，我们将大小和长宽比设置为合适的大小）\n",
        "\n",
        "\n",
        "![](https://pic3.zhimg.com/80/v2-8efb16e525ab70cdac979755b7aaabbe_720w.jpg)\n",
        "图一：Anchor 的概念\n",
        "\n",
        "记scale为feature maps上每个各点映射到原图后再进行缩放的系数, 锚框真实的大小为 base_size × scale，记 ratio 为 anchor 的纵横比（H : W）。\n",
        "\n",
        "在 MMDetection 中，Faster R-CNN 结合了 FPN。所以每个尺度只设置了一个为 8 的 scale。ratio 为 {0.5, 1, 2}（纵横比 1 : 2、1 : 1、2 : 1）。如下图：\n",
        "\n",
        "![](https://pic3.zhimg.com/80/v2-6826119a8fe48a0e12f46cb684e7baba_720w.jpg)图二：结合 FPN 后的 Anchor 设置\n",
        "\n",
        "在 MMDetection 中，RPN 使用 AnchorGenerator 类生成 Anchor，下面是 AnchorGenerator 的设置。"
      ],
      "metadata": {
        "id": "FNzkZiKUcRC-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "anchor_generator=dict(\n",
        "    type='AnchorGenerator',\n",
        "    scales=[8],\n",
        "    ratios=[0.5, 1.0, 2.0],\n",
        "    straides=[4, 8, 16,32, 64]\n",
        "),"
      ],
      "metadata": {
        "id": "SMxkBOB0X8YU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "在 AnchorGenerator 中，构造函数会调用gen_base_anchors 生成各个尺度的每个格点的anchor(如图二), 形状为(尺度个数,K,4). grid_anchors 是生成所有尺度 anchor 的方法，生成的 anchor 的形状为（尺度个数，H × W × K，4）。因为在 collect_fn 中有额外的 padding 操作来保证一个 batch 的图像大小相同（不是数据预处理里面的 padding），所以需要 valid_flags 方法筛选出哪些 anchor 是在 padding 以内的，valid_flags 函数的输出的形状为（尺度个数，H × W × K）代表有效 anchor 的 mask。下面我们来开看一看源码："
      ],
      "metadata": {
        "id": "pQfK-4jMX6xP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import mmcv\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.nn.modules.utils import _pair\n",
        "\n",
        "from .builder import ANCHOR_GENERATORS\n",
        "\n",
        "\n",
        "@ANCHOR_GENERATORS.register_module()\n",
        "class AnchorGenerator(object):\n",
        "    \"\"\"2D anchor-base 模型的 anchor 生成器\n",
        "\n",
        "    Args:\n",
        "        strides:      (list[int] | list[tuple[int, int]])     各尺度 feature map 相对于原图的步长 (下采样率).\n",
        "        ratios:              (list[float])                    单个尺度中 anchor 的高宽比 (H : W) 的列表.\n",
        "        scales:              (list[int] | None)               单个尺度中 anchor 的缩放比率 (扩张率).\n",
        "                                                              不能与 `octave_base_scale` 和 `scales_per_octave` 一同设置.\n",
        "        base_sizes:          (list[int] | None)               各个尺度基础 anchor 大小的列表.\n",
        "                                                              如果没有给定, 将使用 strides 作为 base_sizes.\n",
        "                                                              如果 stride 非正方形, 则采用最短 stride.\n",
        "        scale_major:         (bool)            如果为 True 先列举完所有的 scales, 如果为 False, 先列举完所有的 ratios\n",
        "        octave_base_scale:   (int)             RetinaNet 中的 base scale\n",
        "        scales_per_octave:   (int)             每一个 grid 的 scale 个数. 在 RetinaNet 中会根据个数自动生成 scales\n",
        "                                               使用 `octave_base_scale` 和 `scales_per_octave` 时, scale 应该为 None.\n",
        "        centers:(list[tuple[float, float]] | None): anchor 的中心点, 默认为 None 代表使用 center_offset 来推断.\n",
        "        center_offset (float):                      一个小数, 代表 center 的偏移量.\n",
        "\n",
        "    Examples:\n",
        "        >>> from mmdet.core import AnchorGenerator\n",
        "        >>> self = AnchorGenerator([16], [1.], [1.], [9])\n",
        "        >>> all_anchors = self.grid_anchors([(2, 2)], device='cpu')\n",
        "        >>> print(all_anchors)\n",
        "        [tensor([[-4.5000, -4.5000,  4.5000,  4.5000],\n",
        "                [11.5000, -4.5000, 20.5000,  4.5000],\n",
        "                [-4.5000, 11.5000,  4.5000, 20.5000],\n",
        "                [11.5000, 11.5000, 20.5000, 20.5000]])]\n",
        "        >>> self = AnchorGenerator([16, 32], [1.], [1.], [9, 18])\n",
        "        >>> all_anchors = self.grid_anchors([(2, 2), (1, 1)], device='cpu')\n",
        "        >>> print(all_anchors)\n",
        "        [tensor([[-4.5000, -4.5000,  4.5000,  4.5000],\n",
        "                [11.5000, -4.5000, 20.5000,  4.5000],\n",
        "                [-4.5000, 11.5000,  4.5000, 20.5000],\n",
        "                [11.5000, 11.5000, 20.5000, 20.5000]]), \\\n",
        "        tensor([[-9., -9., 9., 9.]])]\n",
        "    \"\"\"\n",
        "\n",
        "     def __init__(self,\n",
        "                 strides,\n",
        "                 ratios,\n",
        "                 scales=None,\n",
        "                 base_sizes=None,\n",
        "                 scale_major=True,\n",
        "                 octave_base_scale=None,\n",
        "                 scales_per_octave=None,\n",
        "                 centers=None,\n",
        "                 center_offset=0.):\n",
        "        # faster_rcnn_fpn 配置:\n",
        "        # 对每一个 level 使用单尺度.\n",
        "        # strides: [4, 8, 16, 32, 64]\n",
        "        # ratios:  [0.5, 1.0, 2.0]\n",
        "        # scales:  [8]\n",
        "        # base_sizes: None\n",
        "        # scale_major:True\n",
        "        # octave_base_scale:None\n",
        "        # scales_per_octave:None\n",
        "        # centers: None\n",
        "        # center_offset: 0.0\n",
        "\n",
        "        # center 和 center_offset 只能使用一个\n",
        "\n",
        "        if center_offset != 0:\n",
        "            assert centers is None, 'center cannot be set when center_offset' \\\n",
        "                f'!=0, {centers} is given.'\n",
        "        # 确保 center_offset 是一个 0～1 的小数\n",
        "        if not (0 <= center_offset <= 1):\n",
        "            raise ValueError('center_offset should be in range [0, 1], '\n",
        "                             f'{center_offset} is given.')\n",
        "        if centers is not None:\n",
        "            assert len(centers) == len(strides), \\\n",
        "                'The number of strides should be the same as centers, got ' \\\n",
        "                f'{strides} and {centers}'\n",
        "\n",
        "        # _pair 函数:    如果是数转化为(数, 数) 的元祖, 如果是元祖不变.\n",
        "        self.strides = [_pair(stride) for stride in strides]\n",
        "        # 如果 base_sizes 为 None, 遍历所有尺度的 stride.\n",
        "        # 使用当前尺度的 stride 的长宽最小值作为当前尺度的 base_size\n",
        "        self.base_sizes = [min(stride) for stride in self.strides\n",
        "                           ] if base_sizes is None else base_sizes\n",
        "\n",
        "        assert len(self.base_sizes) == len(self.strides), \\\n",
        "            'The number of strides should be the same as base sizes, got ' \\\n",
        "            f'{self.strides} and {self.base_sizes}'\n",
        "\n",
        "        # 确保 scales 和 octave_base_scale 与 scales_per_octave 不能同时出现.\n",
        "        assert ((octave_base_scale is not None\n",
        "                and scales_per_octave is not None) ^ (scales is not None)), \\\n",
        "            'scales and octave_base_scale with scales_per_octave cannot' \\\n",
        "            ' be set at the same time'\n",
        "\n",
        "        # faster rcnn fpn: 单个尺度只有一个 scale --> [8]\n",
        "         if scales is not None:\n",
        "            self.scales = torch.Tensor(scales)\n",
        "        # retinanet: 单个尺度 scale 为 [2 ^ 0, 2 ^ (1/3), 2 ^ (2/3)]\n",
        "        elif octave_base_scale is not None and scales_per_octave is not None:\n",
        "            octave_scales = np.array(\n",
        "                [2**(i / scales_per_octave) for i in range(scales_per_octave)])\n",
        "            # octave_scales: 4\n",
        "            scales = octave_scales * octave_base_scale\n",
        "            self.scales = torch.Tensor(scales)\n",
        "        else:\n",
        "            raise ValueError('Either scales or octave_base_scale with '\n",
        "                             'scales_per_octave should be set')\n",
        "\n",
        "        self.octave_base_scale = octave_base_scale\n",
        "        self.scales_per_octave = scales_per_octave\n",
        "        self.ratios = torch.Tensor(ratios)\n",
        "        self.scale_major = scale_major\n",
        "        self.centers = centers\n",
        "        self.center_offset = center_offset\n",
        "        self.base_anchors = self.gen_base_anchors()\n",
        "\n",
        "    @property\n",
        "    def num_base_anchors(self):\n",
        "        \"\"\"list[int]: 每个尺度的 grid 生成 anchor 的数量\"\"\"\n",
        "        # eg. faster rcnn fpn [3, 3, 3, 3, 3]\n",
        "        return [base_anchors.size(0) for base_anchors in self.base_anchors]\n",
        "\n",
        "    @property\n",
        "    def num_levels(self):\n",
        "        \"\"\"int: 有多少个尺度.\"\"\"\n",
        "        # eg. faster rcnn fpn: 5\n",
        "        return len(self.strides)\n",
        "\n",
        "    def gen_base_anchors(self):\n",
        "        \"\"\"生成多个尺度的 base anchors. (base anchor 是每个 grid 生成的 anchor)\n",
        "\n",
        "        Returns:\n",
        "            list(torch.Tensor):  所有尺度的 base anchor 的列表,\n",
        "                                 其中每个尺度 base anchor 的形状为 (K, 4),\n",
        "        \"\"\"\n",
        "        # base_sizes    [4, 8, 16, 32, 64]\n",
        "        multi_level_base_anchors = []\n",
        "        # 遍历每个尺度\n",
        "        for i, base_size in enumerate(self.base_sizes):\n",
        "            center = None\n",
        "            if self.centers is not None:\n",
        "                center = self.centers[i]\n",
        "            multi_level_base_anchors.append(\n",
        "                self.gen_single_level_base_anchors(\n",
        "                    base_size,\n",
        "                    scales=self.scales,\n",
        "                    ratios=self.ratios,\n",
        "                    center=center))\n",
        "        return multi_level_base_anchors\n",
        "\n",
        "    def gen_single_level_base_anchors(self,\n",
        "                                      base_size,\n",
        "                                      scales,\n",
        "                                      ratios,\n",
        "                                      center=None):\n",
        "        \"\"\"生成单尺度 base_anchors\n",
        "\n",
        "        Args:\n",
        "            base_size:  (int | float):              基础 anchor 大小.\n",
        "            scales:     (torch.Tensor):             单尺度 anchor 的缩放, base_size * scale 为 anchor 真实大小.\n",
        "            ratios:     (torch.Tensor):             单尺度 anchor 的高宽比 (H : W)\n",
        "            center:     (tuple[float], optional):   单尺度的 base_anchor 的中心点, 默认为 None, 代表自动计算.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: 单尺度的 base_anchor\n",
        "        \"\"\"\n",
        "        # base_size 依次为 4, 8, 16, 32, 64, 代表基础 anchor 大小.\n",
        "        # scales:   [8]\n",
        "        w = base_size\n",
        "        h = base_size\n",
        "        # 如果 center 为 None, 根据 center_offset 自动计算中心点坐标.\n",
        "        if center is None:\n",
        "            x_center = self.center_offset * w   # 0.0\n",
        "            y_center = self.center_offset * h   # 0.0\n",
        "        # 如果 center 不是 None, 使用指定的 center.\n",
        "        else:\n",
        "            x_center, y_center = center\n",
        "\n",
        "        h_ratios = torch.sqrt(ratios)\n",
        "        w_ratios = 1 / h_ratios\n",
        "        # [n_ratios, n_scales]\n",
        "        # 展平后为 [scale1_ratio1, scale1_ratio2, ..., scale2_ratio1, scale2_ratio2...]\n",
        "        if self.scale_major:\n",
        "            ws = (w * w_ratios[:, None] * scales[None, :]).view(-1)\n",
        "            hs = (h * h_ratios[:, None] * scales[None, :]).view(-1)\n",
        "        # [n_scales, n_ratios]\n",
        "        # 展平后为 [ratio1_scale1, ratio1_scale2, ..., ratio2_scale1, ratio2_scale2...]\n",
        "        else:\n",
        "            ws = (w * scales[:, None] * w_ratios[None, :]).view(-1)\n",
        "            hs = (h * scales[:, None] * h_ratios[None, :]).view(-1)\n",
        "\n",
        "        # use float anchor and the anchor's center is aligned with the pixel center\n",
        "        base_anchors = [\n",
        "            x_center - 0.5 * ws, y_center - 0.5 * hs, x_center + 0.5 * ws,\n",
        "            y_center + 0.5 * hs\n",
        "        ]\n",
        "        base_anchors = torch.stack(base_anchors, dim=-1)\n",
        "        return base_anchors\n",
        "\n",
        "    def _meshgrid(self, x, y, row_major=True):\n",
        "        \"\"\"Generate mesh grid of x and y.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Grids of x dimension.\n",
        "            y (torch.Tensor): Grids of y dimension.\n",
        "            row_major (bool, optional): Whether to return y grids first.\n",
        "                Defaults to True.\n",
        "\n",
        "        Returns:\n",
        "            tuple[torch.Tensor]: The mesh grids of x and y.\n",
        "        \"\"\"\n",
        "        xx = x.repeat(len(y))\n",
        "        yy = y.view(-1, 1).repeat(1, len(x)).view(-1)\n",
        "        if row_major:\n",
        "            return xx, yy\n",
        "        else:\n",
        "            return yy, xx\n",
        "\n",
        "    def grid_anchors(self, featmap_sizes, device='cuda'):\n",
        "        \"\"\"生成多尺度的 anchor\n",
        "\n",
        "        Args:\n",
        "            featmap_sizes:  (list[tuple]):  各个尺度的 feature map 大小.\n",
        "            device:         (str):          anchor 存放的设备.\n",
        "\n",
        "        Return:\n",
        "            list[torch.Tensor]: 多尺度的 anchor, 每个尺度生成的 anchor 的形状为: [N, 4],\n",
        "                                其中 N = feature map 高 × feature map 宽 × 每个格点的 anchor 个数\n",
        "        \"\"\"\n",
        "        assert self.num_levels == len(featmap_sizes)\n",
        "        multi_level_anchors = []\n",
        "        for i in range(self.num_levels):\n",
        "            anchors = self.single_level_grid_anchors(\n",
        "                self.base_anchors[i].to(device),\n",
        "                featmap_sizes[i],\n",
        "                self.strides[i],\n",
        "                device=device)\n",
        "            multi_level_anchors.append(anchors)\n",
        "        return multi_level_anchors\n",
        "\n",
        "    def single_level_grid_anchors(self,\n",
        "                                  base_anchors,\n",
        "                                  featmap_size,\n",
        "                                  stride=(16, 16),\n",
        "                                  device='cuda'):\n",
        "        \"\"\"生成单个尺度的 anchor\n",
        "\n",
        "        Note:\n",
        "            此方法会被 ``self.grid_anchors`` 调用\n",
        "\n",
        "        Args:\n",
        "            base_anchors:   (torch.Tensor):         单尺度的 base_anchors\n",
        "            featmap_size:   (tuple[int]):           feature map 的大小\n",
        "            stride:         (tuple[int], optional): feature map 的 stride, 默认为 (16, 16)\n",
        "            device:         (str, optional):        存放 tensor 的设备, 默认为 'cuda'\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: 整个 feature map 生成的 anchor, 形状为 (N, 4)\n",
        "        \"\"\"\n",
        "        # 获取 feature map 的高和宽\n",
        "        feat_h, feat_w = featmap_size\n",
        "        # 生成锚点的 x, y 坐标范围\n",
        "        shift_x = torch.arange(0, feat_w, device=device) * stride[0]\n",
        "        shift_y = torch.arange(0, feat_h, device=device) * stride[1]\n",
        "        # 生成网格\n",
        "        shift_xx, shift_yy = self._meshgrid(shift_x, shift_y)\n",
        "        # 生成锚点\n",
        "        shifts = torch.stack([shift_xx, shift_yy, shift_xx, shift_yy], dim=-1)\n",
        "        shifts = shifts.type_as(base_anchors)\n",
        "\n",
        "        # 锚点加上偏移得到所有的 anchors\n",
        "        # (K, H × W, 4)\n",
        "        all_anchors = base_anchors[None, :, :] + shifts[:, None, :]\n",
        "        # (K × H × W, 4)\n",
        "        all_anchors = all_anchors.view(-1, 4)\n",
        "        # first A rows correspond to A anchors of (0, 0) in feature map,\n",
        "        # then (0, 1), (0, 2), ...\n",
        "        return all_anchors\n",
        "\n",
        "    def valid_flags(self, featmap_sizes, pad_shape, device='cuda'):\n",
        "        \"\"\"生成多个尺度的 valid flags\n",
        "            valid flags 标记在图片内的有效的 anchor, 因为图像有 padding 操作, anchor 可能在原始图片之外.\n",
        "\n",
        "        Args:\n",
        "            featmap_sizes:   (list(tuple)): 多尺度的 feature map 的大小\n",
        "            pad_shape:       (tuple):       填充后的图像的大小\n",
        "            device:          (str):         存放 tensor 的设备\n",
        "\n",
        "        Return:\n",
        "            list(torch.Tensor): 多尺度的 valid flags, 形状为 (n_levels, H × W × K)\n",
        "        \"\"\"\n",
        "        assert self.num_levels == len(featmap_sizes)\n",
        "        multi_level_flags = []\n",
        "        for i in range(self.num_levels):\n",
        "            anchor_stride = self.strides[i]\n",
        "            feat_h, feat_w = featmap_sizes[i]\n",
        "            # 经过 pad 的 h 和 w.\n",
        "            h, w = pad_shape[:2]\n",
        "            # 有效的宽高\n",
        "            valid_feat_h = min(int(np.ceil(h / anchor_stride[0])), feat_h)\n",
        "            valid_feat_w = min(int(np.ceil(w / anchor_stride[1])), feat_w)\n",
        "            flags = self.single_level_valid_flags((feat_h, feat_w),\n",
        "                                                  (valid_feat_h, valid_feat_w),\n",
        "                                                  self.num_base_anchors[i],\n",
        "                                                  device=device)\n",
        "            multi_level_flags.append(flags)\n",
        "        return multi_level_flags\n",
        "\n",
        "    def single_level_valid_flags(self,\n",
        "                                 featmap_size,\n",
        "                                 valid_size,\n",
        "                                 num_base_anchors,\n",
        "                                 device='cuda'):\n",
        "        \"\"\"Generate the valid flags of anchor in a single feature map.\n",
        "\n",
        "        Args:\n",
        "            featmap_size (tuple[int]): The size of feature maps.\n",
        "            valid_size (tuple[int]): The valid size of the feature maps.\n",
        "            num_base_anchors (int): The number of base anchors.\n",
        "            device (str, optional): Device where the flags will be put on.\n",
        "                Defaults to 'cuda'.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: The valid flags of each anchor in a single level\n",
        "                feature map.\n",
        "        \"\"\"\n",
        "        feat_h, feat_w = featmap_size\n",
        "        valid_h, valid_w = valid_size\n",
        "        assert valid_h <= feat_h and valid_w <= feat_w\n",
        "        valid_x = torch.zeros(feat_w, dtype=torch.bool, device=device)\n",
        "        valid_y = torch.zeros(feat_h, dtype=torch.bool, device=device)\n",
        "        valid_x[:valid_w] = 1\n",
        "        valid_y[:valid_h] = 1\n",
        "        valid_xx, valid_yy = self._meshgrid(valid_x, valid_y)\n",
        "        valid = valid_xx & valid_yy\n",
        "        # (H × W, K), K 为每个格点生成的 anchor 个数. --. (H × W × K)\n",
        "        valid = valid[:, None].expand(valid.size(0),\n",
        "                                      num_base_anchors).contiguous().view(-1)\n",
        "        return valid\n",
        "\n",
        "    def __repr__(self):\n",
        "        \"\"\"str: a string that describes the module\"\"\"\n",
        "        indent_str = '    '\n",
        "        repr_str = self.__class__.__name__ + '(\\n'\n",
        "        repr_str += f'{indent_str}strides={self.strides},\\n'\n",
        "        repr_str += f'{indent_str}ratios={self.ratios},\\n'\n",
        "        repr_str += f'{indent_str}scales={self.scales},\\n'\n",
        "        repr_str += f'{indent_str}base_sizes={self.base_sizes},\\n'\n",
        "        repr_str += f'{indent_str}scale_major={self.scale_major},\\n'\n",
        "        repr_str += f'{indent_str}octave_base_scale='\n",
        "        repr_str += f'{self.octave_base_scale},\\n'\n",
        "        repr_str += f'{indent_str}scales_per_octave='\n",
        "        repr_str += f'{self.scales_per_octave},\\n'\n",
        "        repr_str += f'{indent_str}num_levels={self.num_levels}\\n'\n",
        "        repr_str += f'{indent_str}centers={self.centers},\\n'\n",
        "        repr_str += f'{indent_str}center_offset={self.center_offset})'\n",
        "        return repr_str\n"
      ],
      "metadata": {
        "id": "tvx0HXzHZ01r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 二、BBox 编码\n",
        "\n",
        "让网络直接回归边框的坐标或者宽高比较困难，所以才有了 Anchor 的概念。在训练时，对 Anchor 进行编码。编码成 Anchor 与 Ground Truth 的中心点偏移和宽高的修正量，让网络学习。这样网络学习到的实际上是如何对 Anchor 进行修正。在测试时，将网络输出的偏移量解码成 BBox 的坐标即可。\n",
        "\n",
        "那么如何将 Anchor 编码为修正量呢？\n",
        "\n",
        "记 t 为训练目标，x, y 代表 bbox 的中心坐标，w, h 代表 bbox 的宽和高。不带下标的代表是 ground truth，带下标 a 的代表的是 anchor。编码公式如下：\n",
        "\n",
        "$t_x = (x-x_0)/w_a$ $\\space\\space\\space\\space\\space\\space\\space\\space$  $t_y = (y-y_0/w_a$  (1)\n",
        "\n",
        "$t_w = log(w/w_a)$ $\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space$  $t_h = log(h/h_a$  (2)\n",
        "\n",
        "\n",
        "记 $t^*$为网络的预测值，由（1）（2）可推断出我们会得到如下的结果：\n",
        "\n",
        "$t^*_x = (x^*-x_0)/w_a$ $\\space\\space\\space\\space\\space\\space\\space\\space$  $t^*_y = (y^*-y_0/w_a$  (3)\n",
        "\n",
        "$t^*_w = log(w^*/w_a)$ $\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space$  $t_h = log(h^*/h_a$  (4)\n",
        "\n",
        "将（3）（4）式变形，可以得到解码公式如下：\n",
        "\n",
        "$x^* = x_a + w_a + t^*_x $ $\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space$ $y^* = y_a + h_at^*_y$  (5)\n",
        "\n",
        "$w^* = w_ae^{t^*_w} $ $\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space$ $h^* = h_ae^{t^*_h} $ (6)\n",
        "\n",
        "在 RPN 中使用 DeltaXYWHBBoxCoder 编码 bbox，具体设置如下。"
      ],
      "metadata": {
        "id": "4Coc3V_bcNfN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    bbox_coder=dict(\n",
        "            type='DeltaXYWHBBoxCoder',\n",
        "            target_means=[.0, .0, .0, .0],\n",
        "            target_stds=[1.0, 1.0, 1.0, 1.0]),\n"
      ],
      "metadata": {
        "id": "rR9nuhG4gn0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "源码上，我们先来看一下 encode 的核心代码，encode 的公式是上面的（1）和（2），代码如下："
      ],
      "metadata": {
        "id": "H0y6pDRUgzMU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    def bbox2delta(proposals, gt, means=(0., 0., 0., 0.), stds=(1., 1., 1., 1.)):\n",
        "        \"\"\"生成 bbox 与 gt 的修正量\n",
        "\n",
        "        Args:\n",
        "            proposals:      (Tensor):           需要转换的 bbox, 形状为 (N, ..., 4)\n",
        "            gt:             (Tensor):           Gt bboxes, 形状为 (N, ..., 4)\n",
        "            means:          (Sequence[float]):  对坐标标准化的均值\n",
        "            stds:           (Sequence[float]):  对坐标标准化的方差\n",
        "\n",
        "        Returns:\n",
        "            Tensor: (dx, dy, dw, dh) 形式的偏移\n",
        "        \"\"\"\n",
        "        assert proposals.size() == gt.size()\n",
        "\n",
        "        proposals = proposals.float()\n",
        "        gt = gt.float()\n",
        "\n",
        "        # bbox 的中点坐标\n",
        "        px = (proposals[..., 0] + proposals[..., 2]) * 0.5\n",
        "        py = (proposals[..., 1] + proposals[..., 3]) * 0.5\n",
        "        # box 的宽高\n",
        "        pw = proposals[..., 2] - proposals[..., 0]\n",
        "        ph = proposals[..., 3] - proposals[..., 1]\n",
        "\n",
        "        # ground truth 的中点坐标\n",
        "        gx = (gt[..., 0] + gt[..., 2]) * 0.5\n",
        "        gy = (gt[..., 1] + gt[..., 3]) * 0.5\n",
        "        # ground truth 的宽高\n",
        "        gw = gt[..., 2] - gt[..., 0]\n",
        "        gh = gt[..., 3] - gt[..., 1]\n",
        "\n",
        "        # 需要预测的 x\n",
        "        dx = (gx - px) / pw\n",
        "        # 需要预测的 y\n",
        "        dy = (gy - py) / ph\n",
        "        # 需要预测的 w\n",
        "        dw = torch.log(gw / pw)\n",
        "        # 需要预测的 h\n",
        "        dh = torch.log(gh / ph)\n",
        "        deltas = torch.stack([dx, dy, dw, dh], dim=-1)\n",
        "\n",
        "        means = deltas.new_tensor(means).unsqueeze(0)\n",
        "        stds = deltas.new_tensor(stds).unsqueeze(0)\n",
        "        deltas = deltas.sub_(means).div_(stds)\n",
        "\n",
        "        return deltas"
      ],
      "metadata": {
        "id": "kKW75ZGggz6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "再来看一下 decode 的核心代码，decode 对应的公式是上面的（5）和（6）。注意：如果提供 max_shape，decode 会对超出 max_shape 的 bbox 裁剪，可以用 max_shape 来裁剪超出图片大小的 anchor。"
      ],
      "metadata": {
        "id": "vaFKp4MWhW5P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    def delta2bbox(rois,\n",
        "               deltas,\n",
        "               means=(0., 0., 0., 0.),\n",
        "               stds=(1., 1., 1., 1.),\n",
        "               max_shape=None,\n",
        "               wh_ratio_clip=16 / 1000):\n",
        "        \"\"\"将 (dx, dy, dw, dh) 解码为 (x1, y1, x2, y2)\n",
        "\n",
        "        Args:\n",
        "            rois:           (Tensor):           需要转换的 bbox, 形状为 (N, 4)\n",
        "            deltas:         (Tensor):           bbox 的修正量, 形状为 (N, 4 * num_classes). \n",
        "                                                其中 N = num_anchors * W * H\n",
        "            means:          (Sequence[float]):  对坐标标准化的均值\n",
        "            stds:           (Sequence[float]):  对坐标标准化的方差\n",
        "            max_shape:      (tuple[int, int]):  bbox 最大的大小(图片大小), 用于裁剪超出图片的 bbox\n",
        "            wh_ratio_clip:  (float):            bbox 最大的缩放比例\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Boxes with shape (N, 4), where columns represent\n",
        "                tl_x, tl_y, br_x, br_y.\n",
        "        \"\"\"\n",
        "        means = deltas.new_tensor(means).repeat(1, deltas.size(1) // 4)\n",
        "        stds = deltas.new_tensor(stds).repeat(1, deltas.size(1) // 4)\n",
        "        # 还原没有 norm 的 box\n",
        "        denorm_deltas = deltas * stds + means\n",
        "        # 获得 dx, dy, dw, dh\n",
        "        dx = denorm_deltas[:, 0::4]\n",
        "        dy = denorm_deltas[:, 1::4]\n",
        "        dw = denorm_deltas[:, 2::4]\n",
        "        dh = denorm_deltas[:, 3::4]\n",
        "        # 将 |ratio| 限定到 max_ratio 以内\n",
        "        max_ratio = np.abs(np.log(wh_ratio_clip))\n",
        "        dw = dw.clamp(min=-max_ratio, max=max_ratio)\n",
        "        dh = dh.clamp(min=-max_ratio, max=max_ratio)\n",
        "        # ============= 预测的 roi 转化为：中心点+宽高 的形式。===================\n",
        "        px = ((rois[:, 0] + rois[:, 2]) * 0.5).unsqueeze(1).expand_as(dx)\n",
        "        py = ((rois[:, 1] + rois[:, 3]) * 0.5).unsqueeze(1).expand_as(dy)\n",
        "        # Compute width/height of each roi\n",
        "        pw = (rois[:, 2] - rois[:, 0]).unsqueeze(1).expand_as(dw)\n",
        "        ph = (rois[:, 3] - rois[:, 1]).unsqueeze(1).expand_as(dh)\n",
        "        # ===================================================================\n",
        "\n",
        "        # =============== 计算经过网络偏移后的 roi 的中心点和宽高。================\n",
        "        gw = pw * dw.exp()\n",
        "        gh = ph * dh.exp()\n",
        "        # Use network energy to shift the center of each roi\n",
        "        gx = px + pw * dx\n",
        "        gy = py + ph * dy\n",
        "        # ===================================================================\n",
        "\n",
        "        # 中心点+宽高  ==> 左上角坐标+右下角坐标。\n",
        "        x1 = gx - gw * 0.5\n",
        "        y1 = gy - gh * 0.5\n",
        "        x2 = gx + gw * 0.5\n",
        "        y2 = gy + gh * 0.5\n",
        "\n",
        "        # 如果有最大的大小，裁剪经过偏移后的坐标\n",
        "        if max_shape is not None:\n",
        "            x1 = x1.clamp(min=0, max=max_shape[1])\n",
        "            y1 = y1.clamp(min=0, max=max_shape[0])\n",
        "            x2 = x2.clamp(min=0, max=max_shape[1])\n",
        "            y2 = y2.clamp(min=0, max=max_shape[0])\n",
        "        bboxes = torch.stack([x1, y1, x2, y2], dim=-1).view_as(deltas)\n",
        "        return bboxes"
      ],
      "metadata": {
        "id": "Ue96IgCXhXjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DeltaXYWHBBoxCoder 类调用了上述两个方法。并提供了 encode 和 decode 方法，分别用来编码和解码 bbox。"
      ],
      "metadata": {
        "id": "YvG3qJFEhs6O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    import numpy as np\n",
        "    import torch\n",
        "\n",
        "    from ..builder import BBOX_CODERS\n",
        "    from .base_bbox_coder import BaseBBoxCoder\n",
        "\n",
        "\n",
        "    @BBOX_CODERS.register_module()\n",
        "    class DeltaXYWHBBoxCoder(BaseBBoxCoder):\n",
        "        \"\"\"Delta XYWH BBox 编码器.\n",
        "\n",
        "        encode 将 (x1, y1, x2, y2) 编码为 (dx, dy, dw, dh)\n",
        "        decode 将 (dx, dy, dw, dh) 解码为 (x1, y1, x2, y2)\n",
        "\n",
        "        Args:\n",
        "            target_means:   (Sequence[float]): 对坐标标准化的均值\n",
        "            target_stds:    (Sequence[float]): 对坐标标准化的方差\n",
        "        \"\"\"\n",
        "\n",
        "        def __init__(self,\n",
        "                    target_means=(0., 0., 0., 0.),\n",
        "                    target_stds=(1., 1., 1., 1.)):\n",
        "            super(BaseBBoxCoder, self).__init__()\n",
        "            self.means = target_means\n",
        "            self.stds = target_stds\n",
        "\n",
        "        def encode(self, bboxes, gt_bboxes):\n",
        "            \"\"\"将 (x1, y1, x2, y2) 编码为 (dx, dy, dw, dh)\n",
        "\n",
        "            Args:\n",
        "                bboxes:     (torch.Tensor): 源 bboxes, 例如: object proposals.\n",
        "                gt_bboxes:  (torch.Tensor): 目标 bboxes, 例如: ground-truth boxes.\n",
        "\n",
        "            Returns:\n",
        "                torch.Tensor: (dx, dy, dw, dh) 形式的偏移\n",
        "            \"\"\"\n",
        "\n",
        "            assert bboxes.size(0) == gt_bboxes.size(0)\n",
        "            assert bboxes.size(-1) == gt_bboxes.size(-1) == 4\n",
        "            encoded_bboxes = bbox2delta(bboxes, gt_bboxes, self.means, self.stds)\n",
        "            return encoded_bboxes\n",
        "\n",
        "        def decode(self,\n",
        "                bboxes,\n",
        "                pred_bboxes,\n",
        "                max_shape=None,\n",
        "                wh_ratio_clip=16 / 1000):\n",
        "            \"\"\"将 (dx, dy, dw, dh) 解码为 (x1, y1, x2, y2)\n",
        "\n",
        "            Args:\n",
        "                bboxes:         (torch.Tensor):         基准 boxes.\n",
        "                pred_bboxes:    (torch.Tensor):         预测的 bboxes\n",
        "                max_shape:      (tuple[int], optional): bbox 最大的大小(图片大小), 用于裁剪超出图片的 bbox\n",
        "                wh_ratio_clip:  (float, optional):      The allowed ratio between\n",
        "                    width and height.\n",
        "\n",
        "            Returns:\n",
        "                torch.Tensor: (x1, y1, x2, y2) 形式的坐标\n",
        "            \"\"\"\n",
        "\n",
        "            assert pred_bboxes.size(0) == bboxes.size(0)\n",
        "            decoded_bboxes = delta2bbox(bboxes, pred_bboxes, self.means, self.stds,\n",
        "                                        max_shape, wh_ratio_clip)\n",
        "\n",
        "            return decoded_bboxes"
      ],
      "metadata": {
        "id": "bxz3ExOPhtjp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 三、RPN 网络流程\n",
        "\n",
        "MMDetection 的 Faster R-CNN 结合了 FPN。在 RPN 中我们会拿到 P2 ～ P6，总共 5 个尺度的特征图，通道数都为 256。对每个特征图，先使用 3×3 的卷积提取特征，然后再使用两个并列的 1×1 的卷积，生成前景与背景的概率预测和边框的修正量。注意：所有的特征图共享相同的卷积（因为所有的特征图的通道数相同，可以共享）。\n",
        "\n",
        "设每个feature map 每个各点生成的anchor个数为K, 那么分类分支的输出通道数为 K(使用sigmoid为K, 如果使用softmax 为2K) 代表类别为前景或背景的置信度. 回归分支的输出通道数为: 4K, 代表bbox的中心点坐标偏移以及宽高的修正量.\n",
        "\n",
        "每个尺度经过相同的卷积后会得到置信度与修正量的输出值。对于输出值：\n",
        "1. 对每个尺度的输出值: 计算损失\n",
        "2. 整合所有尺度的输出值: 提供候选区域\n",
        "\n",
        "\n",
        "![](https://pic2.zhimg.com/80/v2-d2fc185742120b0e5e4ca82b2942597d_720w.jpg)\n",
        "\n",
        "我们先来看一下配置文件中的内容，下面是所有关于 rpn 的配置。其中 rpn_head 是构建 RPN 网络的主要的配置。又因为在训练时需要分配正负样本并采样，在测试时不需要分配正负样本或采样，且筛选候选区域的设置不同。所以有两个配置，分别是 train_cfg（训练时的配置）和 test_cfg（测试时的配置），分别指定训练和测试不同的设置。"
      ],
      "metadata": {
        "id": "KAYryJOZh0ZB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    # RPNHead 的配置\n",
        "    rpn_head=dict(\n",
        "            type='RPNHead',\n",
        "            in_channels=256,\n",
        "            feat_channels=256,\n",
        "            anchor_generator=dict(\n",
        "                type='AnchorGenerator',\n",
        "                scales=[8],\n",
        "                ratios=[0.5, 1.0, 2.0],\n",
        "                strides=[4, 8, 16, 32, 64]),\n",
        "            bbox_coder=dict(\n",
        "                type='DeltaXYWHBBoxCoder',\n",
        "                target_means=[.0, .0, .0, .0],\n",
        "                target_stds=[1.0, 1.0, 1.0, 1.0]),\n",
        "            loss_cls=dict(\n",
        "                type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
        "            loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\n",
        "\n",
        "    # 训练时 rpn 的配置\n",
        "    train_cfg = dict(\n",
        "        rpn=dict(\n",
        "            assigner=dict(\n",
        "                type='MaxIoUAssigner',\n",
        "                pos_iou_thr=0.7,\n",
        "                neg_iou_thr=0.3,\n",
        "                min_pos_iou=0.3,\n",
        "                match_low_quality=True,\n",
        "                ignore_iof_thr=-1),\n",
        "            sampler=dict(\n",
        "                type='RandomSampler',\n",
        "                num=256,\n",
        "                pos_fraction=0.5,\n",
        "                neg_pos_ub=-1,\n",
        "                add_gt_as_proposals=False),\n",
        "            allowed_border=-1,\n",
        "            pos_weight=-1,\n",
        "            debug=False),\n",
        "        rpn_proposal=dict(\n",
        "            nms_across_levels=False,\n",
        "            nms_pre=2000,\n",
        "            nms_post=1000,\n",
        "            max_num=1000,\n",
        "            nms_thr=0.7,\n",
        "            min_bbox_size=0),\n",
        "\n",
        "    # 测试时 rpn 的配置\n",
        "    test_cfg = dict(\n",
        "        rpn=dict(\n",
        "            nms_across_levels=False,\n",
        "            nms_pre=1000,\n",
        "            nms_post=1000,\n",
        "            max_num=1000,\n",
        "            nms_thr=0.7,\n",
        "            min_bbox_size=0),"
      ],
      "metadata": {
        "id": "V11JigPNl1ai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "此部分的具体代码，我们会在下篇文章中具体讲解。在本篇文章中只会讲解大体的思路\n",
        "\n",
        "## 四、RPN 网络训练\n",
        "那么 RPN 网络如何训练呢？既然是训练一定要有训练的样本，那么 RPN 训练的数据如何定义呢？我们一起来看一看。\n",
        "\n",
        "（一）数据准备\n",
        "对 RPN 来说会生成很多个 anchor，但是我们不会全拿过来训练。原因就是正负样本的不均衡。一整张图片的 gt bbox 可能就几个，但是 anchor 的数量实在是太多了。为什么样本不均衡就不能直接拿来训练呢？我们举个例子：假设有一个数据集，有 100 张图片，其中 99 张是猫，1 张是狗。那么网络只用对任何图片都预测为猫就可以得到 99% 的准确率。这样显然不符合实际的要求。所以对于正负样本的数量不能差距太大。\n",
        "\n",
        "所以对于 RPN 的数据（Anchor）准备，我们需要两个步骤：\n",
        "\n",
        "分配正负样本\n",
        "采样并平衡正负样本的数量（在 RPN 中为 1 : 1）\n",
        "这两个操作也刚好对应了MMDetection 中的 assigner 和 sampler。\n",
        "\n",
        "\n",
        "\n",
        "1. 分配正负样本\n",
        "\n",
        "分配正负样本有四个步骤，步骤如下。\n",
        "\n",
        "（1）初始化时将每个 anchor 的 mask 设置为 -1，表示此 anchor 既不是正样本也不是负样本\n",
        "\n",
        "（2）将 anchor 与所有 gt 的最大的 iou ＜ neg_iou_thr（0.3）的 anchor 的 mask 设置为 0，表示负样本（背景）\n",
        "\n",
        "（3）将 anchor 与所有 gt 的最大的 iou ≥ pos_iou_thr（0.7）的 anchor 的 mask 设置为当前 gt 的类别（前景），表示正样本\n",
        "\n",
        "（4）在（3）中的设置可能会导致有一些 gt 没有分配 anchor，所以对每个 gt 找出与它 iou 最大的 anchor 如果此 iou ≥ min_pos_iou（0.3），将此 anchor 设置为正样本。\n",
        "\n",
        "\n",
        "\n",
        "配置如下："
      ],
      "metadata": {
        "id": "2l0gzreCm3Pw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assigner=dict(\n",
        "            type='MaxIoUAssigner',\n",
        "            pos_iou_thr=0.7,\n",
        "            neg_iou_thr=0.3,\n",
        "            min_pos_iou=0.3,\n",
        "            match_low_quality=True,\n",
        "            ignore_iof_thr=-1),"
      ],
      "metadata": {
        "id": "s96e-C_irlot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "在 RPN 中，使用 MaxIoUAssigner，完成正负样本的分配，具体源码如下："
      ],
      "metadata": {
        "id": "mjFZEjEQrkSf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "from ..builder import BBOX_ASSIGNERS\n",
        "from ..iou_calculators import build_iou_calculator\n",
        "from .assign_result import AssignResult\n",
        "from .base_assigner import BaseAssigner\n",
        "\n",
        "\n",
        "@BBOX_ASSIGNERS.register_module()\n",
        "class MaxIoUAssigner(BaseAssigner):\n",
        "    \"\"\"根据 IOU 分配正负样本.\n",
        "\n",
        "    - -1:         代表忽略, 表示既不是正样本也不是负样本.\n",
        "    - 非负整数:    代表匹配到的类别, 可以是正样本或负样本的类别.\n",
        "\n",
        "    Args:\n",
        "        pos_iou_thr:            (float):            正样本的 IOU 阈值\n",
        "        neg_iou_thr:            (float or tuple):   负样本的 IoU 阈值\n",
        "        min_pos_iou:            (float):            分配正样本时最小的 IOU\n",
        "        gt_max_assign_all:      (bool):             是否分配所有与 gt 的 IOU 最大的 bbox 为正样本(满足 min_pos_iou).\n",
        "        ignore_iof_thr:         (float):            忽略 bboxes 的 IoF 阈值（如果 `gt_bboxes_ignore` 已指定）\n",
        "                                                    负值表示不忽略任何 bboxes。\n",
        "        ignore_wrt_candidates:  (bool):             是否计算 `bboxes` 和 `gt bboxes_ignore` 的 iof.\n",
        "        match_low_quality:      (bool):             是否对每个 gt 找出与它 iou 最大的 anchor.\n",
        "                                                    如果此 iou ≥ min_pos_iou（0.3）, 将此 anchor 设置为正样本.\n",
        "                                                    此操作一般不会用在第二阶段, 如 roi_head 中.\n",
        "        gpu_assign_thr:         (int):              GPU 的 GT 个数的上界分配. 当 gt 的数量超过此阈值时, 将分配在 CPU 设备上.\n",
        "                                                    负值表示不在 CPU 上分配.\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 pos_iou_thr,\n",
        "                 neg_iou_thr,\n",
        "                 min_pos_iou=.0,\n",
        "                 gt_max_assign_all=True,\n",
        "                 ignore_iof_thr=-1,\n",
        "                 ignore_wrt_candidates=True,\n",
        "                 match_low_quality=True,\n",
        "                 gpu_assign_thr=-1,\n",
        "                 iou_calculator=dict(type='BboxOverlaps2D')):\n",
        "        self.pos_iou_thr = pos_iou_thr\n",
        "        self.neg_iou_thr = neg_iou_thr\n",
        "        self.min_pos_iou = min_pos_iou\n",
        "        self.gt_max_assign_all = gt_max_assign_all\n",
        "        self.ignore_iof_thr = ignore_iof_thr\n",
        "        self.ignore_wrt_candidates = ignore_wrt_candidates\n",
        "        self.gpu_assign_thr = gpu_assign_thr\n",
        "        self.match_low_quality = match_low_quality\n",
        "        self.iou_calculator = build_iou_calculator(iou_calculator)\n",
        "\n",
        "    def assign(self, bboxes, gt_bboxes, gt_bboxes_ignore=None, gt_labels=None):\n",
        "        \"\"\"给 bbox 分配 gt\n",
        "\n",
        "        Args:\n",
        "            bboxes:             (Tensor):               需要分配的 bboxes, 形状为(n, 4).\n",
        "            gt_bboxes:          (Tensor):               Ground truth boxes, 形状为 (k, 4).\n",
        "            gt_bboxes_ignore:   (Tensor, optional):     被标记为忽略的 Ground truth bboxes.\n",
        "            gt_labels:          (Tensor, optional):     gt_bboxes 的标签, 形状为 (k, ).\n",
        "\n",
        "        Returns:\n",
        "            :obj:`AssignResult`: 分配的结果\n",
        "\n",
        "        Example:\n",
        "            >>> self = MaxIoUAssigner(0.5, 0.5)\n",
        "            >>> bboxes = torch.Tensor([[0, 0, 10, 10], [10, 10, 20, 20]])\n",
        "            >>> gt_bboxes = torch.Tensor([[0, 0, 10, 9]])\n",
        "            >>> assign_result = self.assign(bboxes, gt_bboxes)\n",
        "            >>> expected_gt_inds = torch.LongTensor([1, 0])\n",
        "            >>> assert torch.all(assign_result.gt_inds == expected_gt_inds)\n",
        "        \"\"\"\n",
        "        # 如果当前的 gt box 的数量大于 gpu 分配数量的阈值, 就使用 cpu 分配.\n",
        "        assign_on_cpu = True if (self.gpu_assign_thr > 0) and (\n",
        "            gt_bboxes.shape[0] > self.gpu_assign_thr) else False\n",
        "        \n",
        "        if assign_on_cpu:\n",
        "            device = bboxes.device\n",
        "            bboxes = bboxes.cpu()\n",
        "            gt_bboxes = gt_bboxes.cpu()\n",
        "            if gt_bboxes_ignore is not None:\n",
        "                gt_bboxes_ignore = gt_bboxes_ignore.cpu()\n",
        "            if gt_labels is not None:\n",
        "                gt_labels = gt_labels.cpu()\n",
        "        # 计算 gt box 和 bbox 的交并比, 形状为 (n_gts, n_bboxes)\n",
        "        overlaps = self.iou_calculator(gt_bboxes, bboxes)\n",
        "\n",
        "        if (self.ignore_iof_thr > 0 and gt_bboxes_ignore is not None\n",
        "                and gt_bboxes_ignore.numel() > 0 and bboxes.numel() > 0):\n",
        "            if self.ignore_wrt_candidates:\n",
        "                ignore_overlaps = self.iou_calculator(\n",
        "                    bboxes, gt_bboxes_ignore, mode='iof')\n",
        "                ignore_max_overlaps, _ = ignore_overlaps.max(dim=1)\n",
        "            else:\n",
        "                ignore_overlaps = self.iou_calculator(\n",
        "                    gt_bboxes_ignore, bboxes, mode='iof')\n",
        "                ignore_max_overlaps, _ = ignore_overlaps.max(dim=0)\n",
        "            overlaps[:, ignore_max_overlaps > self.ignore_iof_thr] = -1\n",
        "        # 分配样本\n",
        "        assign_result = self.assign_wrt_overlaps(overlaps, gt_labels)\n",
        "        if assign_on_cpu:\n",
        "            assign_result.gt_inds = assign_result.gt_inds.to(device)\n",
        "            assign_result.max_overlaps = assign_result.max_overlaps.to(device)\n",
        "            if assign_result.labels is not None:\n",
        "                assign_result.labels = assign_result.labels.to(device)\n",
        "        return assign_result\n",
        "\n",
        "    def assign_wrt_overlaps(self, overlaps, gt_labels=None):\n",
        "        \"\"\"根据 overlaps 对 bbox 分配正负样本.\n",
        "\n",
        "        Args:\n",
        "            overlaps:   (Tensor):           k 个 gt_bboxes 和 n 个 bboxes 的 Overlaps,\n",
        "                                            形状为 (k, n).\n",
        "            gt_labels:  (Tensor, optional): k 个 gt_bboxes 的 labels, 形状为 (k,).\n",
        "\n",
        "        Returns:\n",
        "            :obj:`AssignResult`: 分配后结果\n",
        "        \"\"\"\n",
        "        # 获取 gt 的数量和 bbox 的数量.\n",
        "        num_gts, num_bboxes = overlaps.size(0), overlaps.size(1)\n",
        "\n",
        "        # 1. 给所有的 box 初始化为 -1 代表全为负样本. (num_bboxes,)\n",
        "        assigned_gt_inds = overlaps.new_full((num_bboxes, ),\n",
        "                                             -1,\n",
        "                                             dtype=torch.long)\n",
        "        # 如果 gt 的数量或 bbox 的数量为 0, 直接返回.\n",
        "        if num_gts == 0 or num_bboxes == 0:\n",
        "            # No ground truth or boxes, return empty assignment\n",
        "            max_overlaps = overlaps.new_zeros((num_bboxes, ))\n",
        "            if num_gts == 0:\n",
        "                # No truth, assign everything to background\n",
        "                assigned_gt_inds[:] = 0\n",
        "            if gt_labels is None:\n",
        "                assigned_labels = None\n",
        "            else:\n",
        "                assigned_labels = overlaps.new_full((num_bboxes, ),\n",
        "                                                    -1,\n",
        "                                                    dtype=torch.long)\n",
        "            return AssignResult(\n",
        "                num_gts,\n",
        "                assigned_gt_inds,\n",
        "                max_overlaps,\n",
        "                labels=assigned_labels)\n",
        "\n",
        "        # 对于每个 bbox 找出和它 IOU 最大的 GT box\n",
        "        max_overlaps, argmax_overlaps = overlaps.max(dim=0)\n",
        "        # 对于每个 gt, 找出和他 IOU 最大的 bbox\n",
        "        gt_max_overlaps, gt_argmax_overlaps = overlaps.max(dim=1)\n",
        "\n",
        "        # 2. 最大 iou < neg_iou_thr 的设置为负样本, mask 设置为 0\n",
        "        if isinstance(self.neg_iou_thr, float):\n",
        "            assigned_gt_inds[(max_overlaps >= 0)\n",
        "                             & (max_overlaps < self.neg_iou_thr)] = 0\n",
        "        elif isinstance(self.neg_iou_thr, tuple):\n",
        "            assert len(self.neg_iou_thr) == 2\n",
        "            assigned_gt_inds[(max_overlaps >= self.neg_iou_thr[0])\n",
        "                             & (max_overlaps < self.neg_iou_thr[1])] = 0\n",
        "\n",
        "        # 3. 最大 iou ≥ pos_iou_thr 的设置为正样本, mask 设置为对应类别标签\n",
        "        pos_inds = max_overlaps >= self.pos_iou_thr\n",
        "        assigned_gt_inds[pos_inds] = argmax_overlaps[pos_inds] + 1\n",
        "\n",
        "        # 4. 对每个 gt 找出与它 iou 最大的 bbox 如果此 iou ≥ min_pos_iou, 将此 bbox 设置为正样本\n",
        "        if self.match_low_quality:\n",
        "            # For example, if bbox A has 0.9 and 0.8 iou with GT bbox 1 & 2,\n",
        "            # bbox 1 will be assigned as the best target for bbox A in step 3.\n",
        "            # However, if GT bbox 2's gt_argmax_overlaps = A, bbox A's\n",
        "            # assigned_gt_inds will be overwritten to be bbox B.\n",
        "            # This might be the reason that it is not used in ROI Heads.\n",
        "            for i in range(num_gts):\n",
        "                if gt_max_overlaps[i] >= self.min_pos_iou:\n",
        "                    if self.gt_max_assign_all:\n",
        "                        max_iou_inds = overlaps[i, :] == gt_max_overlaps[i]\n",
        "                        assigned_gt_inds[max_iou_inds] = i + 1\n",
        "                    else:\n",
        "                        assigned_gt_inds[gt_argmax_overlaps[i]] = i + 1\n",
        "\n",
        "        if gt_labels is not None:\n",
        "            assigned_labels = assigned_gt_inds.new_full((num_bboxes, ), -1)\n",
        "            pos_inds = torch.nonzero(\n",
        "                assigned_gt_inds > 0, as_tuple=False).squeeze()\n",
        "            if pos_inds.numel() > 0:\n",
        "                assigned_labels[pos_inds] = gt_labels[\n",
        "                    assigned_gt_inds[pos_inds] - 1]\n",
        "        else:\n",
        "            assigned_labels = None\n",
        "\n",
        "        return AssignResult(\n",
        "            num_gts, assigned_gt_inds, max_overlaps, labels=assigned_labels)\n",
        "        \n",
        "    "
      ],
      "metadata": {
        "id": "ls9oGd62rqMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. 采样并平衡正负样本的数量\n",
        "\n",
        "通过 assigner 我们得到了打了标签的 bbox。其中：-1 代表既不是正样本也不是负样本，0 代表负样本（背景），1 代表正样本（前景）。因为样本的数量实在是太多了，我们还需要限制训练样本的数量。在 MMDetection 中会通过 sampler 来实现。\n",
        "\n",
        "在 RPN 中，样本总数为 256，正负样本的比值为 1 : 1。如过正样本的数量不足 128，会使用负样本填充，配置如下："
      ],
      "metadata": {
        "id": "zP1w3oo3sbHx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sampler=dict(\n",
        "            type='RandomSampler',\n",
        "            num=256,\n",
        "            pos_fraction=0.5,\n",
        "            neg_pos_ub=-1,\n",
        "            add_gt_as_proposals=False),"
      ],
      "metadata": {
        "id": "9c2jUzZorqUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MMDetection 中的所有 sampler 继承 BaseSampler，在 BaseSampler 中 sample 方法调用 _sample_pos，_sample_neg 完成正负样本的采样。所以子类需要重写这两个方法，BaseSampler 类如下："
      ],
      "metadata": {
        "id": "Vel9Xs2UsnVa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from abc import ABCMeta, abstractmethod\n",
        "\n",
        "import torch\n",
        "\n",
        "from .sampling_result import SamplingResult\n",
        "\n",
        "\n",
        "class BaseSampler(metaclass=ABCMeta):\n",
        "    \"\"\"samplers 的基类\n",
        "\n",
        "    Args:\n",
        "        num:                  (int)   采样后的总数\n",
        "        pos_fraction        (float)   正样本的比例\n",
        "        neg_pos_ub            (int)   负样本与正样本数量比值的上界\n",
        "        add_gt_as_proposals  (bool)   是否添加 ground truth 作为 proposal.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 num,\n",
        "                 pos_fraction,\n",
        "                 neg_pos_ub=-1,\n",
        "                 add_gt_as_proposals=True,\n",
        "                 **kwargs):\n",
        "        self.num = num\n",
        "        self.pos_fraction = pos_fraction\n",
        "        self.neg_pos_ub = neg_pos_ub\n",
        "        self.add_gt_as_proposals = add_gt_as_proposals\n",
        "        self.pos_sampler = self\n",
        "        self.neg_sampler = self\n",
        "\n",
        "    @abstractmethod\n",
        "    def _sample_pos(self, assign_result, num_expected, **kwargs):\n",
        "        \"\"\"正样本采样, 此方法需要子类实现.\"\"\"\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def _sample_neg(self, assign_result, num_expected, **kwargs):\n",
        "        \"\"\"负样本采样, 此方法需要子类实现.\"\"\"\n",
        "        pass\n",
        "\n",
        "    def sample(self,\n",
        "               assign_result,\n",
        "               bboxes,\n",
        "               gt_bboxes,\n",
        "               gt_labels=None,\n",
        "               **kwargs):\n",
        "        \"\"\"采样正负样本\n",
        "\n",
        "        This is a simple implementation of bbox sampling given candidates,\n",
        "        assigning results and ground truth bboxes.\n",
        "\n",
        "        Args:\n",
        "            assign_result:  (:obj:`AssignResult`):  Bbox 分配后的结果.\n",
        "            bboxes:         (Tensor):               需要采样的 bbox, 形状为 (N, 4)\n",
        "            gt_bboxes:      (Tensor):               Ground truth bboxes, 形状为 (n_gts, 4)\n",
        "            gt_labels:      (Tensor, optional):     ground truth bboxes 的类别标签.\n",
        "\n",
        "        Returns:\n",
        "            :obj:`SamplingResult`:  采样的结果.\n",
        "\n",
        "        Example:\n",
        "            >>> from mmdet.core.bbox import RandomSampler\n",
        "            >>> from mmdet.core.bbox import AssignResult\n",
        "            >>> from mmdet.core.bbox.demodata import ensure_rng, random_boxes\n",
        "            >>> rng = ensure_rng(None)\n",
        "            >>> assign_result = AssignResult.random(rng=rng)\n",
        "            >>> bboxes = random_boxes(assign_result.num_preds, rng=rng)\n",
        "            >>> gt_bboxes = random_boxes(assign_result.num_gts, rng=rng)\n",
        "            >>> gt_labels = None\n",
        "            >>> self = RandomSampler(num=32, pos_fraction=0.5, neg_pos_ub=-1,\n",
        "            >>>                      add_gt_as_proposals=False)\n",
        "            >>> self = self.sample(assign_result, bboxes, gt_bboxes, gt_labels)\n",
        "        \"\"\"\n",
        "        if len(bboxes.shape) < 2:\n",
        "            bboxes = bboxes[None, :]\n",
        "\n",
        "        bboxes = bboxes[:, :4]\n",
        "\n",
        "        gt_flags = bboxes.new_zeros((bboxes.shape[0], ), dtype=torch.uint8)\n",
        "        # 是否将 gt 添加到正样本.\n",
        "        if self.add_gt_as_proposals and len(gt_bboxes) > 0:\n",
        "            if gt_labels is None:\n",
        "                raise ValueError(\n",
        "                    'gt_labels must be given when add_gt_as_proposals is True')\n",
        "            bboxes = torch.cat([gt_bboxes, bboxes], dim=0)\n",
        "            assign_result.add_gt_(gt_labels)\n",
        "            gt_ones = bboxes.new_ones(gt_bboxes.shape[0], dtype=torch.uint8)\n",
        "            gt_flags = torch.cat([gt_ones, gt_flags])\n",
        "        # 预期的正样本数量（eg, rpn 128）\n",
        "        num_expected_pos = int(self.num * self.pos_fraction)\n",
        "        # 采样正样本.\n",
        "        pos_inds = self.pos_sampler._sample_pos(\n",
        "            assign_result, num_expected_pos, bboxes=bboxes, **kwargs)\n",
        "        # We found that sampled indices have duplicated items occasionally.\n",
        "        # (may be a bug of PyTorch)\n",
        "        pos_inds = pos_inds.unique()\n",
        "        num_sampled_pos = pos_inds.numel()\n",
        "        # 正样本不够的用负样本填充\n",
        "        num_expected_neg = self.num - num_sampled_pos\n",
        "        if self.neg_pos_ub >= 0:\n",
        "            _pos = max(1, num_sampled_pos)\n",
        "            neg_upper_bound = int(self.neg_pos_ub * _pos)\n",
        "            if num_expected_neg > neg_upper_bound:\n",
        "                num_expected_neg = neg_upper_bound\n",
        "        neg_inds = self.neg_sampler._sample_neg(\n",
        "            assign_result, num_expected_neg, bboxes=bboxes, **kwargs)\n",
        "        neg_inds = neg_inds.unique()\n",
        "\n",
        "        sampling_result = SamplingResult(pos_inds, neg_inds, bboxes, gt_bboxes,\n",
        "                                         assign_result, gt_flags)\n",
        "        return sampling_result"
      ],
      "metadata": {
        "id": "ejCEtxMdsrLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RPN 使用 RandomSampler，它继承了 BaseSampler。源码如下："
      ],
      "metadata": {
        "id": "-0uag01ostkC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "from ..builder import BBOX_SAMPLERS\n",
        "from .base_sampler import BaseSampler\n",
        "\n",
        "\n",
        "@BBOX_SAMPLERS.register_module()\n",
        "class RandomSampler(BaseSampler):\n",
        "    \"\"\"Random sampler.\n",
        "\n",
        "    Args:\n",
        "        num:                    (int):              需要采样的个数\n",
        "        pos_fraction:           (float):            正样本数量 : 负样本数量\n",
        "        neg_pos_up:             (int, optional):    负样本与正样本数量比值的上界\n",
        "        add_gt_as_proposals:    (bool, optional):   是否添加 ground truth 作为 proposal.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 num,\n",
        "                 pos_fraction,\n",
        "                 neg_pos_ub=-1,\n",
        "                 add_gt_as_proposals=True,\n",
        "                 **kwargs):\n",
        "        from mmdet.core.bbox import demodata\n",
        "        super(RandomSampler, self).__init__(num, pos_fraction, neg_pos_ub,\n",
        "                                            add_gt_as_proposals)\n",
        "        self.rng = demodata.ensure_rng(kwargs.get('rng', None))\n",
        "\n",
        "    def random_choice(self, gallery, num):\n",
        "        \"\"\"Random select some elements from the gallery.\n",
        "\n",
        "        If `gallery` is a Tensor, the returned indices will be a Tensor;\n",
        "        If `gallery` is a ndarray or list, the returned indices will be a\n",
        "        ndarray.\n",
        "\n",
        "        Args:\n",
        "            gallery (Tensor | ndarray | list): indices pool.\n",
        "            num (int): expected sample num.\n",
        "\n",
        "        Returns:\n",
        "            Tensor or ndarray: sampled indices.\n",
        "        \"\"\"\n",
        "        assert len(gallery) >= num\n",
        "\n",
        "        is_tensor = isinstance(gallery, torch.Tensor)\n",
        "        if not is_tensor:\n",
        "            gallery = torch.tensor(\n",
        "                gallery, dtype=torch.long, device=torch.cuda.current_device())\n",
        "        perm = torch.randperm(gallery.numel(), device=gallery.device)[:num]\n",
        "        rand_inds = gallery[perm]\n",
        "        if not is_tensor:\n",
        "            rand_inds = rand_inds.cpu().numpy()\n",
        "        return rand_inds\n",
        "\n",
        "    def _sample_pos(self, assign_result, num_expected, **kwargs):\n",
        "        \"\"\"Randomly sample some positive samples.\"\"\"\n",
        "        pos_inds = torch.nonzero(assign_result.gt_inds > 0, as_tuple=False)\n",
        "        if pos_inds.numel() != 0:\n",
        "            pos_inds = pos_inds.squeeze(1)\n",
        "        if pos_inds.numel() <= num_expected:\n",
        "            return pos_inds\n",
        "        else:\n",
        "            return self.random_choice(pos_inds, num_expected)\n",
        "\n",
        "    def _sample_neg(self, assign_result, num_expected, **kwargs):\n",
        "        \"\"\"Randomly sample some negative samples.\"\"\"\n",
        "        neg_inds = torch.nonzero(assign_result.gt_inds == 0, as_tuple=False)\n",
        "        if neg_inds.numel() != 0:\n",
        "            neg_inds = neg_inds.squeeze(1)\n",
        "        if len(neg_inds) <= num_expected:\n",
        "            return neg_inds\n",
        "        else:\n",
        "            return self.random_choice(neg_inds, num_expected)"
      ],
      "metadata": {
        "id": "xRQGKWB4suOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "（二）损失函数\n",
        "对于前景置信度的预测，我们使用 BCELoss。对于 Anchor 的修正量，我们使用 L1 Loss，（原论文用的是 Smooth L1 Loss）。对于 L1 Loss，我们只计算正样本的损失。也就是只让网络对正样本进行修正。两个 Loss 相加作为最终的 Loss，配置如下："
      ],
      "metadata": {
        "id": "AsLBy6tFswh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_cls=dict(\n",
        "            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
        "loss_bbox=dict(type='L1Loss', loss_weight=1.0)),"
      ],
      "metadata": {
        "id": "8OJ2WS9qs6PQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "五、生成候选区域\n",
        "RPN 网络不仅需要自己训练，还需要为 roi head 提供候选区域。这个过程是不需要反向传播的。首先使用网络获取置信度和修正值，然后再使用如下的 5 个步骤生成 region proposals：\n",
        "\n",
        "1. 根据前景的置信度筛选出每个尺度前 nms_pre（2000）个预测值\n",
        "2. 合并筛选后的多个尺度的预测值\n",
        "3. 将 bbox 的预测值解码为左上角坐标和右下角坐标\n",
        "4. 用 nms（阈值=nms_thr）合并 bbox\n",
        "5. 根据置信度筛选出前 nms_post（1000）个 proposal\n",
        "\n",
        "\n",
        "设置如下："
      ],
      "metadata": {
        "id": "kkPajXuVs8FM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rpn_proposal=dict(\n",
        "        nms_across_levels=False,\n",
        "        nms_pre=2000,\n",
        "        nms_post=1000,\n",
        "        max_num=1000,\n",
        "        nms_thr=0.7,\n",
        "        min_bbox_size=0),"
      ],
      "metadata": {
        "id": "zXt26a3gs_mP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "源码在 RPNHead 中的 _get_bboxes_single 方法。"
      ],
      "metadata": {
        "id": "kOtoiiQitfzi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _get_bboxes_single(self,\n",
        "                           cls_scores,\n",
        "                           bbox_preds,\n",
        "                           mlvl_anchors,\n",
        "                           img_shape,\n",
        "                           scale_factor,\n",
        "                           cfg,\n",
        "                           rescale=False):\n",
        "        \"\"\"将一张图片的输出转化为 bbox 的结果.\n",
        "\n",
        "        Args:\n",
        "            cls_scores:     (list[Tensor]):    网络输出的 confidence, list 的长度为 level 的长度(5),\n",
        "                                               每个 tensor 的形状是 [K, H, W]\n",
        "            bbox_preds:     (list[Tensor]):    网络输出的坐标值, list 代表每个尺度(如： 长度 5),\n",
        "                                               每个 tensor 的形状是 [4K, H, W]\n",
        "            mlvl_anchors:   (list[Tensor]):    每个 scale 的生成的 anchor,\n",
        "                                               每个 tensor 的形状为: [H × W × K, 4]\n",
        "            img_shape:      (tuple[int]):      图像的大小\n",
        "            scale_factor:   (ndarray):         Scale factor of the image arange as\n",
        "                (w_scale, h_scale, w_scale, h_scale).\n",
        "            cfg:            (mmcv.Config):     Test / postprocessing configuration,\n",
        "                if None, test_cfg would be used.\n",
        "            rescale (bool): If True, return boxes in original image space.\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Labeled boxes in shape (n, 5), where the first 4 columns\n",
        "                are bounding box positions (tl_x, tl_y, br_x, br_y) and the\n",
        "                5-th column is a score between 0 and 1.\n",
        "        \"\"\"\n",
        "        # 1. 根据类别的置信度筛选出每个尺度 topK（K = 2000）个 bbox\n",
        "        # 2. 合并筛选后的多个尺度的 bbox\n",
        "        # 3. 将网络预测值解码\n",
        "        # 4. 用 nms（阈值=0.7）合并 bbox\n",
        "        # 5. 筛选出前 nms_post（1000）个 bbox 作为 proposal\n",
        "\n",
        "        cfg = self.test_cfg if cfg is None else cfg\n",
        "        # bboxes from different level should be independent during NMS,\n",
        "        # level_ids are used as labels for batched NMS to separate them\n",
        "        level_ids = []\n",
        "        mlvl_scores = []\n",
        "        mlvl_bbox_preds = []\n",
        "        mlvl_valid_anchors = []\n",
        "        # 遍历每个尺度\n",
        "        for idx in range(len(cls_scores)):\n",
        "            # 取到一个尺度的网络输出的类别和位置预测\n",
        "            rpn_cls_score = cls_scores[idx]\n",
        "            rpn_bbox_pred = bbox_preds[idx]\n",
        "            # 保证后两个维度相同\n",
        "            assert rpn_cls_score.size()[-2:] == rpn_bbox_pred.size()[-2:]\n",
        "            # [A, H, W] --> [H, W, A]\n",
        "            rpn_cls_score = rpn_cls_score.permute(1, 2, 0)\n",
        "            # 将类别的数值压缩成概率.\n",
        "            if self.use_sigmoid_cls:\n",
        "                # [H × W × A]\n",
        "                rpn_cls_score = rpn_cls_score.reshape(-1)\n",
        "                scores = rpn_cls_score.sigmoid()\n",
        "            else:\n",
        "                # 转成 (-1, 2), 这个 2 代表是背景或不是背景。\n",
        "                # 前景 label 设置为:  [0, 类别数 - 1],\n",
        "                # 背景 label 设置为:  类别数\n",
        "                rpn_cls_score = rpn_cls_score.reshape(-1, 2)\n",
        "                # we set FG labels to [0, num_class-1] and BG label to\n",
        "                # num_class in other heads since mmdet v2.0, However we\n",
        "                # keep BG label as 0 and FG label as 1 in rpn head\n",
        "                # 对类别维度进行 softmax, 取背景的概率\n",
        "                # 形状：[2000]\n",
        "                scores = rpn_cls_score.softmax(dim=1)[:, 1]\n",
        "            # [A × 4, H, W] --> [H × W × A, 4]\n",
        "            rpn_bbox_pred = rpn_bbox_pred.permute(1, 2, 0).reshape(-1, 4)\n",
        "            # 取对应层的 anchor: [单尺度 anchor 总数, 4]\n",
        "            anchors = mlvl_anchors[idx]\n",
        "\n",
        "            # 根据类别的置信度筛选出 topK 个 box\n",
        "            if cfg.nms_pre > 0 and scores.shape[0] > cfg.nms_pre:\n",
        "                # sort is faster than topk\n",
        "                # _, topk_inds = scores.topk(cfg.nms_pre)\n",
        "                # 对 score 从高到低排序\n",
        "                # [182400]\n",
        "                ranked_scores, rank_inds = scores.sort(descending=True)\n",
        "                # 取 topK（cfg.nms_pre） 个 index 和 score: anchor --> [2000]\n",
        "                topk_inds = rank_inds[:cfg.nms_pre]\n",
        "                scores = ranked_scores[:cfg.nms_pre]\n",
        "                # 根据类别的预测值，取 topK 个 bbox\n",
        "                rpn_bbox_pred = rpn_bbox_pred[topk_inds, :]\n",
        "                # anchor 也取 topK 个\n",
        "                anchors = anchors[topk_inds, :]\n",
        "            mlvl_scores.append(scores)\n",
        "            mlvl_bbox_preds.append(rpn_bbox_pred)\n",
        "            mlvl_valid_anchors.append(anchors)\n",
        "            # new_full(形状，填充值，数据类型)\n",
        "            level_ids.append(\n",
        "                scores.new_full((scores.size(0), ), idx, dtype=torch.long))\n",
        "        # cat 的 dim 默认为 0 维\n",
        "        scores = torch.cat(mlvl_scores)\n",
        "        anchors = torch.cat(mlvl_valid_anchors)\n",
        "        rpn_bbox_pred = torch.cat(mlvl_bbox_preds)\n",
        "        proposals = self.bbox_coder.decode(\n",
        "            anchors, rpn_bbox_pred, max_shape=img_shape)\n",
        "        ids = torch.cat(level_ids)\n",
        "\n",
        "        # 如多对 anchor 的大小有限定\n",
        "        if cfg.min_bbox_size > 0:\n",
        "            # 计算 W, H\n",
        "            w = proposals[:, 2] - proposals[:, 0]\n",
        "            h = proposals[:, 3] - proposals[:, 1]\n",
        "            # 取长宽都 > min_bbox_size 的索引\n",
        "            valid_inds = torch.nonzero(\n",
        "                (w >= cfg.min_bbox_size)\n",
        "                & (h >= cfg.min_bbox_size),\n",
        "                as_tuple=False).squeeze()\n",
        "            # 筛选目标\n",
        "            if valid_inds.sum().item() != len(proposals):\n",
        "                proposals = proposals[valid_inds, :]\n",
        "                scores = scores[valid_inds]\n",
        "                ids = ids[valid_inds]\n",
        "\n",
        "        # TODO: remove the hard coded nms type\n",
        "        nms_cfg = dict(type='nms', iou_threshold=cfg.nms_thr)\n",
        "        dets, keep = batched_nms(proposals, scores, ids, nms_cfg)\n",
        "        # nms 后对置信度有排序。直接取前 nms_post 个\n",
        "        return dets[:cfg.nms_post]"
      ],
      "metadata": {
        "id": "oKOTbYB4s_ub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [MMDetection Faster R-CNN 源码详解（四)](https://zhuanlan.zhihu.com/p/194285023)\n",
        "\n",
        "在上一小结中，我们详解了 RPN 的原理及部分代码。在本篇文章中会详解 RPN 的全部源码。\n",
        "\n",
        "\n",
        "RPN（源码篇）\n",
        "1. 整体结构\n",
        "2. BaseDenseHead\n",
        "4. RPNTestMixin\n",
        "5. RPNHead\n",
        "\n",
        "一、整体结构\n",
        "\n",
        "在 MMDetection 中，RPN 部分是通过 RPNHead 类来实现的。其中 RPNHead 继承了 AnchorHead 和 RPNTestMixin，AnchorHead 继承了 BaseDenseHead。继承关系如下图：\n",
        "\n",
        "![](https://pic3.zhimg.com/80/v2-8aad81cc25ee038d5f991048f4af5226_720w.jpg)图一：RPNHead 的继承关系\n",
        "\n",
        "接下来，我们自底至上来分析源码。\n",
        "\n",
        "二、BaseDenseHead（基类）\n",
        "\n",
        "对于训练 RPN 来说，主要有两个流程，计算损失和生成候选区域。因为 RPN 需要训练 Anchor，所以需要采样、平衡正负样本并计算损失。RPN 又需要为 roi_head 提供候选区域，所以 RPN 也需要进行区域推荐。其中训练时计算损失的步骤需要反向传播，而生成候选区域的过程不需要反向传播。而测试时不需要计算损失只需要为后续的网络生成候选区域即可。BaseDenseHead 提供了计算损失和生成候选区域的接口，对应的方法为 loss 和 get_bboxes。\n",
        "\n",
        "从数据上来看，图片经过 RPN 后，会生成每个 Anchor 的置信度和修正量。对于经过 RPN 卷积的输出，一方面需要与 anchor 编码，然后和 gt_bboxes 计算损失，另一方面通过 anchor 解码，筛选后得到 proposal 提供给 roi_head。\n",
        "\n",
        "我们来看下基类 BaseDenseHead，它有 2 个抽象方法，分别是 loss（计算损失）和 get_bboxes（生成候选区域），这两个方法都需要子类来实现。\n",
        "\n",
        "loss 方法的作用是计算 rpn 网络的损失，并将损失以字典的形式返回。get_bboxes 的作用是将网络预测的 bbox 结果转化为 proposal，为 roi head 提供候选区域。\n",
        "\n",
        "** forward_train 方法实现了 RPN 在训练时的前向传播，其主要步骤如下：**\n",
        "\n",
        "1）获得类别（前景）和边框回归的输出值。\n",
        "\n",
        "2）计算类别与边框回归的损失。\n",
        "\n",
        "3）将网络的预测转化为候选区域。\n",
        "\n",
        "我们来看一下源码："
      ],
      "metadata": {
        "id": "y64_1Td1cgH0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from abc import ABCMeta, abstractmethod\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class BaseDenseHead(nn.Module, metaclass=ABCMeta):\n",
        "    \"\"\"DenseHeads 基类\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super(BaseDenseHead, self).__init__()\n",
        "\n",
        "    @abstractmethod\n",
        "    def loss(self, **kwargs):\n",
        "        \"\"\"计算 head 的 loss\"\"\"\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def get_bboxes(self, **kwargs):\n",
        "        \"\"\"将 bbox 预测转化为 region proposals\"\"\"\n",
        "        pass\n",
        "\n",
        "    def forward_train(self,\n",
        "                      x,\n",
        "                      img_metas,\n",
        "                      gt_bboxes,\n",
        "                      gt_labels=None,\n",
        "                      gt_bboxes_ignore=None,\n",
        "                      proposal_cfg=None,\n",
        "                      **kwargs):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x:                        (list[Tensor])  经过 FPN 后的 features\n",
        "            img_metas:                  (list[dict])  一个 batch 的 image 的信息的 list, 如: 大小, 缩放等.\n",
        "            gt_bboxes:                (list[Tensor])  一个 batch 的 Ground truth bboxes 的 list,\n",
        "                                                      每个图片 gt bboxes 的形状为 (num_gts, 4).\n",
        "            gt_labels:         (list[Tensor] | None)  一个 batch 的 Ground truth labels 的 list,\n",
        "                                                      每个图片 gt labels 的形状为 (num_gts,).\n",
        "            gt_bboxes_ignore:  (list[Tensor] | None)  一个 batch 忽略的 ground truth bboxes,\n",
        "                                                      每个图片的 gt_bboxes_ignore 的形状为 (num_ignored_gts, 4).\n",
        "            proposal_cfg:              (mmcv.Config)  测试 / 后处理 的配置, 如果为 None, 就会使用 test_cfg\n",
        "\n",
        "        Returns:\n",
        "            tuple:\n",
        "                losses:          (dict[str, Tensor])  一个 loss 字典\n",
        "                proposal_list:        (list[Tensor])  一个批次的图片的 proposal 列表,\n",
        "                                                      每个 proposal 的形状为 (1000, 5)\n",
        "        \"\"\"\n",
        "        # 前向计算, 拿到 confidence 和 bbox 坐标偏移的结果.\n",
        "        # 结果为 [cls_list, reg_list]\n",
        "        # cls_list 是每个尺度的分类预测结果, 形状为 [torch.Size([batch, anchor, H, W]), ...]\n",
        "        # reg_list 是每个尺度的回归预测结果, 形状为 [torch.Size([batch, anchor × 4, H, W ]), ...]\n",
        "        outs = self(x)\n",
        "        if gt_labels is None:\n",
        "            loss_inputs = outs + (gt_bboxes, img_metas)\n",
        "        else:\n",
        "            loss_inputs = outs + (gt_bboxes, gt_labels, img_metas)\n",
        "        # 计算损失\n",
        "        # 结果为 dict('loss_rpn_cls', 'loss_rpn_bbox')\n",
        "        # loss_rpn_cls  是每个尺度的分类损失, 是一个 tensor 数值.\n",
        "        # loss_rpn_bbox 是每个尺度的回归损失, 是一个 tensor 数值.\n",
        "        losses = self.loss(*loss_inputs, gt_bboxes_ignore=gt_bboxes_ignore)\n",
        "        # proposal_cfg 为 None, 只返回损失不提供 proposal, 例如: 单独训练 RPN 就不需要提供 proposal\n",
        "        if proposal_cfg is None:\n",
        "            return losses\n",
        "        # proposal_cfg 不是 None, 返回损失且提供 proposal\n",
        "        else:\n",
        "            # 一个批次的图片的 proposal 列表, 每个 proposal 的形状为 (1000, 5)\n",
        "            proposal_list = self.get_bboxes(*outs, img_metas, cfg=proposal_cfg)\n",
        "            return losses, proposal_list"
      ],
      "metadata": {
        "id": "h6G_g5VuvUuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 三、AnchorHead（继承 BaseDenseHead）\n",
        "AnchorHead 继承了 BaseDenseHead，提供了所有 anchor-base 模型通用的方法。对于不同的 anchor-base 的网络模型只用继承 AnchorHead 并重写一部分方法就可以实现它的功能。下面我们一个一个方法的来看 AnchorHead 的功能。\n",
        "\n",
        "### （一）__init__\n",
        "\n",
        "在 构造函数 中，AnchorHead 会构建所有需要的模块，并调用 _init_layers 初始化 Head 的层。 具体 构建的模块如下：\n",
        "\n",
        "anchor_generator：anchor 生成\n",
        "bbox_coder：bbox 编码\n",
        "loss_cls：分类损失\n",
        "loss_bbox：bbox 损失\n",
        "assigner：分配正负样本（训练时需要）\n",
        "sampler：正负样本采样（训练时需要）\n"
      ],
      "metadata": {
        "id": "tWkxMl-WvwZN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from mmcv.cnn import normal_init\n",
        "\n",
        "from mmdet.core import (anchor_inside_flags, build_anchor_generator,\n",
        "                        build_assigner, build_bbox_coder, build_sampler,\n",
        "                        force_fp32, images_to_levels, multi_apply,\n",
        "                        multiclass_nms, unmap)\n",
        "from ..builder import HEADS, build_loss\n",
        "from .base_dense_head import BaseDenseHead\n",
        "\n",
        "\n",
        "@HEADS.register_module()\n",
        "class AnchorHead(BaseDenseHead):\n",
        "    \"\"\"Anchor-based head (RPN, RetinaNet, SSD, etc.).\n",
        "\n",
        "    Args:\n",
        "        num_classes:              (int)   类别的个数, 不包括背景类.\n",
        "        in_channels:              (int)   输入的 feature map 的通道数.\n",
        "        feat_channels:            (int)   中间提取特征使用的通道数.\n",
        "        anchor_generator:        (dict)   anchor generator 的配置文件字典.\n",
        "        bbox_coder:              (dict)   box coder 的配置文件字典.\n",
        "        reg_decoded_bbox:        (bool)   如果为 True, 将会对解码的 bbox 回归损失. (默认值: False).\n",
        "        background_label:  (int | None)   背景标签的 id. 在 RPN 中为 0, 其他的 head 为 num_classes.\n",
        "                                          如果为 None 会自动设置为 num_classes.\n",
        "        loss_cls:                (dict)   分类 loss 的配置文件字典.\n",
        "        loss_bbox:               (dict)   回归 loss 的配置文件字典.\n",
        "        train_cfg:               (dict)   anchor head 的训练配置.\n",
        "        test_cfg:                (dict)   anchor head 的测试配置.\n",
        "    \"\"\"  # noqa: W605\n",
        "\n",
        "    def __init__(self,\n",
        "                 num_classes,\n",
        "                 in_channels,\n",
        "                 feat_channels=256,\n",
        "                 anchor_generator=dict(\n",
        "                     type='AnchorGenerator',\n",
        "                     scales=[8, 16, 32],\n",
        "                     ratios=[0.5, 1.0, 2.0],\n",
        "                     strides=[4, 8, 16, 32, 64]),\n",
        "                 bbox_coder=dict(\n",
        "                     type='DeltaXYWHBBoxCoder',\n",
        "                     target_means=(.0, .0, .0, .0),\n",
        "                     target_stds=(1.0, 1.0, 1.0, 1.0)),\n",
        "                 reg_decoded_bbox=False,\n",
        "                 background_label=None,\n",
        "                 loss_cls=dict(\n",
        "                     type='CrossEntropyLoss',\n",
        "                     use_sigmoid=True,\n",
        "                     loss_weight=1.0),\n",
        "                 loss_bbox=dict(\n",
        "                     type='SmoothL1Loss', beta=1.0 / 9.0, loss_weight=1.0),\n",
        "                 train_cfg=None,\n",
        "                 test_cfg=None):\n",
        "        super(AnchorHead, self).__init__()\n",
        "        self.in_channels = in_channels        # 256, FPN 每个尺度的输出通道数\n",
        "        self.num_classes = num_classes        # 类别个数, 不包括背景类.\n",
        "        self.feat_channels = feat_channels    # 256\n",
        "        self.use_sigmoid_cls = loss_cls.get('use_sigmoid', False)\n",
        "        # TODO better way to determine whether sample or not\n",
        "        # 使用 FocalLoss 不需要对 proposal 进行采样, 所以 sampling = False\n",
        "        self.sampling = loss_cls['type'] not in [\n",
        "            'FocalLoss', 'GHMC', 'QualityFocalLoss'\n",
        "        ]\n",
        "        if self.use_sigmoid_cls:\n",
        "            self.cls_out_channels = num_classes\n",
        "        else:\n",
        "            self.cls_out_channels = num_classes + 1\n",
        "\n",
        "        if self.cls_out_channels <= 0:\n",
        "            raise ValueError(f'num_classes={num_classes} is too small')\n",
        "        self.reg_decoded_bbox = reg_decoded_bbox\n",
        "\n",
        "        # 如果为 None 设置为 num_classes, 否则设置为 0 (RPN: 0)\n",
        "        self.background_label = (\n",
        "            num_classes if background_label is None else background_label)\n",
        "        # background_label 必须是 0 或 num_classes\n",
        "        assert (self.background_label == 0\n",
        "                or self.background_label == num_classes)\n",
        "\n",
        "        self.bbox_coder = build_bbox_coder(bbox_coder)\n",
        "        self.loss_cls = build_loss(loss_cls)\n",
        "        self.loss_bbox = build_loss(loss_bbox)\n",
        "        self.train_cfg = train_cfg\n",
        "        self.test_cfg = test_cfg\n",
        "        # 只有训练时才会分配正负样本 (assigner) 和平衡正负样本的数量 (sampler)\n",
        "        if self.train_cfg:\n",
        "            self.assigner = build_assigner(self.train_cfg.assigner)\n",
        "            # use PseudoSampler when sampling is False\n",
        "            if self.sampling and hasattr(self.train_cfg, 'sampler'):\n",
        "                sampler_cfg = self.train_cfg.sampler\n",
        "            else:\n",
        "                sampler_cfg = dict(type='PseudoSampler')\n",
        "            self.sampler = build_sampler(sampler_cfg, context=self)\n",
        "        self.fp16_enabled = False\n",
        "        \n",
        "        # anchor 的生成, 无论是训练或测试都需要.\n",
        "        self.anchor_generator = build_anchor_generator(anchor_generator)\n",
        "\n",
        "        # num_anchors 每个尺度 base_anchor 的数量.\n",
        "        # 通常每个尺度 base_anchor 的数量相同, 如 RPN(3, 3, 3, 3, 3), 除了 ssd.\n",
        "        self.num_anchors = self.anchor_generator.num_base_anchors[0]\n",
        "        self._init_layers()"
      ],
      "metadata": {
        "id": "Fjh9iLzuwS92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###（二）_init_layers（RPNHead 会重写）\n",
        "此类的构造函数会调用此方法，完成 Head 层的创建。不过在子类 RPNHead 会对它重写。在这里使用的 Head 是两个 1×1 的卷积。"
      ],
      "metadata": {
        "id": "M3PYgV3WwTs7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " def _init_layers(self):\n",
        "        \"\"\"初始化 Head 的 layer\"\"\"\n",
        "        self.conv_cls = nn.Conv2d(self.in_channels,\n",
        "                                  self.num_anchors * self.cls_out_channels, 1)\n",
        "        self.conv_reg = nn.Conv2d(self.in_channels, self.num_anchors * 4, 1)"
      ],
      "metadata": {
        "id": "38TCQsjqwhW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### （三）init_weights（RPNHead 会重写）\n",
        "初始化 Head 的层。在 RPNHead 中也会对此方法重写，这里使用的是均值为 0，方差为 0.01 的正态分布初始化卷积。"
      ],
      "metadata": {
        "id": "Hmi2aX35wh_8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    def init_weights(self):\n",
        "        \"\"\"初始化 head 的权重\"\"\"\n",
        "        # 使用均值为 0, 方差为 0.01 初始化\n",
        "        normal_init(self.conv_cls, std=0.01)\n",
        "        normal_init(self.conv_reg, std=0.01)"
      ],
      "metadata": {
        "id": "s4e4zE4aGSRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "（四）forward_single（RPNHead 会重写）\n",
        "forward_single 会对单尺度的 feature map 前向传播，此方法也会在 RPNHead 重写。需要注意的是，在 RPN 中所有的尺度都使用同一个网络结构得到输出结果。"
      ],
      "metadata": {
        "id": "l8wZ7pcqGTBh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " def forward_single(self, x):\n",
        "        \"\"\"对单尺度的 feature map 前向传播.\n",
        "\n",
        "        Args:\n",
        "            x (Tensor):    单尺度的 feature map\n",
        "\n",
        "        Returns:\n",
        "            tuple:\n",
        "                cls_score (Tensor): 单尺度的置信度 (通道数为: anchors 的数量 * num_classes)\n",
        "                bbox_pred (Tensor): 单尺度预测的偏移量 (通道数为: anchors 的数量 * 4)\n",
        "        \"\"\"\n",
        "        # 所有尺度使用相同的 conv_cls 和 conv_reg 进行预测.\n",
        "        cls_score = self.conv_cls(x)\n",
        "        bbox_pred = self.conv_reg(x)\n",
        "        return cls_score, bbox_pred"
      ],
      "metadata": {
        "id": "8qEowCRCGWEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "（五）forward\n",
        "前向传播，生成多个尺度的预测值。传入一个经过 backbone 和 neck 后得到的多尺度 feature map 的元祖。经过网络输出后，会得到两个 list，第一个 list 是所有尺度 Anchor 的置信度预测，每个元素的形状为（batch，n_anchors，H，W），第二个 list 是所有尺度 Anchor 的 bbox 回归的预测结果，每个元素的形状为（batch，n_anchors × 4，H，W）。"
      ],
      "metadata": {
        "id": "l-43cUojGX7X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(self, feats):\n",
        "        \"\"\"前向传播, 获得网络预测的分类和回归的结果.\n",
        "\n",
        "        Args:\n",
        "            feats:  (tuple[Tensor]): 经过 backbone 和 neck 后的 features 的元祖, 每个元素是一个尺度的 feature.\n",
        "\n",
        "        Returns:\n",
        "            tuple: 一个元祖, 包括分类分数和 bbox 回归预测的结果\n",
        "                cls_scores (list[Tensor]):  每个尺度的分类分数的 list, 每个元素代表一个尺度, 数据类型为 tensor.\n",
        "                                            每个元素的形状为 [batch, anchor 数量 × 类别个数, H, W]\n",
        "                bbox_preds (list[Tensor]):  每个尺度的 bbox 回归的 list, 每个元素代表一个尺度, 类型为 tensor.\n",
        "                                            每个元素的形状为 [batch, anchor 数量 × 4, H, W]\n",
        "        \"\"\"\n",
        "        return multi_apply(self.forward_single, feats)"
      ],
      "metadata": {
        "id": "sXYJ55WAGafP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "（六）get_anchors\n",
        "输入各个尺度的 feature map 大小，获取一个批次中多张图片多个尺度的 anchor 和 valid flag。"
      ],
      "metadata": {
        "id": "fbkKJCiwGemH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  def get_anchors(self, featmap_sizes, img_metas, device='cuda'):\n",
        "        \"\"\"根据特征图的大小获取 anchor.\n",
        "\n",
        "        Args:\n",
        "            featmap_sizes: (list[tuple]):           各个尺度的 feature map 的大小.\n",
        "            img_metas:     (list[dict]):            一个批次的图像属性信息\n",
        "            device:        (torch.device | str):    返回的 tensor 的设备\n",
        "\n",
        "        Returns:\n",
        "            tuple:\n",
        "                anchor_list:        (list[list[Tensor]]): 一个批次图片的 anchor, 每个元素是一张图片所有尺度的 anchor\n",
        "                valid_flag_list:    (list[list[Tensor]]): 一个批次图片有效的 anchor, 每个元素是一张图片所有尺度的 anchor\n",
        "        \"\"\"\n",
        "        # batch size\n",
        "        num_imgs = len(img_metas)\n",
        "\n",
        "        # 由于一个批次所有图像的特征图大小相同, 所以只用生成 anchor 一次, 就可以得到整个批次的 anchor.\n",
        "        multi_level_anchors = self.anchor_generator.grid_anchors(\n",
        "            featmap_sizes, device)\n",
        "        # 因为同一个 batch 的图片大小相同所以这里直接循环 batch 次数次 anchor 就行.\n",
        "        # anchor_list 是每个图片每个尺度生成的 anchor 的列表, 形状为 list(list(Tensor)).\n",
        "        anchor_list = [multi_level_anchors for _ in range(num_imgs)]\n",
        "\n",
        "        # 对于每个图像, 计算多尺度 anchor 的有效标志.\n",
        "        # 形状为 list(list(Tensor)), 其中 Tensor 代表一张图片一个尺度的 Anchor.\n",
        "        valid_flag_list = []\n",
        "        for img_id, img_meta in enumerate(img_metas):\n",
        "            multi_level_flags = self.anchor_generator.valid_flags(\n",
        "                featmap_sizes, img_meta['pad_shape'], device)\n",
        "            valid_flag_list.append(multi_level_flags)\n",
        "\n",
        "        return anchor_list, valid_flag_list"
      ],
      "metadata": {
        "id": "Tln7181EGfW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "（七）_get_targets_single\n",
        "此函数会生成 RPN 单张图片训练的目标，其主要流程为如下 5 步：\n",
        "\n",
        "筛选出有效的 anchor\n",
        "anchor 分配正负样本（assigner）\n",
        "anchor 正负样本采样（sampler）\n",
        "构建 bbox 和 label 的目标和权重\n",
        "(1) 构建 bbox 的目标和权重：\n",
        "\n",
        "① 将正样本的 anchor 编码为中心点坐标，宽和高的偏移量。\n",
        "\n",
        "② 将正样本对应的 indices 设置为编码后的 anchor\n",
        "\n",
        "③ 将正样本的权重设置为 1\n",
        "\n",
        "(2) 构建 label 的目标和权重：\n",
        "\n",
        "① 将正样本的 label 设置为 1，代表前景\n",
        "\n",
        "② 将正样本的权重设置为 1\n",
        "\n",
        "5. 填充 anchor 到没有筛选 valid flag 的长度\n",
        "\n",
        "下面我们来看看源码："
      ],
      "metadata": {
        "id": "o5pXNFxfGhl9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " def _get_targets_single(self,\n",
        "                            flat_anchors,\n",
        "                            valid_flags,\n",
        "                            gt_bboxes,\n",
        "                            gt_bboxes_ignore,\n",
        "                            gt_labels,\n",
        "                            img_meta,\n",
        "                            label_channels=1,\n",
        "                            unmap_outputs=True):\n",
        "        \"\"\"计算一张图片 anchor 的回归和分类的目标\n",
        "\n",
        "        Args:\n",
        "            flat_anchors:       (Tensor):   合并后的多尺度的 anchor. 形状为: (num_anchors ,4).\n",
        "            valid_flags:        (Tensor):   合并后的多尺度的 anchor 的 flag, 形状为 (num_anchors,).\n",
        "            gt_bboxes:          (Tensor):   图像的 ground truth bbox, 形状为 (num_gts, 4).\n",
        "            gt_bboxes_ignore:   (Tensor):   需要忽略的 Ground truth bboxes 形状为: (num_ignored_gts, 4).\n",
        "            img_meta:           (dict):     此图像的属性信息\n",
        "            gt_labels:          (Tensor):   每个 box 的 Ground truth labels, 形状为 (num_gts,).\n",
        "            label_channels:     (int):      label 所在的通道.\n",
        "            unmap_outputs:      (bool):     是否将输出映射回原始 anchor 配置.\n",
        "\n",
        "        Returns:\n",
        "            tuple:\n",
        "                labels:          (Tensor)     训练的标签, 形状为 (anchor 总数,)\n",
        "                label_weights:   (Tensor)     训练标签的权重, 形状为 (anchor 总数,)\n",
        "                bbox_targets:    (Tensor)     bbox 训练的目标值, 形状为 (anchor 总数, 4)\n",
        "                bbox_weights:    (Tensor)     bbox 训练目标值的权重, 形状为 (anchor 总数, 4)\n",
        "                pos_inds:        (Tensor)     正样本的索引, 形状为 (正样本总数,)\n",
        "                neg_inds:        (Tensor)     负样本的索引, 形状为 (负样本总数,)\n",
        "        \"\"\"\n",
        "        # ===================== 1. 筛选出有效的 anchor ===========================\n",
        "        # 获得有效的 flag, 这里的 inside_flags 就等于 valid_flags, 形状为 (num_anchors,)\n",
        "        inside_flags = anchor_inside_flags(flat_anchors, valid_flags,\n",
        "                                           img_meta['img_shape'][:2],\n",
        "                                           self.train_cfg.allowed_border)\n",
        "        # 如果 anchor 没有一个有效, 直接返回\n",
        "        if not inside_flags.any():\n",
        "            return (None, ) * 7\n",
        "\n",
        "        # 筛选有效的 anchor, 此时 Anchor 数量会减少为有效的 anchor 数量.\n",
        "        anchors = flat_anchors[inside_flags, :]\n",
        "\n",
        "        # ========================== 2. anchor 分配正负样本 ==============================\n",
        "        assign_result = self.assigner.assign(\n",
        "            anchors, gt_bboxes, gt_bboxes_ignore,\n",
        "            None if self.sampling else gt_labels)\n",
        "\n",
        "        # ========================== 3. anchor 正负样本采样 ==============================\n",
        "        sampling_result = self.sampler.sample(assign_result, anchors,\n",
        "                                              gt_bboxes)\n",
        "\n",
        "        # ======================== 4. 构建 label 和 bbox 的目标和权重 =====================\n",
        "        # 有效的 anchor 数量\n",
        "        num_valid_anchors = anchors.shape[0]\n",
        "        # bbox 目标, 初始化将目标设置为 0\n",
        "        bbox_targets = torch.zeros_like(anchors)\n",
        "        # bbox 权重, 即是否需要算入损失, 是否需要网络学习. 初始化将权重设置为 0\n",
        "        bbox_weights = torch.zeros_like(anchors)\n",
        "        # label 的目标, 初始化先将所有有效的 anchor 的标签标记为背景 (0)\n",
        "        labels = anchors.new_full((num_valid_anchors, ),\n",
        "                                  self.background_label,\n",
        "                                  dtype=torch.long)\n",
        "        # label 的权重, 初始化将将权重权设置为 0\n",
        "        label_weights = anchors.new_zeros(num_valid_anchors, dtype=torch.float)\n",
        "        # 获得正负样本的索引\n",
        "        pos_inds = sampling_result.pos_inds\n",
        "        neg_inds = sampling_result.neg_inds\n",
        "        if len(pos_inds) > 0:\n",
        "            # ================ （1）构建 bbox 的目标和权重 ====================\n",
        "            # 获得所有正样本 box 的 anchor, 形状 [正样本数量, 4]\n",
        "            if not self.reg_decoded_bbox:\n",
        "                # 将 anchor 编码为中心点坐标，宽和高的偏移量\n",
        "                pos_bbox_targets = self.bbox_coder.encode(\n",
        "                    sampling_result.pos_bboxes, sampling_result.pos_gt_bboxes)\n",
        "            else:\n",
        "                pos_bbox_targets = sampling_result.pos_gt_bboxes\n",
        "            # 将正样本对应的 indices 设置为编码后的 anchor, 将权重设置为 1\n",
        "            bbox_targets[pos_inds, :] = pos_bbox_targets\n",
        "            bbox_weights[pos_inds, :] = 1.0\n",
        "            # ================ （2）构建 label 的目标和权重 ===================\n",
        "            if gt_labels is None:\n",
        "                # 只有 rpn 的 gt_labels 才设置为 None\n",
        "                labels[pos_inds] = 1\n",
        "            else:\n",
        "                # 否则设置为对应的类别编号\n",
        "                labels[pos_inds] = gt_labels[\n",
        "                    sampling_result.pos_assigned_gt_inds]\n",
        "            # 将正样本的权重设置为 1\n",
        "            if self.train_cfg.pos_weight <= 0:\n",
        "                label_weights[pos_inds] = 1.0\n",
        "            else:\n",
        "                label_weights[pos_inds] = self.train_cfg.pos_weight\n",
        "        if len(neg_inds) > 0:\n",
        "            label_weights[neg_inds] = 1.0\n",
        "\n",
        "        # ===================== 5. 填充 anchor 到没有筛选 valid flag 的长度. ==================\n",
        "        if unmap_outputs:\n",
        "            num_total_anchors = flat_anchors.size(0)\n",
        "            # 填充 labels\n",
        "            labels = unmap(\n",
        "                labels,\n",
        "                num_total_anchors,\n",
        "                inside_flags,\n",
        "                fill=self.background_label)  # fill bg label\n",
        "            # 填充 label_weights\n",
        "            label_weights = unmap(label_weights, num_total_anchors,\n",
        "                                  inside_flags)\n",
        "            # 填充 bbox_targets\n",
        "            bbox_targets = unmap(bbox_targets, num_total_anchors, inside_flags)\n",
        "            # 填充 bbox_weights\n",
        "            bbox_weights = unmap(bbox_weights, num_total_anchors, inside_flags)\n",
        "\n",
        "        return (labels, label_weights, bbox_targets, bbox_weights, pos_inds,\n",
        "                neg_inds, sampling_result)"
      ],
      "metadata": {
        "id": "3ggoF1VIGj9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "（八）get_targets\n",
        "此函数会接受一个批次所有 anchor 的列表和一个批次的 ground truth bbox。返回各个尺度的训练目标。"
      ],
      "metadata": {
        "id": "7Hb4b_yWGnUJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_targets(self,\n",
        "                    anchor_list,\n",
        "                    valid_flag_list,\n",
        "                    gt_bboxes_list,\n",
        "                    img_metas,\n",
        "                    gt_bboxes_ignore_list=None,\n",
        "                    gt_labels_list=None,\n",
        "                    label_channels=1,\n",
        "                    unmap_outputs=True,\n",
        "                    return_sampling_results=False):\n",
        "        \"\"\"获得一个批次的训练和回归目标.\n",
        "\n",
        "        Args:\n",
        "            anchor_list:            (list[list[Tensor]])    所有批次所有尺度的 anchor 的列表,\n",
        "                                                            每个 tensor 代表一张图片的一个尺度的 anchor.\n",
        "                                                            形状为 (num_anchors, 4).\n",
        "            valid_flag_list:        (list[list[Tensor]]):   所有批次所有尺度 anchor 的 valid flag,\n",
        "                                                            每个 tensor 代表一张图片的一个尺度的 anchor 的 valid flag.\n",
        "                                                            形状为 (num_anchors,)\n",
        "            gt_bboxes_list:         (list[Tensor]):         一个 batch 的 gt bbox, 每个 tensor 的形状为 (num_gts, 4)\n",
        "            img_metas:              (list[dict]):           一个 batch 的图片的属性信息.\n",
        "            gt_bboxes_ignore_list:  (list[Tensor]):         需要忽略的 gt bboxes\n",
        "            gt_labels_list:         (list[Tensor] | None):  一个 batch 的 gt labels.\n",
        "            label_channels:         (int):                  标签的通道\n",
        "            unmap_outputs:          (bool):                 是否填充 anchor 到没有筛选 valid flag 的长度\n",
        "\n",
        "        Returns:\n",
        "            tuple:\n",
        "                labels_list:        (list[Tensor]):     每个尺度的 label, 每个元素的形状为 (batch, n_anchors)\n",
        "                label_weights_list: (list[Tensor]):     每个尺度 label 的权重, 每个元素的形状为 (batch, n_anchors)\n",
        "                bbox_targets_list:  (list[Tensor]):     每个尺度的 bbox, 每个元素的形状为 (batch, n_anchors, 4)\n",
        "                bbox_weights_list:  (list[Tensor]):     每个尺度 bbox 的权重, 每个元素的形状为 (batch, n_anchors, 4)\n",
        "                num_total_pos:      (int):              一个批次所有图片的正样本总数\n",
        "                num_total_neg:      (int):              一个批次所有图片的负样本总数\n",
        "            additional_returns: This function enables user-defined returns from\n",
        "                `self._get_targets_single`. These returns are currently refined\n",
        "                to properties at each feature map (i.e. having HxW dimension).\n",
        "                The results will be concatenated after the end\n",
        "        \"\"\"\n",
        "        # 计算 batch 的数量\n",
        "        num_imgs = len(img_metas)\n",
        "        assert len(anchor_list) == len(valid_flag_list) == num_imgs\n",
        "\n",
        "        # 计算每个尺度 anchor 的数量 [187200, 46800, 11700, 2925, 780]\n",
        "        num_level_anchors = [anchors.size(0) for anchors in anchor_list[0]]\n",
        "\n",
        "        concat_anchor_list = []\n",
        "        concat_valid_flag_list = []\n",
        "        # 遍历每个图片, 合并每个图片中所有尺度的 anchor\n",
        "        for i in range(num_imgs):\n",
        "            assert len(anchor_list[i]) == len(valid_flag_list[i])\n",
        "            # 合并所有尺度的 anchor\n",
        "            concat_anchor_list.append(torch.cat(anchor_list[i]))\n",
        "            # 合并所有尺度的 flag\n",
        "            concat_valid_flag_list.append(torch.cat(valid_flag_list[i]))\n",
        "\n",
        "        # compute targets for each image\n",
        "        if gt_bboxes_ignore_list is None:\n",
        "            # <class 'list'>: [None, None, None, None]\n",
        "            gt_bboxes_ignore_list = [None for _ in range(num_imgs)]\n",
        "        if gt_labels_list is None:\n",
        "            # <class 'list'>: [None, None, None, None]\n",
        "            gt_labels_list = [None for _ in range(num_imgs)]\n",
        "        results = multi_apply(\n",
        "            self._get_targets_single,\n",
        "            concat_anchor_list,\n",
        "            concat_valid_flag_list,\n",
        "            gt_bboxes_list,\n",
        "            gt_bboxes_ignore_list,\n",
        "            gt_labels_list,\n",
        "            img_metas,\n",
        "            label_channels=label_channels,\n",
        "            unmap_outputs=unmap_outputs)\n",
        "        (all_labels, all_label_weights, all_bbox_targets, all_bbox_weights,\n",
        "         pos_inds_list, neg_inds_list, sampling_results_list) = results[:7]\n",
        "        rest_results = list(results[7:])  # user-added return values\n",
        "        # no valid anchors\n",
        "        if any([labels is None for labels in all_labels]):\n",
        "            return None\n",
        "        # 统计所有 image 的正负样本\n",
        "        num_total_pos = sum([max(inds.numel(), 1) for inds in pos_inds_list])\n",
        "        num_total_neg = sum([max(inds.numel(), 1) for inds in neg_inds_list])\n",
        "        # split targets to a list w.r.t. multiple levels\n",
        "        labels_list = images_to_levels(all_labels, num_level_anchors)\n",
        "        label_weights_list = images_to_levels(all_label_weights,\n",
        "                                              num_level_anchors)\n",
        "        bbox_targets_list = images_to_levels(all_bbox_targets,\n",
        "                                             num_level_anchors)\n",
        "        bbox_weights_list = images_to_levels(all_bbox_weights,\n",
        "                                             num_level_anchors)\n",
        "        res = (labels_list, label_weights_list, bbox_targets_list,\n",
        "               bbox_weights_list, num_total_pos, num_total_neg)\n",
        "        if return_sampling_results:\n",
        "            res = res + (sampling_results_list, )\n",
        "        for i, r in enumerate(rest_results):  # user-added return values\n",
        "            rest_results[i] = images_to_levels(r, num_level_anchors)\n",
        "\n",
        "        return res + tuple(rest_results)"
      ],
      "metadata": {
        "id": "TQ-FhQi_GraN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "（九）loss_single\n",
        "计算每个尺度分类和回归的损失。注意，对于分类损失正负样本都需要计算。对于回归损失，只计算正样本不计算负样本。因为总采样数为 num_totoal_samples（256 × batch）所以对于每一个尺度都要除以 num_totoal_samples。举个例子，假如有两个尺度，这两个尺度的采样数分别为 2 和 3。那么对于第一个尺度应该占总 loss 的 2/5，对于第二个尺度应该占总 loss 的 3/5。这样各个尺度的 loss 之和就是总 loss。下面我们看一下源码："
      ],
      "metadata": {
        "id": "Ae_1QJAxGtjr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "   def loss_single(self, cls_score, bbox_pred, anchors, labels, label_weights,\n",
        "                    bbox_targets, bbox_weights, num_total_samples):\n",
        "        \"\"\"计算单个尺度的损失.\n",
        "\n",
        "        Args:\n",
        "            cls_score:      (Tensor): 单尺度的 box score, 形状 (batch, n_anchors * n_classes, H, W).\n",
        "            bbox_pred:      (Tensor): 单尺度 bbox 的修正量, 形状 (batch, n_anchors * 4, H, W)\n",
        "            anchors:        (Tensor): 单个尺度的 anchor, 形状为 (batch, n_anchors, 4).\n",
        "            labels:         (Tensor): 每个 anchor 的标签, 形状为 (batch, n_anchors)\n",
        "            label_weights:  (Tensor): label 的权重, 形状为 (batch, n_anchors)\n",
        "            bbox_targets:   (Tensor): bbox 的修正量, 形状为 (batch, n_anchors, 4).\n",
        "            bbox_weights:   (Tensor): bbox 修正量的权重, 形状为 (batch, n_anchors, 4).\n",
        "            num_total_samples  (int): 如果采样, 则 num_total_samples 等于锚点总数, 否则为正样本数量。\n",
        "\n",
        "        Returns:\n",
        "            loss_cls:   (Tensor)    分类的损失值\n",
        "            loss_bbox:  (Tensor)    回归的损失值\n",
        "        \"\"\"\n",
        "        # 分类损失\n",
        "        # torch.Size([batch, n_anchors]) --> torch.Size([batch × n_anchors])\n",
        "        labels = labels.reshape(-1)\n",
        "        label_weights = label_weights.reshape(-1)\n",
        "\n",
        "        # torch.Size([batch, n_anchors × 类别数, H, W]) -->  torch.Size([batch × H × W × n_anchor, 类别数])\n",
        "        cls_score = cls_score.permute(0, 2, 3,\n",
        "                                      1).reshape(-1, self.cls_out_channels)\n",
        "        # 对正负样本计算分类损失, 因为最后要相加, 所以这里 avg_factor=正负样本总数作为分子.\n",
        "        loss_cls = self.loss_cls(\n",
        "            cls_score, labels, label_weights, avg_factor=num_total_samples)\n",
        "        # 回归损失\n",
        "        bbox_targets = bbox_targets.reshape(-1, 4)\n",
        "        bbox_weights = bbox_weights.reshape(-1, 4)\n",
        "        bbox_pred = bbox_pred.permute(0, 2, 3, 1).reshape(-1, 4)\n",
        "        if self.reg_decoded_bbox:\n",
        "            anchors = anchors.reshape(-1, 4)\n",
        "            bbox_pred = self.bbox_coder.decode(anchors, bbox_pred)\n",
        "        # 只计算正样本的回归损失\n",
        "        loss_bbox = self.loss_bbox(\n",
        "            bbox_pred,\n",
        "            bbox_targets,\n",
        "            bbox_weights,\n",
        "            avg_factor=num_total_samples)\n",
        "        return loss_cls, loss_bbox"
      ],
      "metadata": {
        "id": "6ltaXAhnGv-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "（十）loss\n",
        "此方法为 RPN 损失的计算方法。输入经过 RPN 后的多尺度的分类和回归预测结果和 gt bbox。此函数会调用 loss_single 分别计算每个尺度的损失，输出每个尺度分类损失的列表与回归损失的列表的字典。"
      ],
      "metadata": {
        "id": "4CU8qV-jGxeT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " @force_fp32(apply_to=('cls_scores', 'bbox_preds'))\n",
        "    def loss(self,\n",
        "             cls_scores,\n",
        "             bbox_preds,\n",
        "             gt_bboxes,\n",
        "             gt_labels,\n",
        "             img_metas,\n",
        "             gt_bboxes_ignore=None):\n",
        "        \"\"\"计算 Head 的损失\n",
        "\n",
        "        Args:\n",
        "            cls_scores:  (list[Tensor])  多个尺度的预测的置信度 list,\n",
        "                                         其中每个尺度的 tensor 的形状为 [batch, n_anchors × 类别数, H, W]\n",
        "            bbox_preds:  (list[Tensor])  多个尺度位置的修正量的 list,\n",
        "                                         其中每个尺度的 tensor 的形状为 [batch, n_anchors × 4, H, W]\n",
        "            gt_bboxes:   (list[Tensor])  一个 batch 每张图片的 ground truth. list 的长度为 batch 长度.\n",
        "                                         每个 tensor 的形状为 (num_gts, 4) 其中维度 1 代表 [tl_x, tl_y, br_x, br_y]\n",
        "            gt_labels:   (list[Tensor])  每个 gt box 的类别索引.\n",
        "            img_metas:  (list[dict]):    一个批次的图像的属性信息\n",
        "            gt_bboxes_ignore (None | list[Tensor]): specify which bounding\n",
        "                boxes can be ignored when computing the loss. Default: None\n",
        "\n",
        "        Returns:\n",
        "            dict[str, Tensor]: 损失的字典\n",
        "        \"\"\"\n",
        "        # 获取各个尺度 feature map 大小\n",
        "        featmap_sizes = [featmap.size()[-2:] for featmap in cls_scores]\n",
        "        assert len(featmap_sizes) == self.anchor_generator.num_levels\n",
        "\n",
        "        device = cls_scores[0].device\n",
        "        # 获取一个批次的 anchor 和 valid flag\n",
        "        anchor_list, valid_flag_list = self.get_anchors(\n",
        "            featmap_sizes, img_metas, device=device)\n",
        "\n",
        "        label_channels = self.cls_out_channels if self.use_sigmoid_cls else 1\n",
        "        # 得到训练的 target\n",
        "        cls_reg_targets = self.get_targets(\n",
        "            anchor_list,\n",
        "            valid_flag_list,\n",
        "            gt_bboxes,\n",
        "            img_metas,\n",
        "            gt_bboxes_ignore_list=gt_bboxes_ignore,\n",
        "            gt_labels_list=gt_labels,\n",
        "            label_channels=label_channels)\n",
        "        if cls_reg_targets is None:\n",
        "            return None\n",
        "        # labels_list:  多个尺度的 list, 每个尺度的 tensor 形状 [batch, n_anchors]\n",
        "        # label_weights_list: 多个尺度的 list, 每个尺度的 tensor 形状 [batch, n_anchors]\n",
        "        # bbox_targets_list:  多个尺度的 list, 每个尺度的 tensor 形状 [batch, n_anchors, 4]\n",
        "        # bbox_weights_list:  多个尺度的 list, 每个尺度的 tensor 形状 [batch, n_anchors, 4]\n",
        "        # num_total_pos: 正样本总数\n",
        "        # num_total_neg: 负样本总数\n",
        "        (labels_list, label_weights_list, bbox_targets_list, bbox_weights_list,\n",
        "         num_total_pos, num_total_neg) = cls_reg_targets\n",
        "        # 计算样本总数, 如果不采样, 总数为正样本个数. 否则为正负样本总个数\n",
        "        num_total_samples = (\n",
        "            num_total_pos + num_total_neg if self.sampling else num_total_pos)\n",
        "\n",
        "        # 获得每个尺度的 anchor 数量\n",
        "        num_level_anchors = [anchors.size(0) for anchors in anchor_list[0]]\n",
        "        # 把 anchor 变成含多个尺度的 list\n",
        "        concat_anchor_list = []\n",
        "        for i in range(len(anchor_list)):\n",
        "            concat_anchor_list.append(torch.cat(anchor_list[i]))\n",
        "        all_anchor_list = images_to_levels(concat_anchor_list,\n",
        "                                           num_level_anchors)\n",
        "\n",
        "        losses_cls, losses_bbox = multi_apply(\n",
        "            self.loss_single,\n",
        "            cls_scores,\n",
        "            bbox_preds,\n",
        "            all_anchor_list,\n",
        "            labels_list,\n",
        "            label_weights_list,\n",
        "            bbox_targets_list,\n",
        "            bbox_weights_list,\n",
        "            num_total_samples=num_total_samples)\n",
        "        return dict(loss_cls=losses_cls, loss_bbox=losses_bbox"
      ],
      "metadata": {
        "id": "Inn34llAG0S3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "（十一）get_bboxes\n",
        "输入经过 RPN 预测的各个尺度的置信度和 bbox 修正量，此函数会调用 _get_bboxes_single 输出一个批次的 proposal 的列表。每个元素是一张图片的 proposal，每个 proposal 的形状为 （nms_post, 5）代表解码后的 bbox 坐标和置信度预测。"
      ],
      "metadata": {
        "id": "e8SDcLUCG1E5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@force_fp32(apply_to=('cls_scores', 'bbox_preds'))\n",
        "    def get_bboxes(self,\n",
        "                   cls_scores,\n",
        "                   bbox_preds,\n",
        "                   img_metas,\n",
        "                   cfg=None,\n",
        "                   rescale=False):\n",
        "        \"\"\"将网络的输出转化为一个批次的预测\n",
        "\n",
        "        Args:\n",
        "            cls_scores:     (list[Tensor]):         每个尺度的 bbox 分数预测, 形状为 (batch, n_anchors * n_classes, H, W)\n",
        "            bbox_preds:     (list[Tensor]):         每个尺度的 bbox 修正量, 形状为 (batch, n_anchors * 4, H, W)\n",
        "            img_metas:      (list[dict]):           一个批次的图像属性信息\n",
        "            cfg:            (mmcv.Config | None):   Test / postprocessing 配置文件, 如果为 None, 将会使用 test_cfg\n",
        "            rescale:        (bool):                 如果为 True, 则返回原始图像空间中的框, 默认值：False.\n",
        "\n",
        "        Returns:\n",
        "            list(Tensor):   一个批次每个图片的 proposal 的列表, 每个 Tensor 的形状为 (nms_post, 5), \n",
        "                            其中前四列代表解码后的 bbox 坐标, 最后一列代表置信度.\n",
        "\n",
        "        Example:\n",
        "            >>> import mmcv\n",
        "            >>> self = AnchorHead(\n",
        "            >>>     num_classes=9,\n",
        "            >>>     in_channels=1,\n",
        "            >>>     anchor_generator=dict(\n",
        "            >>>         type='AnchorGenerator',\n",
        "            >>>         scales=[8],\n",
        "            >>>         ratios=[0.5, 1.0, 2.0],\n",
        "            >>>         strides=[4,]))\n",
        "            >>> img_metas = [{'img_shape': (32, 32, 3), 'scale_factor': 1}]\n",
        "            >>> cfg = mmcv.Config(dict(\n",
        "            >>>     score_thr=0.00,\n",
        "            >>>     nms=dict(type='nms', iou_thr=1.0),\n",
        "            >>>     max_per_img=10))\n",
        "            >>> feat = torch.rand(1, 1, 3, 3)\n",
        "            >>> cls_score, bbox_pred = self.forward_single(feat)\n",
        "            >>> # note the input lists are over different levels, not images\n",
        "            >>> cls_scores, bbox_preds = [cls_score], [bbox_pred]\n",
        "            >>> result_list = self.get_bboxes(cls_scores, bbox_preds,\n",
        "            >>>                               img_metas, cfg)\n",
        "            >>> det_bboxes, det_labels = result_list[0]\n",
        "            >>> assert len(result_list) == 1\n",
        "            >>> assert det_bboxes.shape[1] == 5\n",
        "            >>> assert len(det_bboxes) == len(det_labels) == cfg.max_per_img\n",
        "        \"\"\"\n",
        "        assert len(cls_scores) == len(bbox_preds)\n",
        "        num_levels = len(cls_scores)\n",
        "\n",
        "        device = cls_scores[0].device\n",
        "        # 获取每个尺度的 feature map 大小\n",
        "        featmap_sizes = [cls_scores[i].shape[-2:] for i in range(num_levels)]\n",
        "        # 生成 anchor\n",
        "        mlvl_anchors = self.anchor_generator.grid_anchors(\n",
        "            featmap_sizes, device=device)\n",
        "\n",
        "        result_list = []\n",
        "        # 遍历 batch 里的每个图片\n",
        "        for img_id in range(len(img_metas)):\n",
        "            # 获取一个图片每个尺度的 anchor 的分数的列表.\n",
        "            # list(anchor × 类别数, H, W), list 代表每个尺度的列表\n",
        "            cls_score_list = [\n",
        "                cls_scores[i][img_id].detach() for i in range(num_levels)\n",
        "            ]\n",
        "            # 获取一张图片每个尺度的 anchor 的 bbox 修正量的列表.\n",
        "            # list(anchor × 4, H, W), list 代表每个尺度的列表\n",
        "            bbox_pred_list = [\n",
        "                bbox_preds[i][img_id].detach() for i in range(num_levels)\n",
        "            ]\n",
        "            img_shape = img_metas[img_id]['img_shape']\n",
        "            scale_factor = img_metas[img_id]['scale_factor']\n",
        "            proposals = self._get_bboxes_single(cls_score_list, bbox_pred_list,\n",
        "                                                mlvl_anchors, img_shape,\n",
        "                                                scale_factor, cfg, rescale)\n",
        "            result_list.append(proposals)\n",
        "        return result_lis"
      ],
      "metadata": {
        "id": "FvM0NcYNG2ua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "（十二）_get_bboxes_single（RPNHead 会重写）\n",
        "这部分的代码会在 RPNHead 中重写，和 RPN 不是很相关，所以不会详细的讲解。有兴趣的可以看看下面的代码："
      ],
      "metadata": {
        "id": "gP1mza2HG5Iy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "def _get_bboxes_single(self,\n",
        "                           cls_score_list,\n",
        "                           bbox_pred_list,\n",
        "                           mlvl_anchors,\n",
        "                           img_shape,\n",
        "                           scale_factor,\n",
        "                           cfg,\n",
        "                           rescale=False):\n",
        "        \"\"\"Transform outputs for a single batch item into bbox predictions.\n",
        "\n",
        "        Args:\n",
        "            cls_score_list (list[Tensor]): Box scores for a single scale level\n",
        "                Has shape (num_anchors * num_classes, H, W).\n",
        "            bbox_pred_list (list[Tensor]): Box energies / deltas for a single\n",
        "                scale level with shape (num_anchors * 4, H, W).\n",
        "            mlvl_anchors (list[Tensor]): Box reference for a single scale level\n",
        "                with shape (num_total_anchors, 4).\n",
        "            img_shape (tuple[int]): Shape of the input image,\n",
        "                (height, width, 3).\n",
        "            scale_factor (ndarray): Scale factor of the image arange as\n",
        "                (w_scale, h_scale, w_scale, h_scale).\n",
        "            cfg (mmcv.Config): Test / postprocessing configuration,\n",
        "                if None, test_cfg would be used.\n",
        "            rescale (bool): If True, return boxes in original image space.\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Labeled boxes in shape (n, 5), where the first 4 columns\n",
        "                are bounding box positions (tl_x, tl_y, br_x, br_y) and the\n",
        "                5-th column is a score between 0 and 1.\n",
        "        \"\"\"\n",
        "        cfg = self.test_cfg if cfg is None else cfg\n",
        "        assert len(cls_score_list) == len(bbox_pred_list) == len(mlvl_anchors)\n",
        "        mlvl_bboxes = []\n",
        "        mlvl_scores = []\n",
        "        for cls_score, bbox_pred, anchors in zip(cls_score_list,\n",
        "                                                 bbox_pred_list, mlvl_anchors):\n",
        "            assert cls_score.size()[-2:] == bbox_pred.size()[-2:]\n",
        "            cls_score = cls_score.permute(1, 2,\n",
        "                                          0).reshape(-1, self.cls_out_channels)\n",
        "            if self.use_sigmoid_cls:\n",
        "                scores = cls_score.sigmoid()\n",
        "            else:\n",
        "                scores = cls_score.softmax(-1)\n",
        "            bbox_pred = bbox_pred.permute(1, 2, 0).reshape(-1, 4)\n",
        "            nms_pre = cfg.get('nms_pre', -1)\n",
        "            if nms_pre > 0 and scores.shape[0] > nms_pre:\n",
        "                # Get maximum scores for foreground classes.\n",
        "                if self.use_sigmoid_cls:\n",
        "                    max_scores, _ = scores.max(dim=1)\n",
        "                else:\n",
        "                    # remind that we set FG labels to [0, num_class-1]\n",
        "                    # since mmdet v2.0\n",
        "                    # BG cat_id: num_class\n",
        "                    max_scores, _ = scores[:, :-1].max(dim=1)\n",
        "                _, topk_inds = max_scores.topk(nms_pre)\n",
        "                anchors = anchors[topk_inds, :]\n",
        "                bbox_pred = bbox_pred[topk_inds, :]\n",
        "                scores = scores[topk_inds, :]\n",
        "            bboxes = self.bbox_coder.decode(\n",
        "                anchors, bbox_pred, max_shape=img_shape)\n",
        "            mlvl_bboxes.append(bboxes)\n",
        "            mlvl_scores.append(scores)\n",
        "        mlvl_bboxes = torch.cat(mlvl_bboxes)\n",
        "        if rescale:\n",
        "            mlvl_bboxes /= mlvl_bboxes.new_tensor(scale_factor)\n",
        "        mlvl_scores = torch.cat(mlvl_scores)\n",
        "        if self.use_sigmoid_cls:\n",
        "            # Add a dummy background class to the backend when using sigmoid\n",
        "            # remind that we set FG labels to [0, num_class-1] since mmdet v2.0\n",
        "            # BG cat_id: num_class\n",
        "            padding = mlvl_scores.new_zeros(mlvl_scores.shape[0], 1)\n",
        "            mlvl_scores = torch.cat([mlvl_scores, padding], dim=1)\n",
        "        det_bboxes, det_labels = multiclass_nms(mlvl_bboxes, mlvl_scores,\n",
        "                                                cfg.score_thr, cfg.nms,\n",
        "                                                cfg.max_per_img)\n",
        "        return det_bboxes, det_labels"
      ],
      "metadata": {
        "id": "dhR1Xl1gG9Qs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "四、RPNTestMixin\n",
        "此类提供了 RPN 在测试时需要调用的方法，RPN 一般在测试时会调用 simple_test_rpn。对于经过 backbone 和 neck 生成的特征图。直接调用 forward 方法生成所有 bbox 的置信度和位置的修正量。然后不需要计算损失，直接调用 get_bboxes 为 roi_head 生成候选区域。具体源码如下："
      ],
      "metadata": {
        "id": "Ogqr7QrBG_Gt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "from mmdet.core import merge_aug_proposals\n",
        "\n",
        "if sys.version_info >= (3, 7):\n",
        "    from mmdet.utils.contextmanagers import completed\n",
        "\n",
        "\n",
        "class RPNTestMixin(object):\n",
        "    \"\"\"Test methods of RPN.\"\"\"\n",
        "\n",
        "    if sys.version_info >= (3, 7):\n",
        "\n",
        "        async def async_simple_test_rpn(self, x, img_metas):\n",
        "            sleep_interval = self.rpn_head.test_cfg.pop(\n",
        "                'async_sleep_interval', 0.025)\n",
        "            async with completed(\n",
        "                    __name__, 'rpn_head_forward',\n",
        "                    sleep_interval=sleep_interval):\n",
        "                rpn_outs = self(x)\n",
        "\n",
        "            proposal_list = self.get_bboxes(*rpn_outs, img_metas)\n",
        "            return proposal_list\n",
        "\n",
        "    def simple_test_rpn(self, x, img_metas):\n",
        "        \"\"\"Test without augmentation.\n",
        "\n",
        "        Args:\n",
        "            x:          (tuple[Tensor]):    经过 backbone 和 neck 后的 features 的元祖, 每个元素是一个尺度的 feature.\n",
        "            img_metas:  (list[dict]):       每个图像的属性信息\n",
        "\n",
        "        Returns:\n",
        "            list[Tensor]:   每个图片生成的 Proposals\n",
        "        \"\"\"\n",
        "        rpn_outs = self(x)\n",
        "        proposal_list = self.get_bboxes(*rpn_outs, img_metas)\n",
        "        return proposal_list\n",
        "\n",
        "    def aug_test_rpn(self, feats, img_metas):\n",
        "        samples_per_gpu = len(img_metas[0])\n",
        "        aug_proposals = [[] for _ in range(samples_per_gpu)]\n",
        "        for x, img_meta in zip(feats, img_metas):\n",
        "            proposal_list = self.simple_test_rpn(x, img_meta)\n",
        "            for i, proposals in enumerate(proposal_list):\n",
        "                aug_proposals[i].append(proposals)\n",
        "        # reorganize the order of 'img_metas' to match the dimensions\n",
        "        # of 'aug_proposals'\n",
        "        aug_img_metas = []\n",
        "        for i in range(samples_per_gpu):\n",
        "            aug_img_meta = []\n",
        "            for j in range(len(img_metas)):\n",
        "                aug_img_meta.append(img_metas[j][i])\n",
        "            aug_img_metas.append(aug_img_meta)\n",
        "        # after merging, proposals will be rescaled to the original image size\n",
        "        merged_proposals = [\n",
        "            merge_aug_proposals(proposals, aug_img_meta, self.test_cfg)\n",
        "            for proposals, aug_img_meta in zip(aug_proposals, aug_img_metas)\n",
        "        ]\n",
        "        return merged_proposals"
      ],
      "metadata": {
        "id": "eHflxWmXHBf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "五、RPNHead（继承 AnchorHead 和 RPNTestMixin）\n",
        "RPNHead 继承了 AnchorHead 和 RPNTestMixin。其中 AnchorHead 负责提供 Anchor 的一些通用的接口和公共方法，并完成了训练部分的代码。RPNTestMixin 负责 RPN 的预测部分。"
      ],
      "metadata": {
        "id": "2UpHR-phHDcA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from mmcv.cnn import normal_init\n",
        "from mmcv.ops import batched_nms\n",
        "\n",
        "from ..builder import HEADS\n",
        "from .anchor_head import AnchorHead\n",
        "from .rpn_test_mixin import RPNTestMixin\n",
        "\n",
        "\n",
        "@HEADS.register_module()\n",
        "class RPNHead(RPNTestMixin, AnchorHead):\n",
        "    \"\"\"RPN head.\n",
        "\n",
        "    Args:\n",
        "        in_channels (int): feature map 的输入通道数\n",
        "    \"\"\"  # noqa: W605\n",
        "\n",
        "    def __init__(self, in_channels, **kwargs):\n",
        "        # RPN 的背景类为 0, 类别数为 1\n",
        "        super(RPNHead, self).__init__(\n",
        "            1, in_channels, background_label=0, **kwargs)\n",
        "\n",
        "    def _init_layers(self):\n",
        "        \"\"\"初始化 head 的层\"\"\"\n",
        "        # 先用 3 x 3, 通道数为 256 的卷积.\n",
        "        self.rpn_conv = nn.Conv2d(\n",
        "            self.in_channels, self.feat_channels, 3, padding=1)\n",
        "        # 然后接上两个 1 x 1 的卷积核:\n",
        "        # cls 分支: 通道数, anchor 的数量 × 类别个数, 因为使用 sigmoid 所以类别个数设置为 1.\n",
        "        self.rpn_cls = nn.Conv2d(self.feat_channels,\n",
        "                                 self.num_anchors * self.cls_out_channels, 1)\n",
        "        # reg 分支: 通道数, anchor 的数量 × 4\n",
        "        self.rpn_reg = nn.Conv2d(self.feat_channels, self.num_anchors * 4, 1)\n",
        "\n",
        "    def init_weights(self):\n",
        "        \"\"\"初始化 head 的权重\"\"\"\n",
        "        # 将所有卷积初始化为均值为 0 方差为 0.01 的正态分布\n",
        "        normal_init(self.rpn_conv, std=0.01)\n",
        "        normal_init(self.rpn_cls, std=0.01)\n",
        "        normal_init(self.rpn_reg, std=0.01)\n",
        "\n",
        "    def forward_single(self, x):\n",
        "        \"\"\"单尺度前向传播\"\"\"\n",
        "        # 所有尺度都使用相同的 conv 预测.\n",
        "        x = self.rpn_conv(x)\n",
        "        x = F.relu(x, inplace=True)\n",
        "        # 注意输出的时候不要使用 relu\n",
        "        rpn_cls_score = self.rpn_cls(x)\n",
        "        rpn_bbox_pred = self.rpn_reg(x)\n",
        "        return rpn_cls_score, rpn_bbox_pred\n",
        "\n",
        "    def loss(self,\n",
        "             cls_scores,\n",
        "             bbox_preds,\n",
        "             gt_bboxes,\n",
        "             img_metas,\n",
        "             gt_bboxes_ignore=None):\n",
        "        \"\"\"计算 head 的损失\n",
        "\n",
        "        Args:\n",
        "            cls_scores:    (list[Tensor])   每个尺度预测的 bbox 的 score,\n",
        "                                            每个 tensor 的形状为 (N, anchor 数量 × 类别数, H, W)\n",
        "            bbox_preds:    (list[Tensor])   每个尺度预测的 bbox 的位置偏移.\n",
        "                                            每个 tensor 的形状为 (N, anchor 数量 × 4, H, W)\n",
        "            gt_bboxes:     (list[Tensor])   每个图片的 Ground truth bboxes,\n",
        "                                            每个 tensor 的形状为 (num_gts, 4), 其中 4 为 [tl_x, tl_y, br_x, br_y]\n",
        "            img_metas:     (list[dict])     每个图片的信息. 例如图片大小等\n",
        "            gt_bboxes_ignore: (None | list[Tensor]): 指定哪个 bbox 在计算损失的时候会被忽略.\n",
        "\n",
        "        Returns:\n",
        "            dict[str, Tensor]: 多个损失的组成的字典.\n",
        "        \"\"\"\n",
        "        losses = super(RPNHead, self).loss(\n",
        "            cls_scores,\n",
        "            bbox_preds,\n",
        "            gt_bboxes,\n",
        "            None,\n",
        "            img_metas,\n",
        "            gt_bboxes_ignore=gt_bboxes_ignore)\n",
        "        return dict(\n",
        "            loss_rpn_cls=losses['loss_cls'], loss_rpn_bbox=losses['loss_bbox'])\n",
        "\n",
        "    def _get_bboxes_single(self,\n",
        "                           cls_scores,\n",
        "                           bbox_preds,\n",
        "                           mlvl_anchors,\n",
        "                           img_shape,\n",
        "                           scale_factor,\n",
        "                           cfg,\n",
        "                           rescale=False):\n",
        "        \"\"\"将一张图片的输出转化为 bbox 的结果.\n",
        "\n",
        "        Args:\n",
        "            cls_scores:     (list[Tensor]):    网络输出的 confidence, list 的长度为 level 的长度(5),\n",
        "                                               每个 tensor 的形状是 [K, H, W]\n",
        "            bbox_preds:     (list[Tensor]):    网络输出的坐标值, list 代表每个尺度(如： 长度 5),\n",
        "                                               每个 tensor 的形状是 [4K, H, W]\n",
        "            mlvl_anchors:   (list[Tensor]):    每个 scale 的生成的 anchor,\n",
        "                                               每个 tensor 的形状为: [H × W × K, 4]\n",
        "            img_shape:      (tuple[int]):      图像的大小\n",
        "            scale_factor:   (ndarray):         Scale factor of the image arange as\n",
        "                (w_scale, h_scale, w_scale, h_scale).\n",
        "            cfg:            (mmcv.Config):     Test / postprocessing configuration,\n",
        "                if None, test_cfg would be used.\n",
        "            rescale (bool): If True, return boxes in original image space.\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Labeled boxes in shape (n, 5), where the first 4 columns\n",
        "                are bounding box positions (tl_x, tl_y, br_x, br_y) and the\n",
        "                5-th column is a score between 0 and 1.\n",
        "        \"\"\"\n",
        "        # 1. 根据类别的置信度筛选出每个尺度 topK（K = 2000）个 bbox\n",
        "        # 2. 合并筛选后的多个尺度的 bbox\n",
        "        # 3. 将网络预测值解码\n",
        "        # 4. 用 nms（阈值=0.7）合并 bbox\n",
        "        # 5. 筛选出前 nms_post（1000）个 bbox 作为 proposal\n",
        "\n",
        "        cfg = self.test_cfg if cfg is None else cfg\n",
        "        # bboxes from different level should be independent during NMS,\n",
        "        # level_ids are used as labels for batched NMS to separate them\n",
        "        level_ids = []\n",
        "        mlvl_scores = []\n",
        "        mlvl_bbox_preds = []\n",
        "        mlvl_valid_anchors = []\n",
        "        # 遍历每个尺度\n",
        "        for idx in range(len(cls_scores)):\n",
        "            # 取到一个尺度的网络输出的类别和位置预测\n",
        "            rpn_cls_score = cls_scores[idx]\n",
        "            rpn_bbox_pred = bbox_preds[idx]\n",
        "            # 保证后两个维度相同\n",
        "            assert rpn_cls_score.size()[-2:] == rpn_bbox_pred.size()[-2:]\n",
        "            # [A, H, W] --> [H, W, A]\n",
        "            rpn_cls_score = rpn_cls_score.permute(1, 2, 0)\n",
        "            # 将类别的数值压缩成概率.\n",
        "            if self.use_sigmoid_cls:\n",
        "                # [H × W × A]\n",
        "                rpn_cls_score = rpn_cls_score.reshape(-1)\n",
        "                scores = rpn_cls_score.sigmoid()\n",
        "            else:\n",
        "                # 转成 (-1, 2), 这个 2 代表是背景或不是背景。\n",
        "                # 前景 label 设置为:  [0, 类别数 - 1],\n",
        "                # 背景 label 设置为:  类别数\n",
        "                rpn_cls_score = rpn_cls_score.reshape(-1, 2)\n",
        "                # we set FG labels to [0, num_class-1] and BG label to\n",
        "                # num_class in other heads since mmdet v2.0, However we\n",
        "                # keep BG label as 0 and FG label as 1 in rpn head\n",
        "                # 对类别维度进行 softmax, 取背景的概率\n",
        "                # 形状：[2000]\n",
        "                scores = rpn_cls_score.softmax(dim=1)[:, 1]\n",
        "            # [A × 4, H, W] --> [H × W × A, 4]\n",
        "            rpn_bbox_pred = rpn_bbox_pred.permute(1, 2, 0).reshape(-1, 4)\n",
        "            # 取对应层的 anchor: [单尺度 anchor 总数, 4]\n",
        "            anchors = mlvl_anchors[idx]\n",
        "\n",
        "            # 根据类别的置信度筛选出 topK 个 box\n",
        "            if cfg.nms_pre > 0 and scores.shape[0] > cfg.nms_pre:\n",
        "                # sort is faster than topk\n",
        "                # _, topk_inds = scores.topk(cfg.nms_pre)\n",
        "                # 对 score 从高到低排序\n",
        "                # [182400]\n",
        "                ranked_scores, rank_inds = scores.sort(descending=True)\n",
        "                # 取 topK（cfg.nms_pre） 个 index 和 score: anchor --> [2000]\n",
        "                topk_inds = rank_inds[:cfg.nms_pre]\n",
        "                scores = ranked_scores[:cfg.nms_pre]\n",
        "                # 根据类别的预测值，取 topK 个 bbox\n",
        "                rpn_bbox_pred = rpn_bbox_pred[topk_inds, :]\n",
        "                # anchor 也取 topK 个\n",
        "                anchors = anchors[topk_inds, :]\n",
        "            mlvl_scores.append(scores)\n",
        "            mlvl_bbox_preds.append(rpn_bbox_pred)\n",
        "            mlvl_valid_anchors.append(anchors)\n",
        "            # new_full(形状，填充值，数据类型)\n",
        "            level_ids.append(\n",
        "                scores.new_full((scores.size(0), ), idx, dtype=torch.long))\n",
        "        # cat 的 dim 默认为 0 维\n",
        "        scores = torch.cat(mlvl_scores)\n",
        "        anchors = torch.cat(mlvl_valid_anchors)\n",
        "        rpn_bbox_pred = torch.cat(mlvl_bbox_preds)\n",
        "        proposals = self.bbox_coder.decode(\n",
        "            anchors, rpn_bbox_pred, max_shape=img_shape)\n",
        "        ids = torch.cat(level_ids)\n",
        "\n",
        "        # 如多对 anchor 的大小有限定\n",
        "        if cfg.min_bbox_size > 0:\n",
        "            # 计算 W, H\n",
        "            w = proposals[:, 2] - proposals[:, 0]\n",
        "            h = proposals[:, 3] - proposals[:, 1]\n",
        "            # 取长宽都 > min_bbox_size 的索引\n",
        "            valid_inds = torch.nonzero(\n",
        "                (w >= cfg.min_bbox_size)\n",
        "                & (h >= cfg.min_bbox_size),\n",
        "                as_tuple=False).squeeze()\n",
        "            # 筛选目标\n",
        "            if valid_inds.sum().item() != len(proposals):\n",
        "                proposals = proposals[valid_inds, :]\n",
        "                scores = scores[valid_inds]\n",
        "                ids = ids[valid_inds]\n",
        "\n",
        "        # TODO: remove the hard coded nms type\n",
        "        nms_cfg = dict(type='nms', iou_threshold=cfg.nms_thr)\n",
        "        dets, keep = batched_nms(proposals, scores, ids, nms_cfg)\n",
        "        # nms 后对置信度有排序。直接取前 nms_post 个\n",
        "        return dets[:cfg.nms_post]"
      ],
      "metadata": {
        "id": "z2ZyFC2UHHQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [源码解读：Faster RCNN的细节（一）](https://zhuanlan.zhihu.com/p/65471961)\n",
        "\n",
        "![](https://pica.zhimg.com/v2-2a51ac64bbb4b620ab1aa90f1793b898_1440w.jpg?source=172ae18b)"
      ],
      "metadata": {
        "id": "Kb0DufuYb3os"
      }
    }
  ]
}