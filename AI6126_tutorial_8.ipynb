{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI6126_tutorial_8.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNCN/8IA9IoWIovsJZ+Nbxd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jinyingtld/python/blob/main/AI6126_tutorial_8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0RJyuNy7Y3nh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bbab1c1-97fe-4be9-99d3-b87d412c5359"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.5.1+cu101\n",
            "  Downloading https://download.pytorch.org/whl/cu101/torch-1.5.1%2Bcu101-cp37-cp37m-linux_x86_64.whl (704.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 704.4 MB 1.2 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.6.1+cu101\n",
            "  Downloading https://download.pytorch.org/whl/cu101/torchvision-0.6.1%2Bcu101-cp37-cp37m-linux_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 51.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.5.1+cu101) (1.21.6)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.5.1+cu101) (0.16.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.6.1+cu101) (7.1.2)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.0+cu111\n",
            "    Uninstalling torch-1.10.0+cu111:\n",
            "      Successfully uninstalled torch-1.10.0+cu111\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.11.1+cu111\n",
            "    Uninstalling torchvision-0.11.1+cu111:\n",
            "      Successfully uninstalled torchvision-0.11.1+cu111\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.5.1+cu101 which is incompatible.\n",
            "torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.5.1+cu101 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.5.1+cu101 torchvision-0.6.1+cu101\n"
          ]
        }
      ],
      "source": [
        "# Install dependencies: (use cu101 because colab has CUDA 10.1)\n",
        "!pip install -U torch==1.5.1+cu101 torchvision==0.6.1+cu101 -f https://download.pytorch.org/whl/torch_stable.html"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a MNISTM dataset class\n",
        "# MNISTM isn't supported by torchvision\n",
        "#https://github.com/liyxi/mnist-m\n",
        "import os\n",
        "import warnings\n",
        "\n",
        "import torch\n",
        "from PIL import Image\n",
        "from torchvision.datasets import VisionDataset\n",
        "from torchvision.datasets.utils import download_and_extract_archive \n",
        "\n",
        "\n",
        "class MNISTM(VisionDataset):\n",
        "    \"\"\"\n",
        "    MNIST-M Dataset.\n",
        "    \"\"\"\n",
        "\n",
        "    resources = [\n",
        "        ('https://github.com/liyxi/mnist-m/releases/download/data/mnist_m_train.pt.tar.gz',\n",
        "         '191ed53db9933bd85cc9700558847391'),\n",
        "        ('https://github.com/liyxi/mnist-m/releases/download/data/mnist_m_test.pt.tar.gz',\n",
        "         'e11cb4d7fff76d7ec588b1134907db59')     \n",
        "    ]\n",
        "\n",
        "    training_file = \"mnist_m_train.pt\"\n",
        "    test_file = \"mnist_m_test.pt\"\n",
        "    classes = ['0 - zero','1 - one', '2 - two', '3 - three', '4 - four',\n",
        "               '5 - five', '6 - six', '7 - seven', '8 - eight', '9 - nine']\n",
        "    \n",
        "    def __init__(self, root, train=True, transform=None, target_transform=None, downlaod=False):\n",
        "        \"\"\"Init MNIST-M dataset.\"\"\"\n",
        "        super(MNISTM, self).__init__(root, transform=transform, target_transform=target_transform)\n",
        "        self.train=train\n",
        "\n",
        "        if downlaod:\n",
        "            self.download()\n",
        "        \n",
        "        if not self._check_exists():\n",
        "            raise RuntimeError(\"Dataset not found.\" + \n",
        "                               \"You can use download=True to download it\")\n",
        "        \n",
        "        if self.train:\n",
        "            data_file=self.train_file\n",
        "        else:\n",
        "            data_file=self.test_file\n",
        "        \n",
        "        print(os.path.join(self.processed_folder,data_file))\n",
        "\n",
        "        self.data, self.targets = torch.load(os.path.join(self.processed_folder,data_file))\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"Get images and target for data loader.\n",
        "        Args:\n",
        "            index (int):Index\n",
        "        returns:\n",
        "            tuple: (image, target) where target is index of the target class.\n",
        "        \"\"\"\n",
        "        img, target = self.data[index], int(self.targets[index])\n",
        "\n",
        "        # doing this so that it is consistent with all other datasets\n",
        "        # to return a PIL Image\n",
        "        img = Image.fromarray(img.squeeze().numpy(), mode=\"RGB\")\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "        \n",
        "        if self.target_transform is not None:\n",
        "            target = self.target_transform(target)\n",
        "        \n",
        "        return img, target\n",
        "    \n",
        "    def __len__(self):\n",
        "        \"\"\"Return size of dataset.\"\"\"\n",
        "        return len(self.data)\n",
        "\n",
        "    @property\n",
        "    def train_labels(self):\n",
        "        warnings.warn(\"train_labels has been renamed targets\")\n",
        "        return self.targets\n",
        "    \n",
        "    @property\n",
        "    def test_labels(self):\n",
        "        warnings.warn(\"test_labels has been renamed targetrs\")\n",
        "        return self.targets\n",
        "    \n",
        "    @property\n",
        "    def train_data(self):\n",
        "        warnings.warn(\"train_data has been renamed data\")\n",
        "        return self.data\n",
        "    \n",
        "    @property\n",
        "    def test_data(self):\n",
        "        warnings.warn(\"test_data has been renamed data\")\n",
        "        return self.data\n",
        "    \n",
        "    @property\n",
        "    def raw_folder(self):\n",
        "        return os.path.join(self.root, self.__class__.__name__, 'raw')\n",
        "    \n",
        "    @property\n",
        "    def processed_folder(self):\n",
        "        return os.path.join(self.root, self.__class__.__name__,'processed')\n",
        "    \n",
        "    @property\n",
        "    def class_to_idx(self):\n",
        "        return {_class:i for i, _class in enumerate(self.classes)}\n",
        "\n",
        "    def _check_exists(self):\n",
        "        return (os.path.exists(os.path.join(self.processed_folder,self.training_file)) and \n",
        "                os.path.exists(os.path.join(self.processed_folder, self.test_file)))\n",
        "    \n",
        "    def download(self):\n",
        "        \"\"\"Download the MNIST-M data\"\"\"\n",
        "\n",
        "        if self._check_exists():\n",
        "            return\n",
        "        \n",
        "        os.makedirs(self.raw_folder, exist_ok=True)\n",
        "        os.makedirs(self.processed_folder, exist_ok=True)\n",
        "    \n",
        "        # download files\n",
        "        for url, md5 in self.resources:\n",
        "            filename = url.rpartition('/')[2]\n",
        "            download_and_extract_archive(url, download_root=self.raw_folder,\n",
        "                                         extract_root=self.processed_folder,\n",
        "                                         filename=filename, md5=md5)\n",
        "        print(\"Done!\")\n",
        "    \n",
        "    def extra_repr(self):\n",
        "        return \"Split: {}\".format(\"Train\" if self.train is True else \"Test\")\n",
        "    \n"
      ],
      "metadata": {
        "id": "uK6rBN7UqoX5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import packages\n",
        "import torch \n",
        "import torchvision\n",
        "from torch import nn\n",
        "from torch.autograd import Function\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms \n",
        "import matplotlib.pyplot as plt \n",
        "import numpy as np \n",
        "from tqdm import tqdm # show progress bar "
      ],
      "metadata": {
        "id": "tLeibRL9r0AV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure cuda is available \n",
        "print(f\"CUDA is available: {torch.cuda.is_available()}\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efaHCSNG67lp",
        "outputId": "cafef993-ff8a-4bde-fca6-ae20148b74c6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA is available: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download datasets\n",
        "# We use MNIST and MNIST-M in the tutorial\n",
        "# MNIST: hand-written digits (28x28)\n",
        "# MNIST-M: MNIST's background blended with random color patches\n",
        "tfm1 = transforms.Compose([\n",
        "    transforms.Grayscale(3), # convert to 3-channel\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307, 0.1307, 0.1307), (0.3081, 0.3081, 0.3081))\n",
        "])\n",
        "\n",
        "tfm2 = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307, 0.1307, 0.1307), (0.3081, 0.3081, 0.3081))\n",
        "])\n",
        "\n",
        "mnist_train = datasets.MNIST(root=\"./data\", train=True, download=True, transform=tfm1)\n",
        "mnist_test = datasets.MNIST(root=\"./data\", train=False, download=True, transform=tfm1)\n",
        "\n"
      ],
      "metadata": {
        "id": "BcrONx9o7cUg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}