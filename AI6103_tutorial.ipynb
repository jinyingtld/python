{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI6103_tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNfqOG+7GhuKBgQRfXi8IqP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jinyingtld/python/blob/main/AI6103_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pythong Programming \n",
        "\n",
        "* Pythong is a dynamic-typed language \n",
        "\n",
        "    - No static type-checking\n",
        "\n",
        "    - Flexible,succinct,though less efficient and error-prone\n",
        "\n",
        "* Pythong has many numerical libraries \n",
        "\n",
        "    - They call highly efficient C/C++ libraries behind the curtain\n",
        "\n",
        "    - LAPACK,BLAS,etc.\n",
        "\n",
        "* Great support for deep learning\n",
        "\n",
        "    - PyTorch,Tensorflow,Jax,Peddle,etc\n"
      ],
      "metadata": {
        "id": "ogJuXS1endkf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic of a Programming Language\n",
        "* Basic syntax\n",
        "* Data types\n",
        "* Control structure\n",
        "* Exceptions\n",
        "* Threads\n",
        "* Performance"
      ],
      "metadata": {
        "id": "R9Qf9pL-nBBU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic Syntax\n",
        "\n",
        "* Indentation and colon mark code blocks\n",
        "* Space-based indentations and tab-based are different!\n",
        "* can be super hard to debug!\n",
        "```\n",
        "sum = 0 \n",
        "for i in range(10):\n",
        "    sum += i\n",
        "print(sum)\n",
        "\n",
        "  sum is printed only once!\n",
        "sum = 0 \n",
        "for i in range(10):\n",
        "    sum += i + i**2 + \\\\\n",
        "    i**3\n",
        "print(sum)\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "F12A4-tNpRqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic Syntax\n",
        "* The return character marks end of line \n",
        "* To continue the same line of code, use the line continuation character \n",
        "\\'\\\\'\n",
        "* \\# is the beginning of a comment \n"
      ],
      "metadata": {
        "id": "HaKKGL8dt19B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Type \n",
        "* Integers have no limits on their value."
      ],
      "metadata": {
        "id": "ZsZkJVsPuctI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C515xEWnmmQM",
        "outputId": "12a68303-e611-4e7c-806b-8916604bf7cc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5541850949295918202405081540365965792972852977172558529301284205616899716558079354764343027580371566264227284283224328943216544902369965718411424586846692304538296607765149546800063770431101584710632766457476187127432980846740321915053107552729325604081860560805554161801453359513633683648277839933837013364541319950089537137346381263775423227192683614308120490424451247427541517608408025625601"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "num = 17 ** 320\n",
        "num"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Type\n",
        "* Integers have no limits on their value.\n",
        "* Floating point numbers, however, do have limits\n",
        "* 64-bit max approx $1.8 * 10^{308}$\n",
        "* 32-bit max approx $3.4 * 10^{38}$\n",
        "* 16-bit max approx $65,504$\n",
        "\n",
        "***Danger of overflow and underflow during mixed precision training***\n",
        "\n",
        "GPU - 32 bit"
      ],
      "metadata": {
        "id": "eBFmFcrhuwVd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Linked lists are first-class citizens"
      ],
      "metadata": {
        "id": "YDPxjRDJv6t1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nl = list()\n",
        "nl.append(3)\n",
        "nl.append(\"hello\")\n",
        "nl.append(8.1)\n",
        "nl\n",
        "# [3, 'hello', 8.1]\n",
        "\n",
        "nl = []\n",
        "nl = [3,0.2]\n",
        "nl\n",
        "# [3, 0.2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9Z7HucKv-UA",
        "outputId": "8f895d53-80a9-4443-d22c-93310f4b9f9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3, 0.2]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Objects are not encapsulated.\n",
        "* Pythong does not have the private keyword.\n",
        "* Based on convention, anything that starts with two underscores are private."
      ],
      "metadata": {
        "id": "RIAokcahwTcf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Robot(object):\n",
        "    def __init__(self):\n",
        "        self.a = 123\n",
        "        self._b = 223\n",
        "        self.__c = 323\n",
        "    \n",
        "obj = Robot()\n",
        "print(obj.a)\n",
        "print(obj._b)\n",
        "# print(obj.__c)\n",
        "# 123\n",
        "# 223\n",
        "# ---------------------------------------------------------------------------\n",
        "# AttributeError                            Traceback (most recent call last)\n",
        "# <ipython-input-9-c06c18ac550e> in <module>()\n",
        "#       8 print(obj.a)\n",
        "#       9 print(obj._b)\n",
        "# ---> 10 print(obj.__c)\n",
        "\n",
        "# AttributeError: 'Robot' object has no attribute '__c'\n",
        "\n",
        "print(obj.__dict__['_Robot__c'])\n",
        "# 323\n",
        "obj.__dict__ # does allow for hacks\n",
        "# {'_Robot__c': 323, '_b': 223, 'a': 123}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5pIpfJdwg2d",
        "outputId": "49779a45-2d2a-424e-d070-7e0271236304"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "123\n",
            "223\n",
            "323\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'_Robot__c': 323, '_b': 223, 'a': 123}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions \n",
        "* Pythong has some aspects of a functional language\n",
        "    - You can assign a functional to a variable"
      ],
      "metadata": {
        "id": "0uiOU-tTxjGQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def addone(x):\n",
        "    return x+1\n",
        "\n",
        "def addtwo(x):\n",
        "    return x+2\n",
        "\n",
        "f = addone\n",
        "print(f(1)) # result is 2\n",
        "f = addtwo\n",
        "print(f(1)) # result is 3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLGPtWUsxuDf",
        "outputId": "9b4be1f2-322c-4a6b-f20e-f86ce5495751"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions \n",
        "* Pythong has some aspects of a functional language\n",
        "    - You can assign a functional to a variable\n",
        "    - Python provides higher-order functions like Lisp\n",
        "        - map(),filter(),reduce(),etc."
      ],
      "metadata": {
        "id": "l3nDFWH2yGzo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import functools \n",
        "def add_one_more(x,y):\n",
        "    return x+y+1\n",
        "\n",
        "f = functools.partial(add_one_more,1)\n",
        "# this creates a partial function whose first argument is known but the second is not. \n",
        "print(f(2)) # result is 1+2+2=4\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCKacvaRyXIq",
        "outputId": "9f46e692-c128-4bfd-a773-257b19809c42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def add_one(x):\n",
        "    return x+1\n",
        "l1 = [1,2,3,4]\n",
        "l2 = list(map(add_one,l1))\n",
        "print(l2)\n",
        "l3 = [add_one(x) for x in l1]\n",
        "\n",
        "# thw two results are the same but many prefer the second style"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCnAZHs9zNFH",
        "outputId": "e552dca8-5714-4983-cbf3-53e0014eb094"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2, 3, 4, 5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multi-threading \n",
        "* You can create multiple threads in Python but they don't work as you expect.\n",
        "* The Global Interpreter Lock (GIL) ensures that only one thread is executing at a time.\n",
        "* It is created as a simple fix for thread safety. \n",
        "* Multi-threading leads to well-known problems of race conditions and dead locks\n",
        "* Python chose a simple solution: get rid of multi-threading\n",
        "* Today, there is just too much path dependency to do anything about it.\n",
        "\n",
        "# Multi-processing \n",
        "* We can circumvent the GIL by using the multiprocessing package of Python. \n",
        "* A process has more overhead than a thread.\n",
        "* All multi-threading problems, like race conditions and deadlocks,still need to be handled by the programmer.\n",
        "* Those problems are inherent to any memory-sharing programs running in parallel. \n",
        "* Don't over-simplify problems.\n",
        "\n",
        "# Pferformance \n",
        "\n",
        "# Numpy \n",
        "\n",
        "# Other Useful Pythong Packages\n",
        "* MatPlotlib\n",
        "    - A library for drawing diagrams in Python \n",
        "    - Visualization of any data.\n",
        "    - Extremely customizable, if slightly steeper learning curve than Excel\n",
        "\n",
        "* Scipy \n",
        "    - Scientific computing.\n",
        "        \n",
        "        Complementary to Numpy \n",
        "* Tensorboard\n",
        "    - Visualization for the training of neural networks\n",
        "\n",
        "# Package Managerment \n",
        "* The purpose of package management is to avoid version conflicts \n",
        "* Pip + virtualenv \n",
        "    - Does not achieve complete isolation between virtual environments\n",
        "* Conda\n",
        "    - Strong isolation\n",
        "    - Provides an online repo of packages\n",
        "    - Highly recommended \n",
        "\n",
        "# Numpy Arrays\n",
        "* A central data structure in Numpy for vectors, matrices, and tensors.\n",
        "* All data in one array have to be the same type.\n",
        "* More on data types: https://numpy.org/doc/stable/reference/arrays.dtypes.html\n"
      ],
      "metadata": {
        "id": "BRt1Uj1jzmyR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creation of Arrays"
      ],
      "metadata": {
        "id": "UkVHdXJgH4Vn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "def print_np_details(arr, name):\n",
        "    print('array', name)\n",
        "    print(arr)\n",
        "    print('python type= ', arr.astype)\n",
        "    print(\"numpy data type= \", arr.dtype)\n",
        "    print(\"shape = \", arr.shape)\n"
      ],
      "metadata": {
        "id": "4-dGGdeoH1q3"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np \n",
        "a1D = np.array([1, 2, 3, 4]) # this creates a numpy.ndarray object from a Python list\n",
        "print_np_details(a1D, \"a1D\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLjG9hc_JFyB",
        "outputId": "4c9dc67e-7310-4e04-cb07-ed9332601a0c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "array a1D\n",
            "[1 2 3 4]\n",
            "python type=  <built-in method astype of numpy.ndarray object at 0x7fe06a871f30>\n",
            "numpy data type=  int64\n",
            "shape =  (4,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this creates a 2d array \n",
        "a2D = np.array([[1, 2, 3, 4], [5, 6, 7, 8]])\n",
        "print_np_details(a2D, \"a2D\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5Wz5vaYJ647",
        "outputId": "005253e1-e41f-4e76-8f5e-83c4b1249666"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "array a2D\n",
            "[[1 2 3 4]\n",
            " [5 6 7 8]]\n",
            "python type=  <built-in method astype of numpy.ndarray object at 0x7fe06a80e760>\n",
            "numpy data type=  int64\n",
            "shape =  (2, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# specify the type of the array\n",
        "a = np.array([127, 128, 129], dtype=np.int8)\n",
        "# 8-bit integer represents value from -128 to 127\n",
        "print_np_details(a, \"a\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AM7T8SoVKLYV",
        "outputId": "3dd68f81-b58f-4a16-f5b6-32bc8ee27951"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "array a\n",
            "[ 127 -128 -127]\n",
            "python type=  <built-in method astype of numpy.ndarray object at 0x7fe06a778d00>\n",
            "numpy data type=  int8\n",
            "shape =  (3,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# setting the data type to unsigned int \n",
        "a = np.array([127, 128, 129, 256], dtype=np.uint8)\n",
        "# 8-bit unsigned integer represents value from 0 to 255\n",
        "print_np_details(a, \"a\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eg_SuQGKKhXg",
        "outputId": "8edc3c29-bb82-4836-cb80-5a87c8a6c07c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "array a\n",
            "[127 128 129   0]\n",
            "python type=  <built-in method astype of numpy.ndarray object at 0x7fe06a81e850>\n",
            "numpy data type=  uint8\n",
            "shape =  (4,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# setting the data type to 16-bit int \n",
        "a = np.array([127, 128, 129, 255], dtype=np.int16)\n",
        "print_np_details(a, \"a\")\n",
        "\n",
        "#setting the data type to 32-bit float\n",
        "b = np.array([127, 128, 129, 255], dtype=np.float32) \n",
        "print_np_details(b, \"b\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQiUnJMdOdNf",
        "outputId": "34a5f3c3-da82-4d6d-e1cf-a517dea753cf"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "array a\n",
            "[127 128 129 255]\n",
            "python type=  <built-in method astype of numpy.ndarray object at 0x7fe06a7e83a0>\n",
            "numpy data type=  int16\n",
            "shape =  (4,)\n",
            "array b\n",
            "[127. 128. 129. 255.]\n",
            "python type=  <built-in method astype of numpy.ndarray object at 0x7fe06a7aa710>\n",
            "numpy data type=  float32\n",
            "shape =  (4,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# zero matrix \n",
        "a = np.zeros((2,3))\n",
        "print_np_details(a, \"a\")\n",
        "\n",
        "b = np.zeros((2,3), dtype=np.int16)\n",
        "print_np_details(b, \"b\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvbbM94mO4Ux",
        "outputId": "1c639889-9cc9-45b6-fbe4-79c9d7a713b8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "array a\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "python type=  <built-in method astype of numpy.ndarray object at 0x7fe06a73be40>\n",
            "numpy data type=  float64\n",
            "shape =  (2, 3)\n",
            "array b\n",
            "[[0 0 0]\n",
            " [0 0 0]]\n",
            "python type=  <built-in method astype of numpy.ndarray object at 0x7fe06a73bad0>\n",
            "numpy data type=  int16\n",
            "shape =  (2, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# one matrix\n",
        "a = np.ones((3, 5))\n",
        "print(a)\n",
        "\n",
        "# identity matrix\n",
        "a = np.eye(4)\n",
        "print(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGkPbtsu11Ag",
        "outputId": "dd838124-5e7b-487b-b50c-935f7339f13b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1.]]\n",
            "[[1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Slicing Arrays"
      ],
      "metadata": {
        "id": "7ZGjYTaL2fLd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.array([[1, 2, 3],[3, 4, 6.7],[5, 9.0, 5]])\n",
        "print(a)\n",
        "print(\"selecting the first row\")\n",
        "print(a[0, :]) # zero based indexing \n",
        "print(\"select the second column\")\n",
        "print(a[:, 1])\n",
        "print(\"selecting the second and the third columns\")\n",
        "print(a[:, 1:3])\n",
        "print(\"selecting the second and the third rows and the 3rd column\")\n",
        "print(a[1:3,2])\n",
        "print(\"selecting the entry a_{2,3}\")\n",
        "print(a[1,2])\n",
        "print(\"fancy indexing first row, and second row\")\n",
        "print(a[[1,2]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nefzQVA12iB4",
        "outputId": "60bbf8fb-165a-44bf-9bad-925c9be9b737"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.  2.  3. ]\n",
            " [3.  4.  6.7]\n",
            " [5.  9.  5. ]]\n",
            "selecting the first row\n",
            "[1. 2. 3.]\n",
            "select the second column\n",
            "[2. 4. 9.]\n",
            "selecting the second and the third columns\n",
            "[[2.  3. ]\n",
            " [4.  6.7]\n",
            " [9.  5. ]]\n",
            "selecting the second and the third rows and the 3rd column\n",
            "[6.7 5. ]\n",
            "selecting the entry a_{2,3}\n",
            "6.7\n",
            "[[3.  4.  6.7]\n",
            " [5.  9.  5. ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.array([[1, 2, 3],[3, 4, 6.7],[5, 9.0, 5]])\n",
        "print(a)\n",
        "print(\"assigning values to the second and the third rows and the 3rd column\")\n",
        "a[1:3, 2] = np.array([0.1, 0.2])\n",
        "print(a)\n",
        "\n",
        "print(\"assigning values to the first rows\")\n",
        "a[0, :] = np.array([100, 200, 300])\n",
        "print(a)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5PSG0cf11EP",
        "outputId": "218b548c-f40b-4288-d1b7-9e279df98744"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.  2.  3. ]\n",
            " [3.  4.  6.7]\n",
            " [5.  9.  5. ]]\n",
            "assigning values to the second and the third rows and the 3rd column\n",
            "[[1.  2.  3. ]\n",
            " [3.  4.  0.1]\n",
            " [5.  9.  0.2]]\n",
            "assigning values to the first rows\n",
            "[[1.e+02 2.e+02 3.e+02]\n",
            " [3.e+00 4.e+00 1.e-01]\n",
            " [5.e+00 9.e+00 2.e-01]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.array([[1, 2, 3],[3, 4, 6.7],[5, 9.0, 5]])\n",
        "print(\"selecting the diagonal\")\n",
        "print(np.diagonal(a))\n",
        "\n",
        "print(\"selecting the diagonal from the first and second row\")\n",
        "print(np.diagonal(a[0:2]))\n",
        "\n",
        "print(\"assign  a new diagonal to a\")\n",
        "print(np.fill_diagonal(a, np.array([-4, -5, -6])))\n",
        "print(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FO4YwpA_11H_",
        "outputId": "03180b14-6056-474c-d9e5-e4c405e5c096"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "selecting the diagonal\n",
            "[1. 4. 5.]\n",
            "selecting the diagonal from the first and second row\n",
            "[1. 4.]\n",
            "assign  a new diagonal to a\n",
            "None\n",
            "[[-4.   2.   3. ]\n",
            " [ 3.  -5.   6.7]\n",
            " [ 5.   9.  -6. ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Element-wise Operations"
      ],
      "metadata": {
        "id": "wCn68bRV6JMg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.array([1, 2, 3, 4])\n",
        "b = np.array([2, 6, 9, 12])\n",
        "print(\"element-wise addition\")\n",
        "print(a+0.2)\n",
        "print(\"element-wise multiplication\")\n",
        "print(a*2)\n",
        "print(\"element-wise division\")\n",
        "print(a/3)\n",
        "\n",
        "print(\"element-wise addition\")\n",
        "print(a+b)\n",
        "print(\"element-wise division\")\n",
        "print(a/b)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NosAdeq26Nhr",
        "outputId": "5abfe311-8c9b-42c0-cc4c-f3b5d785ddf5"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "element-wise addition\n",
            "[1.2 2.2 3.2 4.2]\n",
            "element-wise multiplication\n",
            "[2 4 6 8]\n",
            "element-wise division\n",
            "[0.33333333 0.66666667 1.         1.33333333]\n",
            "element-wise addition\n",
            "[ 3  8 12 16]\n",
            "element-wise division\n",
            "[0.5        0.33333333 0.33333333 0.33333333]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Broadcasting"
      ],
      "metadata": {
        "id": "otsIcQpc63iC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A = np.array([1, 2, 3])\n",
        "B = np.array([[2, 3, 4], [5, 6, 7], [9, 10, 11]])\n",
        "print(A.shape)\n",
        "print(B.shape)\n",
        "\n",
        "A+B"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3AecHp35gj2",
        "outputId": "60c31909-3804-4310-bf90-a715b6f95b57"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3,)\n",
            "(3, 3)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 3,  5,  7],\n",
              "       [ 6,  8, 10],\n",
              "       [10, 12, 14]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear Algrebra Operations"
      ],
      "metadata": {
        "id": "ioT6aKxh8MYQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# inner product \n",
        "a = np.array([1, 2, 3, 4])\n",
        "b = np.array([1/2, 1/16, 9, 12])\n",
        "print(\"inner product\")\n",
        "print(a.dot(b))\n",
        "\n",
        "# matrix-vector multiplication\n",
        "A = np.array([[1, 1/2, 1/3], [3, 0.4, 6.7], [5, 9.0, 5]])\n",
        "x = np.array([2, 1.3, 4.8])\n",
        "print(\"matrix-vector product\")\n",
        "print(A.dot(x)) # x as vector \n",
        "# print(x.dot(A)) # will broadcasting\n",
        "\n",
        "# linear combination of columns\n",
        "y = x[0] * A[:, 0] + x[1] * A[:, 1] + x[2] * A[:, 2]\n",
        "print(\"linear combination of columns\")\n",
        "print(y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66xAgXIl5gmp",
        "outputId": "3bbcc636-ee1e-4477-9378-733f10098433"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inner product\n",
            "75.625\n",
            "matrix-vector product\n",
            "[ 4.25 38.68 45.7 ]\n",
            "linear combination of columns\n",
            "[ 4.25 38.68 45.7 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.linalg import inv\n",
        "import timeit\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "dim = [10, 100, 200, 500, 750, 1000]\n",
        "lst = []\n",
        "for i in range(len(dim)):\n",
        "    print(str(dim[i])+' dimensions')\n",
        "    stmt = 'import numpy; A = numpy.random.rand(' + str(dim[i]) + ',' + str(dim[i]) + ')'\n",
        "    t = timeit.timeit('numpy.linalg.inv(A)', setup=stmt, number=100)\n",
        "    print(t)\n",
        "    lst.append(t)\n",
        "\n",
        "plt.plot(dim, lst, 'bo-')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "GIWxnCab_ymh",
        "outputId": "02416ee7-c538-4c10-bfdf-27d64de6cd7f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 dimensions\n",
            "0.021084909998535295\n",
            "100 dimensions\n",
            "0.1550734710017423\n",
            "200 dimensions\n",
            "0.7290767739996227\n",
            "500 dimensions\n",
            "4.230381375000434\n",
            "750 dimensions\n",
            "6.397920205999981\n",
            "1000 dimensions\n",
            "12.795556408998891\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fe062186910>]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SVD Decomposition"
      ],
      "metadata": {
        "id": "SPSCyyBWBnN2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A = np.array([[1, 2, 3, 6], [-10, 3, 4, 6.7], [5, 9.0, 11, 5]])\n",
        "U,S,V = np.linalg.svd(A)\n",
        "# ?np.linalg.svd\n",
        "print(\"for 2D array, as U@np.diag(S)@V^T\")\n",
        "print('U')\n",
        "print(U)\n",
        "print('S')\n",
        "print(S)\n",
        "print('V^T')\n",
        "print(V)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2w6_8vSf5gpr",
        "outputId": "e9c3ac76-ee56-4a18-99d9-1e74327825f4"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "U\n",
            "[[-0.34765699  0.02897907 -0.93717385]\n",
            " [-0.42696242  0.88498534  0.18575264]\n",
            " [-0.83476806 -0.46471622  0.29529837]]\n",
            "S\n",
            "[17.76772036 11.95197597  3.65354395]\n",
            "V^T\n",
            "[[-0.01417588 -0.53406479 -0.67162636 -0.51331461]\n",
            " [-0.93243623 -0.12295304 -0.12424722  0.31624018]\n",
            " [-0.36080268  0.36693017  0.32291141 -0.79429963]\n",
            " [ 0.01353329  0.75167786 -0.65514036  0.07475534]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('verify that U is orthogonal')\n",
        "print(U.T.dot(U))\n",
        "print('verify that V is orthogonal')\n",
        "print(V.T.dot(V))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJIMcps0CQap",
        "outputId": "498d5dc0-849f-41b7-e904-0db66924c5c5"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "verify that U is orthogonal\n",
            "[[ 1.00000000e+00  1.34820161e-16  2.41621815e-16]\n",
            " [ 1.34820161e-16  1.00000000e+00 -3.03855480e-18]\n",
            " [ 2.41621815e-16 -3.03855480e-18  1.00000000e+00]]\n",
            "verify that V is orthogonal\n",
            "[[ 1.00000000e+00 -2.62495061e-16 -7.90829782e-17  3.32781480e-16]\n",
            " [-2.62495061e-16  1.00000000e+00  8.05880780e-17 -4.31114281e-17]\n",
            " [-7.90829782e-17  8.05880780e-17  1.00000000e+00 -2.45317589e-17]\n",
            " [ 3.32781480e-16 -4.31114281e-17 -2.45317589e-17  1.00000000e+00]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math \n",
        "# what happens when we remove the largest singular value?\n",
        "s1 = S.copy()\n",
        "s1[0]=0 # set the largest singular value to zero\n",
        "S1 = np.diag(s1)\n",
        "S1 = np.hstack([S1, np.zeros((3, 1))]) # make a 3-by-4 diagonal matrix, with the last column being 0\n",
        "print(S1)\n",
        "A1 = U.dot(S1).dot(V)\n",
        "error = pow(np.linalg.norm(A), 2) - pow(np.linalg.norm(A1), 2) # np.linalg.norm(A) is known as the Frobenius norm of A\n",
        "error = math.sqrt(error)\n",
        "print(error) # error in matrix Frobenius norm\n",
        "\n",
        "s1 = S.copy()\n",
        "s1[2]=0 # set the smallest singular value to zero\n",
        "S1 = np.diag(s1)\n",
        "S1 = np.hstack([S1, np.zeros((3, 1))]) # make a 3-by-4 diagonal matrix, with the last column being 0\n",
        "print(S1)\n",
        "A1 = U.dot(S1).dot(V)\n",
        "error = pow(np.linalg.norm(A), 2) - pow(np.linalg.norm(A1), 2) # np.linalg.norm(A) is known as the Frobenius norm of A\n",
        "error = math.sqrt(error)\n",
        "print(error) # error in matrix Frobenius norm\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1eOAkKWDhM-",
        "outputId": "1a9aebf4-1ebd-4242-8d12-ab1e95dae006"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.          0.          0.          0.        ]\n",
            " [ 0.         11.95197597  0.          0.        ]\n",
            " [ 0.          0.          3.65354395  0.        ]]\n",
            "17.76772036486764\n",
            "[[17.76772036  0.          0.          0.        ]\n",
            " [ 0.         11.95197597  0.          0.        ]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "3.653543946201815\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Is this a coincidence? Of course not!\n",
        "\n",
        "The Frobenius norm of matrix A is defined as $||A||_{F}= \\sqrt{\\sum_{i}\\sum_{j}A^{2}_{i,j}}$\n",
        "\n",
        "Denote the singular values by $\\sigma_{1},\\sigma_{2},\\dots,\\sigma_{k}$, We have $\\sum{\\sigma^{2}_{i}}=||A||^{2}_{F}$. That is, the sum of squared singular values equals the squared Frobenius norm.\n",
        "\n",
        "Thus, removing a singular value has the effect of reducing the Frobenius norm by that amount."
      ],
      "metadata": {
        "id": "AI33rJnxGWdj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Eigendecomposition"
      ],
      "metadata": {
        "id": "dLuZfowWKFoV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create an orthogonal matrix \n",
        "from scipy.stats import ortho_group\n",
        "U = ortho_group.rvs(dim=5)\n",
        "U.dot(U.T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8l0uPejfKMmd",
        "outputId": "795fbe3e-51d9-437b-f34f-5d9e8bd6ce03"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.00000000e+00, -2.75652331e-16,  3.54422444e-16,\n",
              "        -3.18720583e-16, -2.88627315e-16],\n",
              "       [-2.75652331e-16,  1.00000000e+00, -3.32657176e-16,\n",
              "        -5.28539356e-17,  2.02151938e-16],\n",
              "       [ 3.54422444e-16, -3.32657176e-16,  1.00000000e+00,\n",
              "        -2.64094496e-16,  2.74429271e-16],\n",
              "       [-3.18720583e-16, -5.28539356e-17, -2.64094496e-16,\n",
              "         1.00000000e+00, -8.80496183e-17],\n",
              "       [-2.88627315e-16,  2.02151938e-16,  2.74429271e-16,\n",
              "        -8.80496183e-17,  1.00000000e+00]])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a symmetric positive definite matrix\n",
        "S = np.diag([1.0, 0.5, 0.72, 1.22, 0.93])\n",
        "A = U.dot(S).dot(U.T)\n",
        "A"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjhErrOALh4D",
        "outputId": "eea4ea8d-6e0f-473c-beef-ad1a85dd6536"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 7.99333611e-01,  5.15555192e-02,  4.84734487e-02,\n",
              "         1.18419167e-01,  1.78894363e-01],\n",
              "       [ 5.15555192e-02,  9.58532889e-01,  6.86702524e-02,\n",
              "        -1.76669798e-04,  7.09260755e-02],\n",
              "       [ 4.84734487e-02,  6.86702524e-02,  8.03858925e-01,\n",
              "         1.58151660e-01, -1.32383208e-01],\n",
              "       [ 1.18419167e-01, -1.76669798e-04,  1.58151660e-01,\n",
              "         1.08904710e+00,  6.26293620e-02],\n",
              "       [ 1.78894363e-01,  7.09260755e-02, -1.32383208e-01,\n",
              "         6.26293620e-02,  7.19227474e-01]])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# verify positive definiteness\n",
        "for i in range(10):\n",
        "    v = np.random.rand(5)\n",
        "    print(v.T.dot(A).dot(v))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2fkkD_jL23l",
        "outputId": "4a442e89-67f1-4aea-d09f-4e9a7c007f0e"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.1809572961671413\n",
            "2.3005504943840367\n",
            "1.584521270482435\n",
            "1.724403439049145\n",
            "0.4776855157472136\n",
            "2.835851645340831\n",
            "1.7721975029099788\n",
            "2.7789756846778433\n",
            "1.2726378591235066\n",
            "2.796455617457099\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# perform eigendecomposition\n",
        "lmba, Q = np.linalg.eig(A)"
      ],
      "metadata": {
        "id": "963WSZ1mMJh-"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# verify result:\n",
        "\n",
        "print(A.dot(Q[:,1]))\n",
        "print(lmba[1]*Q[:,1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuWblb-pMedN",
        "outputId": "02f12cb8-e201-4309-9cdf-6d5ae08c6172"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.45212154 0.25388126 0.4074793  1.00356984 0.21526404]\n",
            "[0.45212154 0.25388126 0.4074793  1.00356984 0.21526404]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New_PyTorch_Usage\n",
        "Preliminary: Check for PyTorch Version"
      ],
      "metadata": {
        "id": "tAB-7R2bNqJR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzlCWLH8N1ua",
        "outputId": "dfb5f242-2187-40d8-ca23-170f5cd5eabe"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.10.0+cu111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "nvidia-smiGPU. Tesla P100-PCIE \n",
        "\n",
        "FanN/A0100%\n",
        "\n",
        "Temp\n",
        "\n",
        "PerfP0P12P0P12\n",
        "\n",
        "PwrPersistence-MGPUoff\n",
        "\n",
        "Bus-IdGPUdomain:bus:device.function\n",
        "\n",
        "Disp.ADisplay ActiveGPU\n",
        "\n",
        "Memory Usage\n",
        "\n",
        "GPU\n",
        "\n",
        "ECC\n",
        "\n",
        "Compute M\n",
        "\n",
        "\n",
        "\n",
        "GPUGPUGPUCPU"
      ],
      "metadata": {
        "id": "K4vK9EiPPDHG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TO3_gn8POLr2",
        "outputId": "1d694eec-a385-4b81-ee90-0c9b9e292f45"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Jan 30 01:01:42 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P0    25W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi -h\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9baSc4mRk4S",
        "outputId": "ed8d61e6-4bc7-4210-fa31-958d1cfdc877"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NVIDIA System Management Interface -- v495.46\n",
            "\n",
            "NVSMI provides monitoring information for Tesla and select Quadro devices.\n",
            "The data is presented in either a plain text or an XML format, via stdout or a file.\n",
            "NVSMI also provides several management operations for changing the device state.\n",
            "\n",
            "Note that the functionality of NVSMI is exposed through the NVML C-based\n",
            "library. See the NVIDIA developer website for more information about NVML.\n",
            "Python wrappers to NVML are also available.  The output of NVSMI is\n",
            "not guaranteed to be backwards compatible; NVML and the bindings are backwards\n",
            "compatible.\n",
            "\n",
            "http://developer.nvidia.com/nvidia-management-library-nvml/\n",
            "http://pypi.python.org/pypi/nvidia-ml-py/\n",
            "Supported products:\n",
            "- Full Support\n",
            "    - All Tesla products, starting with the Kepler architecture\n",
            "    - All Quadro products, starting with the Kepler architecture\n",
            "    - All GRID products, starting with the Kepler architecture\n",
            "    - GeForce Titan products, starting with the Kepler architecture\n",
            "- Limited Support\n",
            "    - All Geforce products, starting with the Kepler architecture\n",
            "nvidia-smi [OPTION1 [ARG1]] [OPTION2 [ARG2]] ...\n",
            "\n",
            "    -h,   --help                Print usage information and exit.\n",
            "\n",
            "  LIST OPTIONS:\n",
            "\n",
            "    -L,   --list-gpus           Display a list of GPUs connected to the system.\n",
            "\n",
            "    -B,   --list-excluded-gpus  Display a list of excluded GPUs in the system.\n",
            "\n",
            "  SUMMARY OPTIONS:\n",
            "\n",
            "    <no arguments>              Show a summary of GPUs connected to the system.\n",
            "\n",
            "    [plus any of]\n",
            "\n",
            "    -i,   --id=                 Target a specific GPU.\n",
            "    -f,   --filename=           Log to a specified file, rather than to stdout.\n",
            "    -l,   --loop=               Probe until Ctrl+C at specified second interval.\n",
            "\n",
            "  QUERY OPTIONS:\n",
            "\n",
            "    -q,   --query               Display GPU or Unit info.\n",
            "\n",
            "    [plus any of]\n",
            "\n",
            "    -u,   --unit                Show unit, rather than GPU, attributes.\n",
            "    -i,   --id=                 Target a specific GPU or Unit.\n",
            "    -f,   --filename=           Log to a specified file, rather than to stdout.\n",
            "    -x,   --xml-format          Produce XML output.\n",
            "          --dtd                 When showing xml output, embed DTD.\n",
            "    -d,   --display=            Display only selected information: MEMORY,\n",
            "                                    UTILIZATION, ECC, TEMPERATURE, POWER, CLOCK,\n",
            "                                    COMPUTE, PIDS, PERFORMANCE, SUPPORTED_CLOCKS,\n",
            "                                    PAGE_RETIREMENT, ACCOUNTING, ENCODER_STATS,\n",
            "                                    SUPPORTED_GPU_TARGET_TEMP, VOLTAGE\n",
            "                                    FBC_STATS, ROW_REMAPPER\n",
            "                                Flags can be combined with comma e.g. ECC,POWER.\n",
            "                                Sampling data with max/min/avg is also returned \n",
            "                                for POWER, UTILIZATION and CLOCK display types.\n",
            "                                Doesn't work with -u or -x flags.\n",
            "    -l,   --loop=               Probe until Ctrl+C at specified second interval.\n",
            "\n",
            "    -lms, --loop-ms=            Probe until Ctrl+C at specified millisecond interval.\n",
            "\n",
            "  SELECTIVE QUERY OPTIONS:\n",
            "\n",
            "    Allows the caller to pass an explicit list of properties to query.\n",
            "\n",
            "    [one of]\n",
            "\n",
            "    --query-gpu=                Information about GPU.\n",
            "                                Call --help-query-gpu for more info.\n",
            "    --query-supported-clocks=   List of supported clocks.\n",
            "                                Call --help-query-supported-clocks for more info.\n",
            "    --query-compute-apps=       List of currently active compute processes.\n",
            "                                Call --help-query-compute-apps for more info.\n",
            "    --query-accounted-apps=     List of accounted compute processes.\n",
            "                                Call --help-query-accounted-apps for more info.\n",
            "                                This query is not supported on vGPU host.\n",
            "    --query-retired-pages=      List of device memory pages that have been retired.\n",
            "                                Call --help-query-retired-pages for more info.\n",
            "    --query-remapped-rows=      Information about remapped rows.\n",
            "                                Call --help-query-remapped-rows for more info.\n",
            "\n",
            "    [mandatory]\n",
            "\n",
            "    --format=                   Comma separated list of format options:\n",
            "                                  csv - comma separated values (MANDATORY)\n",
            "                                  noheader - skip the first line with column headers\n",
            "                                  nounits - don't print units for numerical\n",
            "                                             values\n",
            "\n",
            "    [plus any of]\n",
            "\n",
            "    -i,   --id=                 Target a specific GPU or Unit.\n",
            "    -f,   --filename=           Log to a specified file, rather than to stdout.\n",
            "    -l,   --loop=               Probe until Ctrl+C at specified second interval.\n",
            "    -lms, --loop-ms=            Probe until Ctrl+C at specified millisecond interval.\n",
            "\n",
            "  DEVICE MODIFICATION OPTIONS:\n",
            "\n",
            "    [any one of]\n",
            "\n",
            "    -pm,  --persistence-mode=   Set persistence mode: 0/DISABLED, 1/ENABLED\n",
            "    -e,   --ecc-config=         Toggle ECC support: 0/DISABLED, 1/ENABLED\n",
            "    -p,   --reset-ecc-errors=   Reset ECC error counts: 0/VOLATILE, 1/AGGREGATE\n",
            "    -c,   --compute-mode=       Set MODE for compute applications:\n",
            "                                0/DEFAULT, 1/EXCLUSIVE_PROCESS,\n",
            "                                2/PROHIBITED\n",
            "          --gom=                Set GPU Operation Mode:\n",
            "                                    0/ALL_ON, 1/COMPUTE, 2/LOW_DP\n",
            "    -r    --gpu-reset           Trigger reset of the GPU.\n",
            "                                Can be used to reset the GPU HW state in situations\n",
            "                                that would otherwise require a machine reboot.\n",
            "                                Typically useful if a double bit ECC error has\n",
            "                                occurred.\n",
            "                                Reset operations are not guarenteed to work in\n",
            "                                all cases and should be used with caution.\n",
            "    -vm   --virt-mode=          Switch GPU Virtualization Mode:\n",
            "                                Sets GPU virtualization mode to 3/VGPU or 4/VSGA\n",
            "                                Virtualization mode of a GPU can only be set when\n",
            "                                it is running on a hypervisor.\n",
            "    -lgc  --lock-gpu-clocks=    Specifies <minGpuClock,maxGpuClock> clocks as a\n",
            "                                    pair (e.g. 1500,1500) that defines the range \n",
            "                                    of desired locked GPU clock speed in MHz.\n",
            "                                    Setting this will supercede application clocks\n",
            "                                    and take effect regardless if an app is running.\n",
            "                                    Input can also be a singular desired clock value\n",
            "                                    (e.g. <GpuClockValue>).\n",
            "    -rgc  --reset-gpu-clocks\n",
            "                                Resets the Gpu clocks to the default values.\n",
            "    -lmc  --lock-memory-clocks=  Specifies <minMemClock,maxMemClock> clocks as a\n",
            "                                    pair (e.g. 5100,5100) that defines the range \n",
            "                                    of desired locked Memory clock speed in MHz.\n",
            "                                    Input can also be a singular desired clock value\n",
            "                                    (e.g. <MemClockValue>).\n",
            "    -rmc  --reset-memory-clocks\n",
            "                                Resets the Memory clocks to the default values.\n",
            "    -ac   --applications-clocks= Specifies <memory,graphics> clocks as a\n",
            "                                    pair (e.g. 2000,800) that defines GPU's\n",
            "                                    speed in MHz while running applications on a GPU.\n",
            "    -rac  --reset-applications-clocks\n",
            "                                Resets the applications clocks to the default values.\n",
            "    -pl   --power-limit=        Specifies maximum power management limit in watts.\n",
            "    -cc   --cuda-clocks=        Overrides or restores default CUDA clocks.\n",
            "                                In override mode, GPU clocks higher frequencies when running CUDA applications.\n",
            "                                Only on supported devices starting from the Volta series.\n",
            "                                Requires administrator privileges.\n",
            "                                0/RESTORE_DEFAULT, 1/OVERRIDE\n",
            "    -am   --accounting-mode=    Enable or disable Accounting Mode: 0/DISABLED, 1/ENABLED\n",
            "    -caa  --clear-accounted-apps\n",
            "                                Clears all the accounted PIDs in the buffer.\n",
            "          --auto-boost-default= Set the default auto boost policy to 0/DISABLED\n",
            "                                or 1/ENABLED, enforcing the change only after the\n",
            "                                last boost client has exited.\n",
            "          --auto-boost-permission=\n",
            "                                Allow non-admin/root control over auto boost mode:\n",
            "                                0/UNRESTRICTED, 1/RESTRICTED\n",
            "    -mig  --multi-instance-gpu= Enable or disable Multi Instance GPU: 0/DISABLED, 1/ENABLED\n",
            "                                Requires root.\n",
            "    -gtt  --gpu-target-temp=    Set GPU Target Temperature for a GPU in degree celsius.\n",
            "                                Requires administrator privileges\n",
            "\n",
            "   [plus optional]\n",
            "\n",
            "    -i,   --id=                 Target a specific GPU.\n",
            "    -eow, --error-on-warning    Return a non-zero error for warnings.\n",
            "\n",
            "  UNIT MODIFICATION OPTIONS:\n",
            "\n",
            "    -t,   --toggle-led=         Set Unit LED state: 0/GREEN, 1/AMBER\n",
            "\n",
            "   [plus optional]\n",
            "\n",
            "    -i,   --id=                 Target a specific Unit.\n",
            "\n",
            "  SHOW DTD OPTIONS:\n",
            "\n",
            "          --dtd                 Print device DTD and exit.\n",
            "\n",
            "     [plus optional]\n",
            "\n",
            "    -f,   --filename=           Log to a specified file, rather than to stdout.\n",
            "    -u,   --unit                Show unit, rather than device, DTD.\n",
            "\n",
            "    --debug=                    Log encrypted debug information to a specified file. \n",
            "\n",
            " STATISTICS: (EXPERIMENTAL)\n",
            "    stats                       Displays device statistics. \"nvidia-smi stats -h\" for more information.\n",
            "\n",
            " Device Monitoring:\n",
            "    dmon                        Displays device stats in scrolling format.\n",
            "                                \"nvidia-smi dmon -h\" for more information.\n",
            "\n",
            "    daemon                      Runs in background and monitor devices as a daemon process.\n",
            "                                This is an experimental feature. Not supported on Windows baremetal\n",
            "                                \"nvidia-smi daemon -h\" for more information.\n",
            "\n",
            "    replay                      Used to replay/extract the persistent stats generated by daemon.\n",
            "                                This is an experimental feature.\n",
            "                                \"nvidia-smi replay -h\" for more information.\n",
            "\n",
            " Process Monitoring:\n",
            "    pmon                        Displays process stats in scrolling format.\n",
            "                                \"nvidia-smi pmon -h\" for more information.\n",
            "\n",
            " TOPOLOGY:\n",
            "    topo                        Displays device/system topology. \"nvidia-smi topo -h\" for more information.\n",
            "\n",
            " DRAIN STATES:\n",
            "    drain                       Displays/modifies GPU drain states for power idling. \"nvidia-smi drain -h\" for more information.\n",
            "\n",
            " NVLINK:\n",
            "    nvlink                      Displays device nvlink information. \"nvidia-smi nvlink -h\" for more information.\n",
            "\n",
            " CLOCKS:\n",
            "    clocks                      Control and query clock information. \"nvidia-smi clocks -h\" for more information.\n",
            "\n",
            " ENCODER SESSIONS:\n",
            "    encodersessions             Displays device encoder sessions information. \"nvidia-smi encodersessions -h\" for more information.\n",
            "\n",
            " FBC SESSIONS:\n",
            "    fbcsessions                 Displays device FBC sessions information. \"nvidia-smi fbcsessions -h\" for more information.\n",
            "\n",
            " GRID vGPU:\n",
            "    vgpu                        Displays vGPU information. \"nvidia-smi vgpu -h\" for more information.\n",
            "\n",
            " MIG:\n",
            "    mig                         Provides controls for MIG management. \"nvidia-smi mig -h\" for more information.\n",
            "\n",
            " COMPUTE POLICY:\n",
            "    compute-policy              Control and query compute policies. \"nvidia-smi compute-policy -h\" for more information. \n",
            "\n",
            " BOOST SLIDER:\n",
            "    boost-slider                Control and query boost sliders. \"nvidia-smi boost-slider -h\" for more information. \n",
            "\n",
            " POWER HINT:    power-hint                  Estimates GPU power usage. \"nvidia-smi power-hint -h\" for more information. \n",
            "\n",
            " BASE CLOCKS:    base-clocks                 Query GPU base clocks. \"nvidia-smi base-clocks -h\" for more information. \n",
            "\n",
            "Please see the nvidia-smi(1) manual page for more detailed information.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensor"
      ],
      "metadata": {
        "id": "nKCUJ8rdR-wP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A = torch.tensor([[1., -1.], [1., -1.]])\n",
        "print(A)\n",
        "print(A.type)\n",
        "print(A.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPN8XPgsSF1C",
        "outputId": "4c9d0af4-960a-48d9-9cec-744018266ab7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1., -1.],\n",
            "        [ 1., -1.]])\n",
            "<built-in method type of Tensor object at 0x7f43134a97d0>\n",
            "torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch works with numpy smoothly\n",
        "import numpy as np\n",
        "A = torch.tensor(np.array([[1, 2, 3], [4, 5, 6]]))\n",
        "print(A)\n",
        "print(A.dtype)\n",
        "\n",
        "A = torch.tensor(np.array([[1, 2, 3], [4, 5, 6]], dtype=np.float32)) # PyTorch inherits dtype from numpy\n",
        "print(A)\n",
        "print(A.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfFTeQOCRnWV",
        "outputId": "d437a715-2bdd-4f7d-8ed6-9a690bdace12"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "torch.int64\n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]])\n",
            "torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A = torch.ones([2, 2])\n",
        "print(A)\n",
        "\n",
        "A = A.cuda() # Returns a copy of this object in CUDA memory\n",
        "# ?A.cuda()\n",
        "print(A)\n",
        "\n",
        "# create tensor directly on the GPU \n",
        "cuda0 = torch.device('cuda:0')\n",
        "A = torch.ones([2,4], dtype=torch.float32, device=cuda0)\n",
        "print(A)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWEKmxSNTSaQ",
        "outputId": "e27b2f6b-d615-490e-b8c7-f6f739288c81"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]])\n",
            "tensor([[1., 1.],\n",
            "        [1., 1.]], device='cuda:0')\n",
            "tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Performance Tip:***Whenever possible, create tensors on GPUs directly, instead of transfering from CPU to GPU after creation."
      ],
      "metadata": {
        "id": "Hl7hiZlAUXzG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensor Operations\n"
      ],
      "metadata": {
        "id": "NX_eE2S7UooD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tensor operations \n",
        "A = torch.ones([2, 2])\n",
        "B = torch.tensor([[1, 3], [2, 4]])\n",
        "#component-wise operations\n",
        "print('A+B')\n",
        "print(A+B)\n",
        "print('A*B')\n",
        "print(A*B) # element-wise (inner product )\n",
        "# [[1.*1, 3.*1],\n",
        "#  [2.*1, 4.*]]\n",
        "\n",
        "print(A)\n",
        "\n",
        "# matrix multiplication \n",
        "print(\"matrix multiplication A*B\")\n",
        "\n",
        "# print(torch.matmul(A, B)) # this line fails because matmul only supports 32-bit floats\n",
        "print(torch.matmul(A.float(), B.float()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcmEhqq_VCNz",
        "outputId": "fd62f062-2005-4ab5-88bd-e9a11751f81b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A+B\n",
            "tensor([[2., 4.],\n",
            "        [3., 5.]])\n",
            "A*B\n",
            "tensor([[1., 3.],\n",
            "        [2., 4.]])\n",
            "tensor([[1., 1.],\n",
            "        [1., 1.]])\n",
            "matrix multiplication A*B\n",
            "tensor([[3., 7.],\n",
            "        [3., 7.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# concatenation \n",
        "print(A)\n",
        "print(B)\n",
        "print('along the row dimension')\n",
        "C = torch.cat([A, B],dim=0)\n",
        "print(C)\n",
        "\n",
        "print('along the column dimension')\n",
        "C = torch.cat([A, B], dim=1)\n",
        "print(C)\n",
        "\n",
        "print('create a new batch dimension and concatenate')\n",
        "As = A.unsqueeze(dim=0)\n",
        "Bs = B.unsqueeze(dim=0)\n",
        "print('As shape: ' + str(As.shape))\n",
        "print('Bs shape: ' + str(Bs.shape))\n",
        "C = torch.cat([As, Bs],dim=0)\n",
        "print(C)\n",
        "print(C.shape)\n",
        "\n",
        "As"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LViyHIW7Un0W",
        "outputId": "b7d84531-0688-46b0-81cf-0dda230598e3"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]])\n",
            "tensor([[1, 3],\n",
            "        [2, 4]])\n",
            "along the row dimension\n",
            "tensor([[1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 3.],\n",
            "        [2., 4.]])\n",
            "along the column dimension\n",
            "tensor([[1., 1., 1., 3.],\n",
            "        [1., 1., 2., 4.]])\n",
            "create a new batch dimension and concatenate\n",
            "As shape: torch.Size([1, 2, 2])\n",
            "Bs shape: torch.Size([1, 2, 2])\n",
            "tensor([[[1., 1.],\n",
            "         [1., 1.]],\n",
            "\n",
            "        [[1., 3.],\n",
            "         [2., 4.]]])\n",
            "torch.Size([2, 2, 2])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1., 1.],\n",
              "         [1., 1.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Batch multiplication -- optimized for mini-batch operations\n",
        "A = torch.ones([2, 2, 3])\n",
        "A[1, :, :] = A[1, :, :] * 0.5\n",
        "print(A)\n",
        "print('A shape: ' + str(A.shape))\n",
        "\n",
        "B1 = torch.tensor([[1, 3], [2, 4], [4, 6]], dtype=torch.float32).unsqueeze(0)\n",
        "B2 = torch.tensor([[4, 3], [22, 4], [-4, 60]], dtype=torch.float32).unsqueeze(0)\n",
        "B = torch.cat([B1, B2], dim=0)\n",
        "print(B)\n",
        "print('B shape: ' + str(B.shape))\n",
        "D = torch.bmm(A, B) #2x2x3 2x3x2 = > 2 x(2x3x3x2=2x2) => 2x2x2\n",
        "# ?torch.bmm() # Performs a batch matrix-matrix product of matrices \n",
        "\n",
        "print(D)\n",
        "print(D.shape)# 2x2x2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbdrVGX6oyl6",
        "outputId": "60141023-c594-490b-8ba3-3ed8dd4470ec"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[1.0000, 1.0000, 1.0000],\n",
            "         [1.0000, 1.0000, 1.0000]],\n",
            "\n",
            "        [[0.5000, 0.5000, 0.5000],\n",
            "         [0.5000, 0.5000, 0.5000]]])\n",
            "A shape: torch.Size([2, 2, 3])\n",
            "tensor([[[ 1.,  3.],\n",
            "         [ 2.,  4.],\n",
            "         [ 4.,  6.]],\n",
            "\n",
            "        [[ 4.,  3.],\n",
            "         [22.,  4.],\n",
            "         [-4., 60.]]])\n",
            "B shape: torch.Size([2, 3, 2])\n",
            "tensor([[[ 7.0000, 13.0000],\n",
            "         [ 7.0000, 13.0000]],\n",
            "\n",
            "        [[11.0000, 33.5000],\n",
            "         [11.0000, 33.5000]]])\n",
            "torch.Size([2, 2, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Eigendecomposition\n",
        "# create orthogonal matrix\n",
        "U = torch.zeros([5, 5])\n",
        "torch.nn.init.orthogonal_(U) # any function ending in _ performs in-place modification\n",
        "print(U)\n",
        "\n",
        "# eigenvalues\n",
        "S = torch.diag(torch.tensor([2, 1.8, 0.9, 0.55, 0.3]))\n",
        "print(S)\n",
        "\n",
        "M = torch.matmul(torch.matmul(U,S), U.T)\n",
        "print(M)\n",
        "\n",
        "# verify positive definiteness\n",
        "for i in range(10):\n",
        "    v = torch.ones([5, 1]) # it is necessary to specify one more dimension in PyTorch\n",
        "    torch.nn.init.normal_(v)\n",
        "    ss = torch.matmul(torch.matmul(torch.transpose(v, 0, 1), M), v)\n",
        "    print(ss)\n",
        "\n",
        "# ?torch.transpose()\n",
        "\n",
        "L_complex, V_complex = torch.linalg.eig(M) # this by default returns complex numbers \n",
        "print(L_complex) # eigenvalues\n",
        "print(V_complex) # eigenvectors\n",
        "# print(torch.view_as_real(L_complex)[:,0]) # real parts\n",
        "# print(torch.view_as_real(V_complex)[:,:,0])\n"
      ],
      "metadata": {
        "id": "FPhLOgGEsaxS",
        "outputId": "c4a52840-6b8c-4e17-8d57-e5d48fcccddb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-4.1378e-01, -5.5021e-01, -6.5474e-01,  1.1579e-01, -2.8975e-01],\n",
            "        [ 4.7968e-01, -6.3601e-01,  4.1114e-01,  3.5579e-01, -2.6415e-01],\n",
            "        [ 7.7292e-01,  7.6314e-02, -5.9887e-01, -1.9334e-01,  2.7295e-02],\n",
            "        [ 2.5185e-02,  2.5416e-01, -2.0888e-01,  8.9174e-01,  3.0975e-01],\n",
            "        [ 2.5507e-02,  4.7153e-01,  7.1814e-05,  1.6564e-01, -8.6578e-01]])\n",
            "tensor([[2.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 1.8000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.0000, 0.9000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.5500, 0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.3000]])\n",
            "tensor([[ 1.3057,  0.0363, -0.3770, -0.1196, -0.4023],\n",
            "        [ 0.0363,  1.4310,  0.3926, -0.1941, -0.4143],\n",
            "        [-0.3770,  0.3926,  1.5489,  0.0941,  0.0795],\n",
            "        [-0.1196, -0.1941,  0.0941,  0.6230,  0.2178],\n",
            "        [-0.4023, -0.4143,  0.0795,  0.2178,  0.6415]])\n",
            "tensor([[1.1076]])\n",
            "tensor([[14.9804]])\n",
            "tensor([[0.8448]])\n",
            "tensor([[4.5256]])\n",
            "tensor([[2.8584]])\n",
            "tensor([[1.5442]])\n",
            "tensor([[6.0189]])\n",
            "tensor([[7.8584]])\n",
            "tensor([[7.6510]])\n",
            "tensor([[4.7131]])\n",
            "tensor([2.0000+0.j, 1.8000+0.j, 0.9000+0.j, 0.3000+0.j, 0.5500+0.j])\n",
            "tensor([[-4.1378e-01+0.j, -5.5021e-01+0.j,  6.5474e-01+0.j,  2.8975e-01+0.j,\n",
            "          1.1579e-01+0.j],\n",
            "        [ 4.7968e-01+0.j, -6.3601e-01+0.j, -4.1114e-01+0.j,  2.6415e-01+0.j,\n",
            "          3.5579e-01+0.j],\n",
            "        [ 7.7292e-01+0.j,  7.6314e-02+0.j,  5.9887e-01+0.j, -2.7295e-02+0.j,\n",
            "         -1.9334e-01+0.j],\n",
            "        [ 2.5185e-02+0.j,  2.5416e-01+0.j,  2.0888e-01+0.j, -3.0975e-01+0.j,\n",
            "          8.9174e-01+0.j],\n",
            "        [ 2.5508e-02+0.j,  4.7153e-01+0.j, -7.2022e-05+0.j,  8.6578e-01+0.j,\n",
            "          1.6564e-01+0.j]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensor Expand \n",
        "Returns a new view of the self tensor with singleton dimensions expanded to a larger size. This does not allocate new memory. \n",
        "\n",
        "Any dimension of size 1 can be expanded to an arbitrary value without allocating new memory."
      ],
      "metadata": {
        "id": "I5_sjH1AjW7c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([[1], [2], [3]])\n",
        "x.size()\n",
        "x.expand(-1, 4) # -1 means not changing the size of that dimension\n",
        "\n"
      ],
      "metadata": {
        "id": "AT9dNisZjr_p",
        "outputId": "17b783f5-5f89-4c91-b932-84eea6b1e143",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 1, 1, 1],\n",
              "        [2, 2, 2, 2],\n",
              "        [3, 3, 3, 3]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***We cannot expand any dimension whose size is not 1!***"
      ],
      "metadata": {
        "id": "eEcp05CUnecD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x.expand(4, 4) # Uh-oh!"
      ],
      "metadata": {
        "id": "ZXuQDwckkxBv",
        "outputId": "25256abc-143f-4781-d2b1-45eac028f473",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-0e3ab91431b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Uh-oh!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (4) must match the existing size (3) at non-singleton dimension 0.  Target sizes: [4, 4].  Tensor sizes: [3, 1]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.expand(6, 4)"
      ],
      "metadata": {
        "id": "0AWRaRMHnsoK",
        "outputId": "29a59979-3f0a-45ad-f686-9bd4d9c8a40f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-4b1391892c62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (6) must match the existing size (3) at non-singleton dimension 0.  Target sizes: [6, 4].  Tensor sizes: [3, 1]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What happens when you write to a tensor resulting from expansion?"
      ],
      "metadata": {
        "id": "O-xE7dfxn4Rl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = x.repeat(4, 3) # repeat the first dimension 4 times, yielding 12x1. this actually takes new memory\n",
        "print(y)\n",
        "y[1, 1] = 100\n",
        "print(y)\n",
        "x"
      ],
      "metadata": {
        "id": "gs8opuy3ntSj",
        "outputId": "3504eee2-ab16-42b1-9204-a1c8ba4ad294",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 1, 1],\n",
            "        [2, 2, 2],\n",
            "        [3, 3, 3],\n",
            "        [1, 1, 1],\n",
            "        [2, 2, 2],\n",
            "        [3, 3, 3],\n",
            "        [1, 1, 1],\n",
            "        [2, 2, 2],\n",
            "        [3, 3, 3],\n",
            "        [1, 1, 1],\n",
            "        [2, 2, 2],\n",
            "        [3, 3, 3]])\n",
            "tensor([[  1,   1,   1],\n",
            "        [  2, 100,   2],\n",
            "        [  3,   3,   3],\n",
            "        [  1,   1,   1],\n",
            "        [  2,   2,   2],\n",
            "        [  3,   3,   3],\n",
            "        [  1,   1,   1],\n",
            "        [  2,   2,   2],\n",
            "        [  3,   3,   3],\n",
            "        [  1,   1,   1],\n",
            "        [  2,   2,   2],\n",
            "        [  3,   3,   3]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1],\n",
              "        [2],\n",
              "        [3]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = x.expand(3, 4)\n",
        "y[1, 1] = 100 # modifying the expanded tensor. This will allocate new memory.\n",
        "print(y)\n",
        "print(x)\n",
        "# However, PyTorch documentation explicitly warns against modifying the tensor resulted from the expansion \n",
        "# operation. So we probably shouldn't do this. "
      ],
      "metadata": {
        "id": "v_HW8mE-ntVr",
        "outputId": "5e886b4c-2b2e-4549-e175-868112e9ed7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  1,   1,   1,   1],\n",
            "        [100, 100, 100, 100],\n",
            "        [  3,   3,   3,   3]])\n",
            "tensor([[  1],\n",
            "        [100],\n",
            "        [  3]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Broadcasting \n",
        "Two tensors are \"broadcastable\" if the following rules hold: \n",
        "\n",
        "Each tensor has at least one dimension. \n",
        "\n",
        "when iterating over the dimension sizes, starting at the trailing dimension, the dimension sizes must either be equal, one of them is 1, or one of them does not exist."
      ],
      "metadata": {
        "id": "a868Bg9YpaBb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.empty(5, 7, 3)\n",
        "y = torch.empty(5, 7, 3)\n",
        "# same shapes are always broadcastable (i.e. the above rules always hold) \n",
        "\n",
        "x = torch.empty((0, ))\n",
        "y = torch.empty(2, 2)\n",
        "# x and y are not broadcastable, because x does not have at least 1 diemnsion\n",
        "\n",
        "# can line up trailing dimensions\n",
        "x = torch.empty(5, 3, 4, 1)\n",
        "y = torch.empty(   3, 1, 1)\n",
        "#  x and y are broadcastable.\n",
        "# 1st trailing dimension: both have size 1\n",
        "# 2nd trailing dimension: y has size 1\n",
        "# 3rd trailing dimension: x size == y size\n",
        "# 4th trailing dimension: y dimension doesn't exist\n",
        "\n",
        "print(x + y)\n",
        "\n",
        "# but:\n",
        "x = torch.empty(5,2,4,1)\n",
        "y = torch.empty(  3,1,1)\n",
        "# x and y are not broadcastable, because in the 3rd trailing dimension 2 != 3\n",
        "x + y"
      ],
      "metadata": {
        "id": "sv61iqj3ra99",
        "outputId": "30f7c452-21f3-4424-ba2e-6d237b338798",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[-2.4168e-14],\n",
            "          [-2.3633e-14],\n",
            "          [-2.3633e-14],\n",
            "          [-2.3633e-14]],\n",
            "\n",
            "         [[ 3.0843e-41],\n",
            "          [ 3.0843e-41],\n",
            "          [ 3.0843e-41],\n",
            "          [ 3.0843e-41]],\n",
            "\n",
            "         [[ 2.3694e-38],\n",
            "          [ 2.3694e-38],\n",
            "          [ 1.9422e+31],\n",
            "          [ 2.7491e+20]]],\n",
            "\n",
            "\n",
            "        [[[ 6.1949e-04],\n",
            "          [ 1.9421e+31],\n",
            "          [ 2.7491e+20],\n",
            "          [ 2.2842e-12]],\n",
            "\n",
            "         [[ 1.8788e+31],\n",
            "          [ 7.9303e+34],\n",
            "          [ 6.1949e-04],\n",
            "          [ 1.8590e+34]],\n",
            "\n",
            "         [[ 7.7767e+31],\n",
            "          [ 7.1536e+22],\n",
            "          [ 1.8180e+31],\n",
            "          [ 1.4580e-19]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1495e+24],\n",
            "          [-2.3630e-14],\n",
            "          [ 2.3592e-09],\n",
            "          [ 3.3978e+21]],\n",
            "\n",
            "         [[ 1.3284e-08],\n",
            "          [ 1.6411e-07],\n",
            "          [ 1.6617e+22],\n",
            "          [ 1.3401e-08]],\n",
            "\n",
            "         [[ 2.0802e+23],\n",
            "          [ 1.0524e+21],\n",
            "          [ 2.4694e-18],\n",
            "          [ 8.2207e+32]]],\n",
            "\n",
            "\n",
            "        [[[ 1.8394e+25],\n",
            "          [ 6.1963e-04],\n",
            "          [ 4.1161e-11],\n",
            "          [-2.3633e-14]],\n",
            "\n",
            "         [[ 1.8179e+31],\n",
            "          [ 1.8524e+28],\n",
            "          [ 2.1715e-18],\n",
            "          [ 2.1259e+20]],\n",
            "\n",
            "         [[ 2.5785e-09],\n",
            "          [ 2.6514e-09],\n",
            "          [ 2.1068e-07],\n",
            "          [ 1.0800e-05]]],\n",
            "\n",
            "\n",
            "        [[[ 8.2658e-10],\n",
            "          [ 1.6502e-07],\n",
            "          [ 1.7471e-04],\n",
            "          [-2.3631e-14]],\n",
            "\n",
            "         [[ 7.2128e+22],\n",
            "          [ 2.1715e-18],\n",
            "          [ 1.0372e-08],\n",
            "          [ 1.0072e-11]],\n",
            "\n",
            "         [[ 7.7194e-10],\n",
            "          [ 1.7283e-04],\n",
            "          [ 4.0288e-11],\n",
            "          [ 6.5552e-10]]]])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-51d07fd020dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# x and y are not broadcastable, because in the 3rd trailing dimension 2 != 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 1"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If two tensors x, y are \"broadcastable\", the resulting tensor size is calculated as follows:\n",
        "\n",
        "If the number of dimensions of x and y are not equal, prepend 1 to the dimensions of the tensor with fewer dimensions to make them equal length.\n",
        "\n",
        "Then, for each dimension size, the resulting dimension size is the max of the sizes of x and y along that dimension."
      ],
      "metadata": {
        "id": "tyve2tkJuUon"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# can line up trailing dimensions to make reading easier\n",
        "x = torch.empty(5,1,4,1) # Returns a tensor filled with uninitialized data. \n",
        "y = torch.empty(  3,1,1)\n",
        "(x + y).size()"
      ],
      "metadata": {
        "id": "Ck7-WS-uu0ti",
        "outputId": "22ec8d10-1fa0-413a-ac5c-18df8bfe2bf5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 3, 4, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# but not necessary:\n",
        "x = torch.empty(1)\n",
        "y = torch.empty(3,1,7)\n",
        "(x+y).size()"
      ],
      "metadata": {
        "id": "cxzwZ-AkpXxC",
        "outputId": "227835e4-ae02-4874-c9e6-de308f64bd0d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 1, 7])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.empty(5,2,4,1)\n",
        "y = torch.empty(3,1,1)\n",
        "(x+y).size()"
      ],
      "metadata": {
        "id": "nkYDsfATvNxp",
        "outputId": "3b11a930-fb2e-425a-8e3d-9387a649244d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-2378f7a1b7a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 1"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# In-place semantics\n",
        "One complication is that in-place operations do not allow the in-place tensor to change shapes as a result of the broadcast.\n"
      ],
      "metadata": {
        "id": "aqB0boNIvmq2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.empty(5,3,4,1)\n",
        "y = torch.empty(3,1,1)\n",
        "(x.add_(y)).size() # this replaces x with the result of the addition operation"
      ],
      "metadata": {
        "id": "00G5Zro-vzPH",
        "outputId": "20ddf7d0-3867-45da-fdf7-df0bd7b4c448",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 3, 4, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.empty(1,3,1)\n",
        "y = torch.empty(3,1,7)\n",
        "(x.add_(y)).size()"
      ],
      "metadata": {
        "id": "3XY29_yqv_pq",
        "outputId": "65d9512e-2909-4205-8913-3ec6f49e646c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-70f0f82f0dd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: output with shape [1, 3, 1] doesn't match the broadcast shape [3, 3, 7]"
          ]
        }
      ]
    }
  ]
}